<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"

	>

<channel>
	<title>Radar</title>
	<atom:link href="https://www.oreilly.com/radar/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.oreilly.com/radar</link>
	<description>Now, next, and beyond: Tracking need-to-know trends at the intersection of business and technology</description>
	<lastBuildDate>Tue, 01 Nov 2022 18:00:40 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.3.14</generator>
	<item>
		<title>Radar Trends to Watch: November 2022</title>
		<link>https://www.oreilly.com/radar/radar-trends-to-watch-november-2022/</link>
				<comments>https://www.oreilly.com/radar/radar-trends-to-watch-november-2022/#respond</comments>
				<pubDate>Tue, 01 Nov 2022 11:15:57 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[Radar Trends]]></category>
		<category><![CDATA[Signals]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14760</guid>
				<description><![CDATA[Maintaining a separate category for AI is getting difficult. We’re seeing important articles about AI infiltrating security, programming, and almost everything else; even biology. That sounds like a minor point, but it’s important: AI is eating the world. What does it mean when an AI system can reconstruct what somebody wants to say from their [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>Maintaining a separate category for AI is getting difficult. We’re seeing important articles about AI infiltrating security, programming, and almost everything else; even biology. That sounds like a minor point, but it’s important: AI is eating the world. What does it mean when an AI system can reconstruct what somebody wants to say from their brainwave? What does it mean when cultured brain cells can be configured to play Pong? They don’t play well, but it’s not long since that was a major achievement for AI.</p>



<h2>Artificial Intelligence</h2>



<ul><li>Hugo Bowne-Anderson <a href="https://www.youtube.com/watch?v=7zB6ESFto_U" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">interviews Shreya Shankar</a> about her ethnographic study of MLOps Practices. This is a must-listen! Shreya talks about pain points, good practices, and how the real world differs from what you’re taught in school.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://usefulsensors.com/" target="_blank">Useful Sensors</a> is a startup that produces <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://petewarden.com/2022/10/20/launching-useful-sensors/" target="_blank">sensors with AI built in</a>.  Their first product is a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.sparkfun.com/products/21231" target="_blank">PersonSensor</a>, a $10 camera that detects faces and computes their location relative to the camera.</li><li>The Bias Buccaneers is a group of volunteers who are creating a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/10/20/1061977/ai-bias-bounty-help-catch-unfair-algorithms-faster/" target="_blank">competition for detecting bias in AI systems</a>. Microsoft and Amazon, among others, are backing it. The practice of auditing AI systems, while it has had a slow start, is poised to grow as regulations covering AI gain traction.</li><li>Microsoft has released an open source toolkit for <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blogs.microsoft.com/ai/microsoft-open-sources-its-farm-of-the-future-toolkit/" target="_blank">AI-based precision farming</a>.</li><li>Facebook’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arxiv.org/abs/2207.04672" target="_blank">No Language Left Behind</a> project has released an open source <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/facebookresearch/fairseq/tree/nllb" target="_blank">model</a> (along with code and training data) that can translate between any of 200 languages.</li><li>The creators of StableDiffusion have <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://mpost.io/stabilityai-announced-ai-music-generator-harmonai-based-on-dance-diffusion-model/" target="_blank">announced</a><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.harmonai.org/" target="_blank"> HarmonyAI</a>, a community for building AI tools for generating music. They have released an application called <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://colab.research.google.com/github/Harmonai-org/sample-generator/blob/main/Dance_Diffusion.ipynb" target="_blank">Dance Diffusion</a>.</li><li>Researchers have developed a turtle-like robot that can both <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-10-morphing-limbs-robot.html" target="_blank">swim and walk on land</a> by changing the shape of its legs. Applications may include monitoring aquatic ecosystems and underwater farming.</li><li>If you’re interested in writing AI software to generate code (and not just using Copilot), Evan Pu has begun a series of blog posts on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://evanthebouncy.github.io/program-synthesis-minimal/what-is-synthesis/" target="_blank">program synthesis</a>.</li><li>An AI application called <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-10-ai-platform.html" target="_blank">Transkribus</a> is capable of reading old handwriting. Anyone who has done archival research will know immediately what a big problem this is.</li><li>Transformers revolutionized natural language processing. CapitalOne is exploring the use of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twimlai.com/podcast/twimlai/transformers-for-tabular-data-at-capital-one-with-bayan-bruss/" target="_blank">Transformers for tabular data</a>, which could lead to a similar revolution in financial applications.</li><li>Google’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://google-research.github.io/seanet/audiolm/examples/" target="_blank">AudioLM</a> uses large <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/10/07/1060897/ai-audio-generation/" target="_blank">language model techniques to produce spoken audio and music</a>. The prompts are audio clips, rather than texts, and the output sounds more natural than other audio synthesis software.</li><li>Can AI be used to develop new algorithms for problems humans think are well-understood, like matrix multiplication? Deep Mind’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.deepmind.com/blog/discovering-novel-algorithms-with-alphatensor" target="_blank">AlphaTensor</a> says yes. This result won’t get as much attention as generative art, but it is likely to be more important.</li><li>The White House has revealed its <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/" target="_blank">AI Bill of Rights</a>. It’s an impressive document but, unlike similar efforts in Europe and elsewhere, says little about enforcement.</li><li>Tesla has <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://bdtechtalks.com/2022/10/03/teslas-optimus-robot/" target="_blank">demonstrated a prototype of Optimus</a>, its humanoid home robot. Reactions are mixed; the demonstration was unimpressive, though they appear to have done years worth of R&amp;D in a very short time. It’s also not clear that their robot is solving the right problems.</li><li>Not to be outdone by Make-A-Video and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://phenaki.video/" target="_blank">Phenaki</a> (another text-to-video AI generator), Google has announced <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://imagen.research.google/video/" target="_blank">Imagen Video</a> and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://dreamfusionpaper.github.io/" target="_blank">DreamFusion</a>.  DreamFusion generates 2D images that can be viewed from any angle. (Others have done <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/ashawkey/stable-dreamfusion" target="_blank">something similar based on Stable Diffusion</a>.)</li><li>An AI system can now <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.biorxiv.org/content/10.1101/2022.09.29.509744v1" target="_blank">reconstruct continuous language</a> sequences from non-invasive recordings of brain activity.</li><li>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/10/01/1060539/eu-tech-policy-harmful-ai-liability/" target="_blank">proposed law in the EU</a> would allow people to sue AI companies for damages after being harmed by a result from an AI system.</li><li>A fascinating method for <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.schneier.com/blog/archives/2022/10/detecting-deepfake-audio-by-modeling-the-human-acoustic-tract.html" target="_blank">detecting audio deepfakes</a> has achieved 99% accuracy. It models what a human vocal tract would have to do to produce the sounds. Most deep fakes require impossible configurations of the vocal tracts.</li></ul>



<h2>Programming</h2>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/coders-author-clive-thompson-on-how-programming-is-changing/" target="_blank">Clive Thompson’s thoughts</a> on the future of programming are worth reading, particularly on the influence of tools like Copilot on “code-adjacent” programmers; that is, non-professionals who do limited programming as part of their jobs. For them, Copilot will be a superpower.</li><li>Another kind of automatic code generation: the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/OpenAPITools/openapi-generator" target="_blank">OpenAPI Generator</a> is a tool that automatically generates client libraries, stubs, and other code for APIs that are documented according to the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/OAI/OpenAPI-Specification" target="_blank">OpenAPI Specification</a>.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/open-source-contribution-takes-a-hit-as-security-concerns-grow/" target="_blank">Contributions of code to open source</a> software projects appear to be declining, possibly because of security concerns. If this hypothesis is correct, it is counterproductive. Open source is critical infrastructure, and critical infrastructure needs to be maintained.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/wasmcloud/" target="_blank">wasmCloud</a> is a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://wasmcloud.com/" target="_blank">platform</a> for developing components with WebAssembly that can run anywhere, including in the cloud or on small networked devices. It includes the ability to form a mesh network that’s independent of where components run.</li><li>Matt Welsh predicts that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://levelup.gitconnected.com/the-end-of-programming-6e3f7ff0d8b4" target="_blank">the future of computing will not be about programming</a>; it will be about training large models for specialized applications.</li><li>Another tool for deploying containers: <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/how-to-deploy-containers-with-nerdctl/" target="_blank">nerdctl</a>. How many is too many? We don’t know whether nerdctl is a winner, but it’s important to watch for lightweight alternatives to Kubernetes.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/terraform-cloud-now-offers-less-code-and-no-code-options/" target="_blank">Terraform will be offering a no code option</a> for cloud configuration.&nbsp; This will simplify cloud deployment, making it possible for developers to deploy directly without assistance from an operations group.</li><li>The Cassandra database will support <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/an-apache-cassandra-breakthrough-acid-transactions-at-scale/" target="_blank">ACID transactions</a>, taking advantage of a new consensus protocol named <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://ieeexplore.ieee.org/document/9861765" target="_blank">Accord</a>.</li><li>More alternatives to the Electron framework: Last month, we mentioned Rust’s Tauri. Now there’s an <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://levelup.gitconnected.com/another-fantastic-electron-alternative-cc3a5ce12462" target="_blank">Electron-like framework for Go</a>, called <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://wails.app/" target="_blank">Wails</a>.</li><li>Steve Yegge has emerged from retirement to take a job as Head of Engineering at <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://about.sourcegraph.com/blog/introducing-steve-yegge" target="_blank">Sourcegraph</a>, a company that’s making tools for searching, navigating, and understanding code across multiple repositories. We normally wouldn’t consider a “new hire” noteworthy, but everything Steve does is worth watching. Be on the lookout for some excellent tools.</li><li><a href="https://www.edgeless.systems/products/constellation/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Constellation</a> is the first implementation of <a href="https://thenewstack.io/constellation-the-first-confidential-kubernetes-distribution/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Confidential Kubernetes:</a> a Kubernetes distribution designed for confidential computing. Confidential computing isn’t limited to individual nodes; Constellation authenticates all of the nodes in a Kubernetes cluster, and ensures that data is always encrypted, especially in transit.</li></ul>



<h2>Security</h2>



<ul><li>A cryptocurrency mining operation named <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/massive-cryptomining-campaign-abuses-free-tier-cloud-dev-resources/amp/" target="_blank">PurpleUrchin</a> is using free resources offered by services like GitHub and Heroku.&nbsp;The security community suspects that their goal isn’t mining coins but executing a 51% attack against one of the smaller currencies.</li><li>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/10/passkeys-microsoft-apple-and-googles-password-killer-are-finally-here/" target="_blank">standard for passkeys</a> that is supported by Google, Apple, and Microsoft, and that is easy to use, means that (at last, maybe) we can do away with passwords.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.schneier.com/blog/archives/2022/10/adversarial-ml-attack-that-secretly-gives-a-language-model-a-point-of-view.html" target="_blank">Model spinning</a> is a new attack against language models that causes them to take a specific viewpoint on a subject in response to trigger words in the prompt–for example, taking a positive or negative viewpoint on a political figure. It could be used to generate interactive propaganda.</li><li>Random number generation is fundamental to many algorithms and games–particularly algorithms related to privacy and security. However, generating good random sequences is difficult. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.schneier.com/blog/archives/2022/10/on-the-randomness-of-automatic-card-shufflers.html" target="_blank">Flaws in devices like</a><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bbc.com/future/article/20221019-how-a-magician-mathematician-revealed-a-casino-loophole" target="_blank"> automatic card shufflers</a> show how tricky the problem can be.</li><li>The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.honeycomb.io/blog/future-ops-platform-engineering" target="_blank">platform</a><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/i/spaces/1vOxwMnyXpPGB" target="_blank"> engineering</a><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.elidedbranches.com/" target="_blank"> movement</a> is <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/sre-vs-devops-ops-vs-dev-2-0-or-something-new/" target="_blank">gaining steam</a>. Platform engineering requires treating the developer’s environment as a product, and developing that environment into a platform that’s easy to work in, and that makes it simple and safe for developers to push working code into production.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/google-aurora-a-collab-between-chrome-and-web-frameworks/" target="_blank">Aurora</a> is a collaboration between the Chrome browser’s development team and developers of frameworks like React and Next.JS that intends to make the browser a better target for these frameworks.</li><li>Mitre’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://d3fend.mitre.org/" target="_blank">D3FEND</a> is a public knowledge graph of cybersecurity countermeasures. It is a counterpart to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://attack.mitre.org/" target="_blank">ATT&amp;CK</a>, a knowledge graph of tactics and techniques used by attackers.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/sternum-adds-observability-to-the-internet-of-things/" target="_blank">Sternum</a> is an observability and security platform designed for IoT devices based on Linux or RTOS. It is difficult to get information from devices once they’re in the field. Sternum performs anomaly detection, in addition to providing information about user-defined traces.</li><li>What can you trust in the software supply chain? Nothing, not even compilers; a new <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arxiv.org/abs/2210.00108" target="_blank">paper</a> shows that compilers can be used to insert undetectable backdoors into models for machine learning. Trust nothing.</li><li><a href="https://techxplore.com/news/2022-10-kind-downcoding-flaws-anonymizing.html">Downcoding</a> is a new attack against common methods for anonymizing data. It was designed specifically as a challenge to privacy regulations: organizations that collect and share data have to do better to preserve privacy. Anonymization isn’t enough.</li></ul>



<h2>Web3</h2>



<ul><li>Apple’s AppStore now <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://9to5mac.com/2022/10/24/app-store-guidelines-updated-nft-ad-managers/" target="_blank">allows apps that purchase NFTs</a>, or deliver services through NFTs. However, all payments must be made through in-app purchases.</li><li>The British artist Damien Hirst has started to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bbc.com/news/entertainment-arts-63218704" target="_blank">burn the originals of artworks that he has sold as NFTs</a> to “complete the transformation” of the work into the digital world. The artworks are burned in a public exhibition, making the burning itself a work of performance art.</li><li>Metatheft: A threat actor has injected dApps into <a rel="noreferrer noopener" href="https://www.bleepingcomputer.com/news/security/hackers-are-breaching-scam-sites-to-hijack-crypto-transactions/" target="_blank">cryptocurrency scam</a> sites. These dApps divert funds sent to the scammer to the threat actor’s accounts, thus stealing directly from the scam’s victims. The scammers presumably have no interest in reporting these thefts to authorities.</li></ul>



<h2>Metaverse</h2>



<ul><li>A Korean research group has developed a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-10-xr-based-metaverse-platform-multi-user-collaborations.html" target="_blank">platform for collaboration in the Metaverse</a>. Fundamental ideas behind this platform are enabling people to work together in a virtual space; location recognition; minimizing latency between users; and gesture recognition.</li><li>It’s rumored that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/gadgets/2022/10/apples-ar-vr-headset-will-scan-your-iris-when-you-put-it-on/" target="_blank">Apple’s VR headset will perform an iris scan</a> when someone puts it on, to authenticate the user to apps.</li><li>Facebook/Meta figures out how to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-10-meta-virtual-reality-avatars-legs.html" target="_blank">add legs</a> to its Metaverse avatars. This was their “most requested feature.” Nobody seems impressed.</li></ul>



<h2>Biology</h2>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/science/2022/10/a-dish-of-neurons-may-have-taught-itself-to-play-pong-badly/" target="_blank">Pong played by a dish of cultured neurons</a>? Dishbrain doesn’t play well, but it’s surprising that it plays at all.</li><li><a href="https://www.technologyreview.com/2022/10/12/1061204/human-brain-cells-transplanted-baby-rats-brains/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Human brain cells transplanted into rat brains</a> grow and integrate themselves with the rat’s brain cells, eventually becoming roughly one sixth of a functioning brain. This could become a platform for researching human brain diseases. And we have to ask: <a href="https://www.technologyreview.com/2022/10/14/1061611/rats-with-human-brain-cells/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">are these rats just rats</a>?</li></ul>



<h2>Quantum Computing</h2>



<ul><li>Researchers have used a quantum computer to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-10-important-breakthrough-quantum-efficient-batteries.html" target="_blank">find solutions to the Fermi-Hubbard model</a>, a&nbsp;problem that can’t be solved with classical computers. Unlike previous demonstrations of quantum advantage, which had no practical value, the Fermi-Hubbard model has important implications for battery and solar cell research.</li></ul>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/radar-trends-to-watch-november-2022/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>What We Learned Auditing Sophisticated AI for Bias</title>
		<link>https://www.oreilly.com/radar/what-we-learned-auditing-sophisticated-ai-for-bias/</link>
				<comments>https://www.oreilly.com/radar/what-we-learned-auditing-sophisticated-ai-for-bias/#respond</comments>
				<pubDate>Tue, 18 Oct 2022 11:14:23 +0000</pubDate>
		<dc:creator><![CDATA[Patrick Hall]]></dc:creator>
				<category><![CDATA[AI & ML]]></category>
		<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Deep Dive]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14754</guid>
				<description><![CDATA[A recently passed law in New York City requires audits for bias in AI-based hiring systems. And for good reason. AI systems fail frequently, and bias is often to blame. A recent sampling of headlines features sociological bias in generated images, a chatbot, and a virtual rapper. These examples of denigration and stereotyping are troubling [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4344524&amp;GUID=B051915D-A9AC-451E-81F8-6596032FA3F9&amp;Options=Advanced&amp;Search" target="_blank">recently passed law</a> in New York City requires audits for bias in AI-based hiring systems. And for good reason. AI systems fail frequently, and bias is often to blame. A recent sampling of headlines features sociological bias in <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://futurism.com/dall-e-mini-racist" target="_blank">generated images</a>, a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://mashable.com/article/meta-facebook-ai-chatbot-racism-donald-trump" target="_blank">chatbot</a>, and a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://mashable.com/article/fn-meka-record-deal-racial-stereotyping" target="_blank">virtual rapper</a>. These examples of denigration and stereotyping are troubling and harmful, but what happens when the same types of systems are used in more sensitive applications? Leading scientific publications assert that algorithms used in healthcare in the U.S. diverted care away from <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nature.com/articles/d41586-019-03228-6" target="_blank">millions of black people</a>. The government of the Netherlands resigned in 2021 after an algorithmic system <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.theguardian.com/world/2021/jan/15/dutch-government-resigns-over-child-benefits-scandal" target="_blank">wrongly accused</a> 20,000 families–disproportionately minorities–of tax fraud. Data can be wrong. Predictions can be wrong. System designs can be wrong. These errors can hurt people in very unfair ways. </p>



<p>When we use AI in security applications, the risks become even more direct. In security, bias isn’t just offensive and harmful. It’s a weakness that adversaries will exploit. What could happen if a deepfake detector works better on people who look like President Biden than on people who look like former President Obama? What if a named entity recognition (NER) system, based on a cutting-edge large language model (LLM), fails for Chinese, Cyrillic, or Arabic text? The answer is simple—bad things and legal liabilities.</p>



<p>As AI technologies are adopted more broadly in security and other high-risk applications, we’ll all need to know more about AI audit and risk management. This article introduces the basics of AI audit, through the lens of our practical experience at <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bnh.ai/" target="_blank">BNH.AI</a>, a boutique law firm focused on AI risks, and shares some general lessons we’ve learned from auditing sophisticated deepfake detection and LLM systems.</p>



<h3>What Are AI Audits and Assessments?</h3>



<p>Audit of decision-making and algorithmic systems is a niche vertical, but not necessarily a new one. Audit has been an integral aspect of model risk management (MRM) in consumer finance for years, and colleagues at <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bldsllc.com/" target="_blank">BLDS</a> and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://quantuniversity.com/" target="_blank">QuantUniversity</a> have been conducting model audits for some time. Then there’s the new cadre of AI audit firms like <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://orcaarisk.com/" target="_blank">ORCAA</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.getparity.ai/" target="_blank">Parity</a>, and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://babl.ai/" target="_blank">babl</a>, with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.bnh.ai/" target="_blank">BNH.AI</a> being the only law firm of the bunch. AI audit firms tend to perform a mix of audits and assessments. Audits are usually more official, tracking adherence to some policy, regulation, or law, and tend to be conducted by independent third parties with varying degrees of limited interaction between auditor and auditee organizations. Assessments tend to be more informal and cooperative. AI audits and assessments may focus on bias issues or other serious risks including <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.torquenews.com/1083/tesla-model-3-autopilot-hits-yet-another-police-vehicle-why-wont-they-stop" target="_blank">safety</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.theverge.com/2020/1/29/21114358/facebook-550-million-settle-lawsuit-facial-recognition-technology-illinois" target="_blank">data privacy harms</a>, and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bbc.com/news/technology-53389657" target="_blank">security vulnerabilities</a>.</p>



<p>While standards for AI audits are still immature, they do exist. For our audits, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.bnh.ai/" target="_blank">BNH.AI</a> applies external authoritative standards from laws, regulations, and AI risk management frameworks. For example, we may audit anything from an organization’s adherence to the nascent New York City employment law, to obligations under Equal Employment Opportunity Commission regulations, to MRM guidelines, to fair lending regulations, or to NIST’s draft AI risk management framework (AI RMF).</p>



<p>From our perspective, regulatory frameworks like MRM present some of the clearest and most mature guidance for audit, which are critical for organizations looking to minimize their legal liabilities. The internal control questionnaire in the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.occ.treas.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/pub-ch-model-risk.pdf" target="_blank"><em>Office of the Comptroller of the Currency’s MRM Handbook</em></a> (starting pg. 84) is an extraordinarily polished and complete audit checklist, and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf" target="_blank"><em>the Interagency Guidance on Model Risk Management</em></a> (also known as SR 11-7) puts forward clear cut advice on audit and the governance structures that are necessary for effective AI risk management writ large. Given that MRM is likely too stuffy and resource-intensive for nonregulated entities to adopt fully today, we can also look to NIST’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nist.gov/system/files/documents/2022/08/18/AI_RMF_2nd_draft.pdf" target="_blank"><em>draft AI Risk Management Framework</em></a> and the risk management <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://pages.nist.gov/AIRMF/" target="_blank">playbook</a> for a more general AI audit standard. In particular, NIST’s SP1270 <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf" target="_blank"><em>Towards a Standard for Identifying and Managing Bias in Artificial Intelligence</em></a>, a resource associated with the draft AI RMF, is extremely useful in bias audits of newer and complex AI systems.<sup>1</sup></p>



<p>For audit results to be recognized, audits have to be transparent and fair. Using a public, agreed-upon standard for audits is one way to enhance fairness and transparency in the audit process. But what about the auditors? They too must be held to some standard that ensures ethical practices. For instance, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.bnh.ai/" target="_blank">BNH.AI</a> is held to the Washington, DC, Bar’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.dcbar.org/for-lawyers/legal-ethics/rules-of-professional-conduct" target="_blank">Rules of Professional Conduct</a>. Of course, there are other emerging auditor standards, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://forhumanity.center/forhumanity-university/" target="_blank">certifications</a>, and principles. Understanding the ethical obligations of your auditors, as well as the existence (or not) of nondisclosure agreements or attorney-client privilege, is a key part of engaging with external auditors. You should also be considering the objective standards for the audit.</p>



<p>In terms of what your organization could expect from an AI audit, and for more information on audits and assessments, the recent paper <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://link.springer.com/content/pdf/10.1007/s44206-022-00017-z.pdf" target="_blank"><em>Algorithmic Bias and Risk Assessments: Lessons from Practice</em></a> is a great resource. If you’re thinking of a less formal internal assessment, the influential <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://dl.acm.org/doi/pdf/10.1145/3351095.3372873" target="_blank"><em>Closing the AI Accountability Gap</em></a> puts forward a solid framework with worked documentation examples.</p>



<h3>What Did We Learn From Auditing a Deepfake Detector and an LLM for Bias?</h3>



<p>Being a law firm, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.bnh.ai/" target="_blank">BNH.AI</a> is almost never allowed to discuss our work due to the fact that most of it is privileged and confidential. However, we’ve had the good fortune to work with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.iqt.org/labs/" target="_blank">IQT Labs</a> over the past months, and they generously shared summaries of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.bnh.ai/" target="_blank">BNH.AI</a>’s audits. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.iqt.org/ai-assurance-do-deepfakes-discriminate/" target="_blank">One audit</a> addressed potential bias in a deepfake detection system and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.iqt.org/interrogating-roberta-inside-the-challenge-of-learning-to-audit-ai-models-and-tools/" target="_blank">the other</a> considered bias in LLMs used for NER tasks. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.bnh.ai/" target="_blank">BNH.AI</a> audited these systems for adherence to the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.intelligence.gov/artificial-intelligence-ethics-framework-for-the-intelligence-community" target="_blank"><em>AI Ethics Framework for the Intelligence Community</em></a>. We also tend to use standards from US nondiscrimination law and the NIST SP1270 guidance to fill in any gaps around bias measurement or specific LLM concerns. Here’s a brief summary of what we learned to help you think through the basics of audit and risk management when your organization adopts complex AI.</p>



<h4>Bias is about more than data and models</h4>



<p>Most people involved with AI understand that unconscious biases and overt prejudices are recorded in digital data. When that data is used to train an AI system, that system can replicate our bad behavior with speed and scale. Unfortunately, that’s just one of many mechanisms by which bias sneaks into AI systems. By definition, new AI technology is less mature. Its operators have less experience and associated governance processes are less fleshed out. In these scenarios, bias has to be approached from a broad social and technical perspective. In addition to data and model problems, decisions in initial meetings, homogenous engineering perspectives, improper design choices, insufficient stakeholder engagement, misinterpretation of results, and other issues can all lead to biased system outcomes. If an audit or other AI risk management control focuses only on tech, it’s not effective.</p>



<p>If you’re struggling with the notion that social bias in AI arises from mechanisms besides data and models, consider the concrete example of screenout discrimination. This occurs when those with disabilities are unable to access an employment system, and they lose out on employment opportunities. For screenout, it may not matter if the system’s outcomes are perfectly balanced across demographic groups, when for example, someone can’t see the screen, be understood by voice recognition software, or struggles with typing. In this context, bias is often about system design and not about data or models. Moreover, screenout is a potentially serious <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.eeoc.gov/laws/guidance/americans-disabilities-act-and-use-software-algorithms-and-artificial-intelligence" target="_blank">legal liability</a>. If you’re thinking that deepfakes, LLMs and other advanced AI wouldn’t be used in employment scenarios, sorry, that’s wrong too. Many organizations now perform fuzzy keyword matching and resume scanning based on LLMs. And several new startups are proposing deepfakes as a way to make foreign accents more understandable for customer service and other work interactions that could easily spillover to interviews.</p>



<h4>Data labeling is a problem</h4>



<p>When <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.bnh.ai/" target="_blank">BNH.AI</a> audited <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/IQTLabs/FakeFinder" target="_blank">FakeFinder</a> (the deepfake detector), we needed to know demographic information about people in deepfake videos to gauge performance and outcome differences across demographic groups. If plans are not made to collect that kind of information from the people in the videos beforehand, then a tremendous manual data labeling effort is required to generate this information. Race, gender, and other demographics are not straightforward to guess from videos. Worse, in deepfakes, bodies and faces can be from different demographic groups. Each face and body needs a label. For the LLM and NER task, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.bnh.ai/" target="_blank">BNH.AI</a>’s audit plan required demographics associated with entities in raw text, and possibly text in multiple languages. While there are many interesting and useful benchmark datasets for testing bias in natural language processing, none provided these types of exhaustive demographic labels.</p>



<p>Quantitative measures of bias are often important for audits and risk management. If your organization wants to measure bias quantitatively, you’ll probably need to test data with demographic labels. The difficulties of attaining these labels should not be underestimated. As newer AI systems consume and generate ever-more complicated types of data, labeling data for training and testing is going to get more complicated too. Despite the possibilities for feedback loops and error propagation, we may end up needing AI to label data for other AI systems.</p>



<p>We’ve also observed organizations claiming that data privacy concerns prevent data collection that would enable bias testing. Generally, this is not a defensible position. If you’re using AI at scale for commercial purposes, consumers have a reasonable expectation that AI systems will protect their privacy <em>and</em> engage in fair business practices. While this balancing act may be extremely difficult, it’s usually possible. For example, large consumer finance organizations have been testing models for bias for years without direct access to demographic data. They often use a process called <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://files.consumerfinance.gov/f/201409_cfpb_report_proxy-methodology.pdf" target="_blank">Bayesian-improved surname geocoding</a> (BISG) that infers race from name and ZIP code to comply with nondiscrimination and data minimization obligations.</p>



<h4>Despite flaws, start with simple metrics and clear thresholds</h4>



<p>There are <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.youtube.com/watch?v=jIXIuYdnyyk" target="_blank">many</a> mathematical definitions of bias. More are published all the time. More formulas and measurements are published because the existing definitions are always found to be flawed and simplistic. While new metrics tend to be more sophisticated, they’re often harder to explain and lack agreed-upon thresholds at which values become problematic. Starting an audit with complex risk measures that can’t be explained to stakeholders and without known thresholds can result in confusion, delay, and loss of stakeholder engagement.</p>



<p>As a first step in a bias audit, we recommend converting the AI outcome of interest to a binary or a single numeric outcome. Final decision outcomes are often binary, even if the learning mechanism driving the outcome is unsupervised, generative, or otherwise complex. With deepfake detection, a deepfake is detected or not. For NER, known entities are recognized or not. A binary or numeric outcome allows for the application of traditional measures of practical and statistical significance with clear thresholds.</p>



<p>These metrics focus on outcome differences across demographic groups. For example, comparing the rates at which different race groups are identified in deepfakes or the difference in mean raw output scores for men and women. As for formulas, they have names like standardized mean difference (SMD, Cohen’s <em>d</em>), the adverse impact ratio (AIR) and four-fifth’s rule threshold, and basic statistical hypothesis testing (e.g., <em>t</em>-, <em>x</em><sup>2</sup>-, binomial <em>z</em>-, or Fisher’s exact tests). When traditional metrics are aligned to existing laws and regulations, this first pass helps address important legal questions and informs subsequent more sophisticated analyses.</p>



<h3>What to Expect Next in AI Audit and Risk Management?</h3>



<p>Many emerging <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.protocol.com/bulletins/dc-bill-ai-algorithms-data" target="_blank">municipal</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://iapp.org/news/a/top-10-operational-impacts-of-the-cpra-part-9-the-scope-of-the-anticipated-cpra-regulations/" target="_blank">state</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.congress.gov/bill/116th-congress/house-bill/2231/text" target="_blank">federal</a>, and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/what-the-draft-european-union-ai-regulations-mean-for-business" target="_blank">international</a> data privacy and AI laws are incorporating audits or related requirements. Authoritative <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.iso.org/committee/6794475/x/catalogue/p/1/u/1/w/0/d/0" target="_blank">standards</a> and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nist.gov/itl/ai-risk-management-framework" target="_blank">frameworks</a> are also becoming more concrete. Regulators are <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.ftc.gov/business-guidance/blog/2020/04/using-artificial-intelligence-and-algorithms" target="_blank">taking notice</a> of AI incidents, with the FTC “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.protocol.com/policy/ftc-algorithm-destroy-data-privacy" target="_blank">disgorging</a>” three algorithms in three years. If today’s AI is as powerful as many claim, none of this should come as a surprise. Regulation and oversight is commonplace for other powerful technologies like aviation or nuclear power. If AI is truly the next big transformative technology, get used to audits and other risk management controls for AI systems.</p>



<hr class="wp-block-separator" />



<h4>Footnotes</h4>



<ol><li>Disclaimer: I am a co-author of that document.</li></ol>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/what-we-learned-auditing-sophisticated-ai-for-bias/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>The Collaborative Metaverse</title>
		<link>https://www.oreilly.com/radar/the-collaborative-metaverse/</link>
				<comments>https://www.oreilly.com/radar/the-collaborative-metaverse/#respond</comments>
				<pubDate>Wed, 12 Oct 2022 20:01:45 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[Metaverse]]></category>
		<category><![CDATA[Virtual Reality]]></category>
		<category><![CDATA[Commentary]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14750</guid>
				<description><![CDATA[We want to congratulate Dylan Field on his startup Figma, which Adobe recently purchased for $20B. Dylan started his career with O&#8217;Reilly Media when he was in high school—not that long ago. With Figma, he&#8217;s made the big time. It&#8217;s worth thinking about why Figma has been so successful, and why Adobe was willing to [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>We want to congratulate Dylan Field on his startup Figma, which Adobe recently purchased for $20B. Dylan started his career with O&#8217;Reilly Media when he was in high school—not that long ago. With Figma, he&#8217;s made the big time.</p>



<p>It&#8217;s worth thinking about why Figma has been so successful, and why Adobe was willing to pay so much for it. Since the beginning, Figma has been about collaboration. Yes, it was a great design tool. Yes, it ran completely in the browser, no downloads and installation required. But more than anything else, Figma was a tool for collaboration. That was a goal from the beginning. Collaboration wasn&#8217;t an afterthought; it was baked in.</p>



<p>My thesis about the Metaverse is that it is, above all, about enabling collaboration. VR goggles and AR glasses? Fine, but the Metaverse will fail if it only works for those who want to wear a headset. Crypto? I strongly object to the idea that everything needs to be owned—and that every transaction needs to pay a tax to anonymous middlemen (whether they&#8217;re called miners or stakers). Finally, I think that Facebook/Meta, Microsoft, and others who say that the Metaverse is about &#8220;better meetings” are just plain headed in the wrong direction. I can tell you—anyone in this industry can tell you—that we don&#8217;t need better meetings, we need fewer meetings.</p>



<p>But we still need people working together, particularly as more and more of us are working remotely. So the real question facing us is: how do we minimize meetings, while enabling people to work together? Meetings are, after all, a tool for coordinating people, for transferring information in groups, for circulating ideas outside of one-to-one conversations. They’re a tool for collaboration. That&#8217;s precisely what tools like Figma are for: enabling designers to work together on a project conveniently, without conflicting with each other. They&#8217;re about demonstrating designs to managers and other stakeholders. They&#8217;re about brainstorming new ideas (with Figjam) with your team members. And they&#8217;re about doing all this without requiring people to get together in a conference room, in Zoom, or in any of the other conferencing services. The problem with those tools isn&#8217;t really the flat screen, the &#8220;Brady Bunch&#8221; design, or the absence of avatars; the problem is that you still have to interrupt some number of people and get them in the same (virtual) place at the same time, breaking whatever flow that they were in.</p>



<p>We don&#8217;t need better meetings; we need better tools for collaboration so that we don&#8217;t need as many meetings. That&#8217;s what the Metaverse means for businesses. Tools like GitHub and Google’s Colab are really about collaboration, as are Google Docs and Microsoft Office 365. The Metaverse is strongly associated with gaming, and if you look at games like Overwatch and Fortnite, and you&#8217;ll see that those games are really about collaboration between online players. That&#8217;s what makes these games fun. I&#8217;ve got nothing against VR goggles, but what makes the experience special is the interaction with other players in real time. You don’t need goggles for that.</p>



<p>Collaboration made Figma worth $20B. It&#8217;s one of the first &#8220;enterprise Metaverse&#8221; applications. It certainly won&#8217;t be the last. Congratulations again to the team at Figma, and to our alumnus Dylan. And congratulations to Adobe, for realizing Figma&#8217;s importance.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/the-collaborative-metaverse/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>What Is Hyperautomation?</title>
		<link>https://www.oreilly.com/radar/what-is-hyperautomation/</link>
				<comments>https://www.oreilly.com/radar/what-is-hyperautomation/#respond</comments>
				<pubDate>Tue, 11 Oct 2022 10:59:21 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[AI & ML]]></category>
		<category><![CDATA[Research]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14733</guid>
				<description><![CDATA[Gartner has anointed “Hyperautomation” one of the top 10 trends for 2022. Should it be? Is it a real trend, or just a collection of buzzwords? As a trend, it’s not performing well on Google; it shows little long-term growth, if any, and gets nowhere near as many searches as terms like “Observability” and “Generative [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>Gartner has anointed “Hyperautomation” one of the top 10 trends for 2022. Should it be? Is it a real trend, or just a collection of buzzwords? As a trend, it’s not performing well on Google; it shows little long-term growth, if any, and gets nowhere near as many searches as terms like “Observability” and “Generative Adversarial Networks.” And it’s never bubbled up far enough into our consciousness to make it into our monthly Trends piece. As a trend, we’re openly skeptical about Hyperautomation.</p>



<p>However, that skeptical conclusion is too simplistic. Hyperautomation may just be another ploy in the game of buzzword bingo, but we need to look behind the game to discover what’s important. There seems to be broad agreement that hyperautomation is the combination of Robotic Process Automation with AI. Natural language generation and natural language understanding are frequently mentioned, too, but they’re subsumed under AI. So is optical character recognition (OCR)–something that’s old hat now, but is one of the first successful applications of AI. Using AI to discover tasks that can be automated also comes up frequently. While we don’t find the multiplication of buzzwords endearing, it’s hard to argue that adding AI to anything is uninteresting–and specifically adding AI to automation.</p>



<p>It’s also hard to argue against the idea that we’ll see more automation in the future than we see now.&nbsp; We’ll see it in the processing of the thousands of documents businesses handle every day. We’ll see it in customer service. We’ll see it in compliance. We’ll see it in healthcare. We’ll see it in banking. Several years ago, the “Automate all the things!” meme originated in IT’s transformation from manual system administration to automated configuration management and software deployment. That may be the first instance of what’s now been christened Hyperautomation. We can certainly apply the slogan to many, if not all, clerical tasks–and even to the automation process itself. “Automate all the things” is itself a thing. And yes, the meme was always partially ironic–so we should be on the lookout for promises that are easily made but hard to keep.&nbsp;Some tasks should not be automated; some tasks could be automated, but the company has insufficient data to do a good job; some tasks can be automated easily, but would benefit from being redesigned first.</p>



<p>So we’re skeptical about the term Hyperautomation, but we’re not skeptical about the desire to automate. A new buzzword may put automation on executives’ radar–or it may be little more than a technique for rebranding older products. The difference is focusing on your business needs, rather than the sales pitch. Automating routine office tasks is an important and worthwhile project–and redesigning routine tasks so that they can be integrated into a larger workflow that can be automated more effectively is even more important. Setting aside the buzzword, we can start by asking what a successful automation project requires. In the long run, the buzzword is unimportant; getting the job done is what matters.</p>



<h3>Automating Office Processes</h3>



<p>It’s easy to observe that in most companies, there are many processes that can be automated but aren’t. Processing invoices, managing inventory, customer service, handling loan applications, taking orders, billing customers: these are all processes that are largely routine and open to automation. At some companies, these tasks are already automated, at least in part. But I don’t want to trivialize the thinking that goes into automating a process. What’s required?</p>



<p>Office staff usually perform tasks like invoice processing by filling in a web form. Automating this process is simple. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Selenium_(software)" target="_blank">Selenium</a>, the first tool for automated browser testing (2004), could be programmed to find fields on a web page, click on them or insert text, click “submit,” scrape the resulting web page, and collect results. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Robotic_process_automation" target="_blank">Robotic process automation</a> (RPA) has a fancier name, but that’s really all it is. This kind of automation predates modern AI. It’s purely rules-based: click here, add a name there, use some fairly simple logic to fill in the other fields, and click submit. It’s possible to augment this basic process with OCR so the application can find data on paper forms, or to use natural language processing to gather information through a chat server. But the core of the process is simple, and hasn’t changed much since the early days of web testing. We could see it as an example of 1980s-style “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Expert_system" target="_blank">expert systems</a>,” based on deterministic business rules.</p>



<p>That simple scenario doesn’t hold up for more complex tasks. Consider an application for filling a prescription at a pharmacy. That application has to:</p>



<ul><li>look up when the prescription was last filled</li><li>look up patient data to see whether there are any refills left</li><li>look up the prescriber and generate a message, if there are no refills left</li><li>look up the patient’s other medications to determine whether there are any drug interactions</li><li>look up regulations about restricted substances, in which case other rules apply (for example, requiring ID when the patient picks up the medication)</li><li>look up the pharmacy’s stock to see whether the medication is in stock (and order it if it isn’t)</li><li>look up the patient’s insurance to generate charges for the insurance company&nbsp;</li><li>look up the patient’s credit card information to generate a charge for the co-pay</li></ul>



<p>There are probably even more steps (I am not a pharmacist) and variations: new prescriptions, expired prescriptions, uninsured patients, expired credit cards, and no doubt many more corner cases. None of these steps is particularly difficult by itself, and each could be viewed as a separate task for automation, giving you a web of interconnected tasks–more complex, but not necessarily a bad result. However, one thing should be obvious: to fill a prescription, you need to access many different kinds of data, in many different databases. Some of these data sources will be owned by the pharmacy; others aren’t. Most are subject to privacy regulations. They are all likely to exist in some kind of silo that’s difficult to access from the outside the group that created the silo–and the reason for that difficulty may be political as well as technological.&nbsp;So from the start, we have a data integration problem compounded with a compliance problem. Data integration and regulatory compliance are particularly tough in healthcare and medicine, but don’t kid yourself: if you’re working with data, you will face integration problems, and if you’re working with personal data, you need to think about compliance. An AI project that doesn’t address data integration and governance (including compliance) is bound to fail, regardless of how good your AI technology might be. Buzzword or not, Hyperautomation is doing a service if it focuses attention on these issues.</p>



<p>Data integration problems aren’t pretty; they’re boring, uninteresting, the “killing field of any modeling project,” as Lorien Pratt has said. So we really can’t talk about automating any significant task without seeing it as a non-trivial data integration project: matching IDs, reconciling slightly different definitions of database columns, de-duping, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Named-entity_recognition" target="_blank">named entity recognition</a>, all of that fun stuff. Some of these tasks have been automated, but many aren’t. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://mitsloan.mit.edu/ideas-made-to-matter/why-its-time-data-centric-artificial-intelligence" target="_blank">Andrew Ng</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://learning.oreilly.com/videos/artificial-intelligence-conference/9781492050544/9781492050544-video324795/" target="_blank">Christopher Ré</a>, and others have pointed out that in the past decade, we’ve made a lot of progress with algorithms and hardware for running AI. Our current set of AI algorithms are good enough, as is our hardware; the hard problems are all about data. That’s the cutting edge for AI research: automating ways to find quality data, clean it, label it, and merge it with data from other sources. While that research is only starting to filter into practice, and much remains to be done, “automating all the things” will require confronting data problems from the beginning.</p>



<p>Another sad reality is that a company’s data is less rich than they’d like to think. We don’t need to look any further than O’Reilly for an example. Like any online company, we have good visibility into what happens on the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://learning.oreilly.com/home/" target="_blank">O’Reilly Learning Platform</a>. We can see what books and courses our customers are using, and for how long. We know if customers only read the first chapter of some book, and can think about what how to improve it. The data available to our retail business is much more limited. We know we’ve sold X books to Amazon, and Y books to wholesalers, but we never know anything about the customers who buy those books, when they buy them, or even if they buy them. Books can sit on shelves or in warehouses for a long time before they come back as returns. The online business is information-rich; the retail business is information-poor. Most real-world business lie somewhere between those extremes.</p>



<p>That’s the bad news. The good news is that we’re talking about building something exciting. We’re talking about applications that use APIs to pull data from many different sources, and deliver better results than humans can. We’re talking about applications that integrate all of those sources into a single course of action, and can do so seamlessly. There are resonances between this and what, in other application domains, is being called a “metaverse.” While we’re skeptical about how the term “Hyperautomation” has been used, we also wonder: is Hyperautomation, considered properly, the business version of the metaverse? One component of a business metaverse would certainly be seamless access to data wherever it resides; the metaverse would be populated by bots that automate routine tasks. Hold that thought; we’ll return to it.</p>



<h3>Making Good Business Decisions</h3>



<p>Finding processes to automate is called process discovery. We have to be careful about process discovery because automating the wrong processes, or automating them in inappropriate ways, wastes resources at best; at worst, it can make a business uncompetitive. There are products that use AI to discover which processes can be automated, but in real life, process discovery will rely heavily on people: your knowledge of the business, the knowledge of subject matter experts, and the knowledge of staff members who are actually doing the work, and whose input is often ignored.&nbsp; I’m reminded of a friend who was hired to build a new application to check in patients at a doctor’s office. The receptionists hated the old app. No one knew why, until my friend insisted on sitting down at the receptionist’s desk. Then it was painfully obvious why the staff hated the old application–and the problem was easy to correct.</p>



<p>Over the past decade, one problem with data science and its successors has been the assumption that all you need is data, and lots of it; analyzing that data will lead you to new products, new processes, new strategies: just follow the data and let it transform your business. But we also know that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.infoworld.com/article/3639028/why-ai-investments-fail-to-deliver.html" target="_blank">most AI projects fail</a>, just as <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.cio.com/article/230427/why-it-projects-still-fail.html" target="_blank">most IT projects fail</a>. If you don’t want your projects to be among the failures, you can’t make naive assumptions about what data can do. All businesses like “up and to the right,” and data is good at revealing trends that look “up and to the right.” However, growth always ends: nothing grows exponentially forever, not even Facebook and Google. You’ll eventually run out of potential new customers, raw material, credit at the bank–something will get in the way. The historical trends revealed by data will eventually end. Data isn’t very good at telling you where the growth curve will flatten out, and for an executive, that’s probably the most important information. What will cause those trends to end, and what strategies will the business need to adopt? It is difficult to answer that kind of question with nothing but data.</p>



<p>Lorien Pratt outlines a four-step process for using data effectively to make business decisions:</p>



<ul><li>Understand the business outcomes that you want to achieve.</li><li>Understand the actions that you can take in your current business situation.</li><li>Map out the paths between actions and outcomes. If you take some action, what changes? Most actions have multiple effects.&nbsp;</li><li>Decide where data fits in. What data do you have? How can you use it to analyze your current situation, and measure the results of any actions you take?</li></ul>



<p>These four steps are the heart of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.lorienpratt.com/dihandbook/" target="_blank">decision intelligence</a>. It is a good process for any business decision, but it’s particularly important when you’re implementing automation. If you start from the data, rather than the business outcomes and the levers you can use to change the situation, you are likely to miss important possibilities. No dataset tells you the structure of the world; that requires human expertise and experience. You’ll find small, local optimizations, but you’re likely to miss important use cases if you don’t look at the larger picture. This leads to a “knowledge decision gap.” Pratt mentions the use of satellite imagery to analyze data relevant to climate change: predicting fires, floods, and other events. The models exist, and are potentially very useful; but on the ground, firefighters and others who respond to emergencies still use paper maps. They don&#8217;t have access to up to date maps and forecasts, which can show what roads can be used safely, and where severe damage has occurred. Data needs to become the means, a tool for making good decisions. It is not an end in itself.</p>



<p>Donald Farmer says something similar. It’s easy to look at some process (for example, invoice processing, or checking in patients) and decide to automate it. You analyze what your staff does to process an invoice, and then design a system to perform that process. You may use some process discovery tools to help. If the process you are automating requires making some simple decisions, AI can probably be used to automate those decisions. You will probably succeed, but this approach overlooks two big problems. First, many business processes are failing processes. They’re inefficient, poorly designed, and perhaps even wholly inappropriate for the task. Never assume that most businesses are well run, and that they represent some sort of “best practice.” If you automate a poor process, then all you have is a faster poor process. That may be an improvement, but even if it’s an improvement, it’s sure to be far from optimal.</p>



<p>Farmer’s second point is related, but goes much deeper. Business processes never exist in isolation. They connect to other processes in a complex web. That web of connected processes is really what makes the business work. Invoice processing has tendrils into accounting. Manufacturing affects quality control, customer support, finance, shipping and receiving, accounts receivable, and more. HR processes have effects throughout the organization. Redesigning one process might give you a local improvement, but rethinking how the business works is a much bigger opportunity.&nbsp; Farmer points to <a href="https://www.blackline.com/" target="_blank" rel="noreferrer noopener" aria-label="Blackline (opens in a new tab)">Blackline</a>, a company that does process automation for financial services. They don’t automate a single process: they automate all of a client’s financial processes, with the result that all actions are processed immediately; the books are always closed. This kind of automation has huge consequences. You don’t have to wait for a few weeks after the end of a month (or quarter or year) to close the books and find out your results; you know the results continuously. As a result, your relationship to many important financial metrics changes. You always know your cash flow; you always know your credit line. Audits take on a completely different meaning because the business is always auditing itself. New strategies are possible because you have information that you’ve never had before.</p>



<p>Other areas of a company could be treated similarly. What would supply chain management be like if a company had constant, up-to-date information about inventory, manufacturing, new orders, and shipping? What would happen to product design, sales, and engineering if a constant digest of issues from customer service were available to them?</p>



<p>These changes sound like something that we’ve often talked about in software development: continuous integration and continuous delivery. Just as CI/CD requires IT departments to automate software deployment pipelines, continuous business processes come from automating–together–all of the processes that make businesses work. Rethinking the entirety of a business’s processes in order to gain new insights about the nature of the business, to change your relationship to critical measures like cash flow, and to automate the business’s core to make it more effective is indeed Hyperautomation. It’s all about integrating processes that couldn’t be integrated back when the processes were done by hand; that pattern recurs repeatedly as businesses transform themselves into digital businesses. Again, does this sound like a business Metaverse? After all, the consumer Metaverse is all about <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oreilly.com/radar/the-metaverse-is-not-a-place/" target="_blank">sharing immersive experience</a>. While automating business processes doesn’t require VR goggles, for an executive I can’t imagine anything more immersive than immediate, accurate knowledge of every aspect of a company’s business. That’s surely more important than taking a meeting with your bank’s 3D avatars.</p>



<p>This kind of automation doesn’t come from a superficial application of AI to some isolated business tasks. It’s all about deep integration of technology, people, and processes. Integration starts with a thorough understanding of a business’s goals, continues with an understanding of the actions you can take to change your situations, and ends with the development of data-driven tools to effect the changes you want to see. While AI tools can help discover processes that can be automated, AI tools can’t do this job alone. It can’t happen without subject matter experts. It requires collaboration between people who know your business well, the people who are actually performing those tasks, and the stakeholders–none of which have the entire picture. Nor can it be undertaken without addressing data integration problems head-on. For some problems, like pharmacy prescription application we’ve already touched on, data integration isn’t just another problem; it is the problem that dwarfs all other problems.</p>



<p>We also need to be aware of the dangers. On one hand, automating all of a company’s processes to make a single coherent whole sounds like a great idea. On the other hand, it sounds like the kind of massive boil-the-ocean IT project that’s almost certainly bound to fail, or remain forever unfinished. Is there a happy medium between automating a single process and embarking on an endless task? There has to be. Understand your business’s goals, understand what levers can affect your performance, understand where you can use data–and then start with a single process, but a process that you have understood in the broader context.&nbsp;Then don’t just build applications. Build services, and applications that work by using those services. Build an API that can integrate with other processes that you automate.&nbsp;When you build services, you make it easier to automate your other tasks, including tasks that involve customers and suppliers. This is how <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://gist.github.com/chitchcock/1281611" target="_blank">Jeff Bezos built</a> Amazon’s business empire.</p>



<h3>The Humans in the Loop</h3>



<p>Developers who are automating business systems have to determine where humans belong in the loop. This is a sensitive issue: many employees will be afraid of losing their jobs, being “replaced by a machine.” Despite talk about making jobs more interesting and challenging, it would be unrealistic to deny that many executives look at process automation and think about reducing headcount. Employees’ fears are real. Still, as of mid-2022, we remain in a job market where hiring is difficult, at any level, and if a business is going to grow, it needs the human resources to grow. Automating processes to make decisions in routine situations can be a way to do more without adding staff: if pharmacy employees can rely on an automated process to look up drug interactions, regulations, and medical records, in addition to managing the insurance process, they are free to take on more important or more difficult tasks.</p>



<p>Making jobs more challenging (or difficult) can be a double-edged sword. While many people in the automation industry talk about “relieving staff of boring, routine tasks,” they often aren’t familiar with the realities of clerical work. Boring, routine tasks are indeed boring and routine, but few people want to spend all their time wrestling with difficult, complex tasks. Everybody likes an “easy win,” and few people want an environment where they’re constantly challenged and facing difficulties–if nothing else, they’ll end up approaching every new task when they’re tired and mentally exhausted. Tired and overstressed employees are less likely to make good decisions, and more likely to think “what’s the easiest way to get this decision off of my desk.” The question of how to balance employees’ work experiences, giving them both the “easy wins,” but enabling them to handle the more challenging cases hasn’t been resolved. We haven’t seen an answer to this question–for the time, it’s important to recognize that it’s a real issue that can’t be ignored.</p>



<p>It’s also very easy to talk about “human in the loop” without talking about where, exactly, the human fits in the loop. Designing the loop needs to be part of the automation plan. Do we want humans evaluating and approving all the AI system’s decisions?&nbsp; That begs the question of exactly what, or why, we’re automating. That kind of loop might be somewhat more efficient, because software would look up information and fill in forms automatically. But the gain in efficiency would be relatively small. Even if they didn’t need to spend time looking up information, an office worker would still need to understand each case. We want systems that implement end-to-end automation, as much as possible. We need employees to remain in the loop, but their role may not be making individual decisions. Human employees need to monitor the system’s behavior to ensure that it is working effectively. For some decisions, AI may only play an advisory role: a human may use AI to run a number of simulations, look at possible outcomes, and then make set a policy or execute some action. Humans aren’t managed by the machine; it’s the other way around. Humans need to understand the context of decisions, and improve the system’s ability to make good decisions.</p>



<p>If we want to leave as many decisions as possible to the system, what roles do we want humans to have? Why do we want humans in the loop? What should they be doing?</p>



<ul><li>Humans need to manage and improve the system</li><li>Humans need to investigate and rectify bad decisions</li></ul>



<p>Neither role is trivial or simple. “Managing and improving the system” encompasses a lot, ranging from automating new tasks to improving the system’s performance on current tasks. All AI models have a finite lifetime; at some point, their behavior won’t reflect the “real world,” possibly because the system itself has changed the way the real world behaves. Models are also subject to bias; they are built from historical data, and historical data almost never reflects our ideals of fairness and justice.&nbsp; Therefore, managing and improving the system includes careful monitoring, understanding and evaluating data sources, and handling the data integration problems that result. We’re talking about a job that’s much more technical than a typical clerical position.</p>



<p>This understanding of the “human in the loop” suggests a user interface that’s more like a dashboard than a web form. People in this role will&nbsp; need to know how the system is operating on many levels, ranging from basic performance (which could be measured in actions per second, time taken to generate and communicate an action), to aggregate statistics about decisions (how many users are clicking on recommended products), to real-time auditing of the quality of the decisions (are they fair or biased, and if biased, in what way).</p>



<p>Likewise, all decision-making processes are going to produce bad decisions from time to time.&nbsp;For better or for worse, that’s baked into the foundations of AI. (And as humans, we can’t claim that we don’t also make bad decisions.) Those bad decisions will range from simple misdiagnoses, poor recommendations, and errors to subtle examples of bias. We can’t make the mistake of assuming that an automated decision will always be correct. It’s possible that automated decision-making will be&nbsp; an improvement over human decision-making; but bad decisions will still be made. The good news is that, at least in principle, AI systems are auditable. We know exactly what decisions were made, we know the data that the system used.</p>



<p>We can also ask an AI system to explain itself, although explainability is still an area of active research. We need explanations for two reasons. Staff will need to explain decisions to customers: people have never liked the feeling that they are interacting with a machine, and while that preference might change, “that’s what the computer said” will never be a satisfactory explanation. The system’s explanation of its decisions needs to be concise and intelligible. Saying that a loan applicant was on the wrong side of some abstract boundary in a high-dimensional space won’t do it; a list of three or four factors that affected the decision will satisfy many users. A loan applicant needs to know that they don’t have sufficient income, that they have a poor credit history, or that the item they want to purchase is overpriced. Once that reasoning is on the table, it’s possible to move forward and ask whether the automated system was incorrect, and from there, to change the decision. We can’t let automation become another way for management to “blame the computer” and avoid accountability.</p>



<p>Improving the system so that it gives better results requires a more technical explanation. Is the system too sensitive to certain factors? Was it trained using biased, unfair data? Is it inferring qualities like gender or ethnicity from other data? Relatively simple tests, like higher error rates for minority groups, are often a sign of bias. Data is always historical, and history doesn’t score very well on fairness. Fairness is almost always aspirational: something we want to characterize the decisions we’re making now and in the future. Generating fair results from biased data is still a subject for research, but again, we have an important advantage: decisions made by machines are auditable.</p>



<p>To override an automated decision, we need to consider interfaces for performing two different tasks: correcting the action, and preventing the incorrect action from being taken again. The first might be a simple web form that overrides the original decision–no matter how hard we try to automate “simple web forms” out of existence, they have a way of returning. The second needs to feed back into the metrics and dashboards for monitoring the system’s behavior. Is retraining needed? Is special-purpose training to fine-tune a model’s behavior an option?</p>



<p>Although re-training an AI system can be expensive, and auditing training data is a big project, they’re necessary, and have to be part of the plan. Even when there are no egregious errors, models need to be retrained to remain relevant. For example, fashion recommendations from a model that hasn’t been retrained in a year are not likely to be relevant.</p>



<p>Another problem with interfaces between humans and AI systems arises when we position the system as an “oracle”: a voice of truth that provides “the right answer.” We haven’t yet developed user interfaces that allow users to discuss or argue with a computer; users can’t question authority.&nbsp; (Such interfaces might grow out of the work on large language models that’s being done by Google, Facebook, OpenAI, HuggingFace, and others.) Think about a diagnostic system in a doctor’s office. The system might look at a photo of a patient’s rash and say “That’s poison ivy.” So can a doctor or a nurse, and they’re likely to say “I didn’t need an expensive machine to tell me that,” even if the machine allows them to treat more patients in an hour. But there’s a deeper problem: what happens if that diagnosis (whether human or automated) is wrong? What if, after treatment, the patient returns with the same rash? You can’t give the same diagnosis again.</p>



<p>Shortly after IBM’s Watson won Jeopardy, I was invited to a demonstration at their lab. It included a short game (played against IBM employees), but what interested me the most was when they showed what happened when Watson gave an incorrect answer. They showed the last five alternatives, from which Watson chose its answer. This level wasn’t just a list: it included pros and cons for each answer under consideration, along with the estimated probability that each answer was correct. Choose the highest probability and you have an “oracle.” But if the oracle is wrong, the most useful information will be on the layer with the rejected answers: the other answers that might have been correct. That information could help the doctor whose patient returns because their poison ivy was actually a strange food allergy: a list of other possibilities, along with questions to ask that might lead to a resolution. Our insistence on AI systems as oracles, rather than knowledgeable assistants, has prevented us from developing user interfaces that support collaboration and exploration between a computer and a human.</p>



<p>Automation isn’t about replacing humans; it’s about collaboration between humans and machines. One important area of research for the “office metaverse” will be rethinking user interface designs for AI systems. We will need better dashboards for monitoring the performance of our automation systems; we’ll need interfaces that help workers research and explore ambiguous areas; and we probably won’t get away from filling in web forms, though if automation can handle all the simple cases, that may be all right.</p>



<h3>Putting It All Together</h3>



<p>Hyperautomation may or may not be the biggest technology trend of 2022. That game of buzzword bingo is unimportant. But “automating all the things”–that’s sure to be on every senior manager’s mind. As you head in this direction, here are some things to keep in mind:</p>



<ul><li>Businesses are complex systems. While you should start with some simple automation tasks, remember that these simple tasks are components of these larger systems. Don’t just automate poor processes; take the opportunity to understand what you are doing and why you are doing it, and redesign your business accordingly.</li><li>Humans must always be in the loop. Their (our) primary role shouldn’t be to accept or reject automated decisions, but to understand where the system is succeeding and failing, and to help it to improve.&nbsp;</li><li>The most important function of the “human in the loop” is accountability. If a machine makes a bad decision, who is accountable and who has the authority to rectify it?</li><li>Answers and decisions don’t arise magically out of the data. Start by understanding the business problems you are trying to solve, the actions that will have an influence on those problems, and then look at the data you can bring to bear.</li><li>Companies marketing AI solutions focus on the technology.&nbsp; But the technology is useless without good data–and most businesses aren’t as data-rich as they think they are. </li></ul>



<p>If you keep these ideas in mind, you’ll be in good shape. AI isn’t magic. Automation isn’t magic. They’re tools, means to an end–but that end can be reinventing your business. The industry has talked about digital transformation for a long time, but few companies have really done it. This is your opportunity to start.</p>



<hr class="wp-block-separator" />



<p>Special thanks to Jennifer Stirrup, Lorien Pratt, and Donald Farmer, for conversations about Hyperautomation, Decision Intelligence, and automating business decisions.&nbsp;Without them, this article wouldn’t have been possible. All three have upcoming books from O’Reilly. Donald Farmer’s <a href="https://learning.oreilly.com/library/view/embedded-analytics/9781098120924/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Embedded Analytics</a> is currently available in Early Release, and Lorien Pratt has a preview of <a href="https://www.lorienpratt.com/dihandbook/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">The Decision Intelligence Handbook</a> on her website.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/what-is-hyperautomation/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>Radar Trends to Watch: October 2022</title>
		<link>https://www.oreilly.com/radar/radar-trends-to-watch-october-2022/</link>
				<comments>https://www.oreilly.com/radar/radar-trends-to-watch-october-2022/#respond</comments>
				<pubDate>Tue, 04 Oct 2022 11:15:42 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[Radar Trends]]></category>
		<category><![CDATA[Signals]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14726</guid>
				<description><![CDATA[September was a busy month. In addition to continued fascination over art generation with DALL-E and friends, and the questions they pose for intellectual property, we see interesting things happening with machine learning for low-powered processors: using attention, mechanisms, along with a new microcontroller that can run for a week on a single AA battery. [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>September was a busy month. In addition to continued fascination over art generation with DALL-E and friends, and the questions they pose for intellectual property, we see interesting things happening with machine learning for low-powered processors: using attention, mechanisms, along with a new microcontroller that can run for a week on a single AA battery. In other parts of the technical universe, “platform engineering” has been proposed as an alternative to both DevOps and SRE. We’ve seen demonstrations of SQL injection-like attacks against GPT-3; and companies including Starbucks, Chipotle, and Universal Studios are offering NFT-based loyalty programs. (In addition to a Chipotle’s steak grilling demo in the Metaverse.)</p>



<h2>Artificial Intelligence</h2>



<ul><li>Facebook/Meta ups the ante on AI-generated images: they have a system that creates short <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://ai.facebook.com/blog/generative-ai-text-to-video/" target="_blank">videos from a natural language description</a>.&nbsp; Videos are currently limited to five seconds. It isn’t <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://makeavideo.studio/" target="_blank">open to the public.</a></li><li>Transformers, which have a key to the progress in natural language processing, are now being <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arxiv.org/abs/2204.07118" target="_blank">adapted for work in computer vision</a>, displaying convolutional neural networks.</li><li>A group of researchers are talking about bringing <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://bdtechtalks.com/2022/09/26/self-attention-tinyml/" target="_blank">attention mechanisms</a> to resource-constrained TinyML applications. Attention mechanisms are the central innovation that led to language tools like GPT-3. Low power attention could revolutionize embedded AI applications.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenextweb.com/news/common-sense-test-for-ai-smarter-machines" target="_blank">AGENT</a> is a new benchmark for “common sense” in AI. It consists of a series of 3D animations. An AI model has to rate the videos as “surprising” or “expected.” To score highly, the model needs to demonstrate a human-like ability to plan, in addition to understanding concepts like basic physics.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://openai.com/blog/whisper/" target="_blank">Whisper</a> is a new speech-to-text AI model from OpenAI. Its accuracy is impressive and, unlike other OpenAI products, it is open source.</li><li>Google’s Sparrow is an <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/09/22/1059922/deepminds-new-chatbot-uses-google-searches-plus-humans-to-give-better-answers/" target="_blank">experimental AI chatbot that has been trained not to generate “dangerous” replies</a> (ranging from hate speech to financial advice and claims of sentience). It is far from perfect, but it appears to be a significant improvement over current chat technology.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://haveibeentrained.com/" target="_blank">Have I been trained</a> is a web application that searches for specific images in the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://laion.ai/blog/laion-5b/" target="_blank">LAION-5B</a> data set, which was used to train several image generation models. You can search using images or text. It’s useful for discovering whether your artwork or photos were used in training.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/09/artists-begin-selling-ai-generated-artwork-on-stock-photography-websites/#p3" target="_blank">Art generated by AI tools</a> like Midjourney and Stable Diffusion is starting to appear on stock photography web sites. Getty Images has <a href="https://arstechnica.com/information-technology/2022/09/fearing-copyright-issues-getty-images-bans-ai-generated-artwork/">banned</a> AI-generated content because they are concerned about copyright violations.</li><li>A new model for analyzing chest x-ray images <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/09/15/1059541/ai-medical-notes-teach-itself-spot-disease-chest-x-rays/" target="_blank">learns from natural language medical reports</a> written when the image was taken, rather than images labeled after the fact. Its accuracy is roughly equivalent to human radiologists.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-09-advancing-human-like-perception-self-driving-vehicles.html" target="_blank">Amodal panoptic segmentation</a> is a new vision algorithm that allows systems to identify objects that are partially obscured by objects in front. This could be an important technology for improving autonomous vehicles’ ability to identify pedestrians successfully.</li><li>Huggingface has released a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/huggingface/diffusers" target="_blank">toolkit for building diffusion models</a>. Diffusion models are the technology used by DALL-E, Stable Diffusion, and other AI tools that build images through random processes.</li><li>English is the dominant language for AI research, and that inevitably introduces bias into models. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-09-english-bias-images.html" target="_blank">IGLUE</a> (Image-Grounded Language Understanding Evaluation) is a benchmark that tests an AI system’s performance in 20 different languages, and includes culture-specific images.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://promptbase.com/" target="_blank">PromptBase</a> is a secondary market where you can buy and sell prompts for machine learning systems. They’re currently soliciting prompts for DALL-E, Midjourney, Stable Diffusion, and GPT-3. This world is developing very quickly.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://huggingface.co/spaces/shaneweisz/AutoCounterspeech" target="_blank">AutoCounterspeech</a> is a language model that generates appropriate replies that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://theconversation.com/metas-ai-chatbot-hates-mark-zuckerberg-but-why-is-it-less-bothered-about-racism-189657" target="_blank">confront and contest hate speech</a>. It’s another example of a large language that has been adapted for a specific purpose with specialized training.</li><li>Simon Willison and Andy Baio have created a tool to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://waxy.org/2022/08/exploring-12-million-of-the-images-used-to-train-stable-diffusions-image-generator/" target="_blank">explore 12 billion of the images</a> used to train the Stable Diffusion image generator.&nbsp;Their results are fascinating.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenextweb.com/news/intel-unveils-neuromorphic-approach-to-interactive-continual-learning-robots" target="_blank">Neuromorphic computing</a>, which is based on specialized chips that emulate human neurons, is better at identifying objects than traditional neural networks, and uses much less power.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/08/31/1058800/what-does-gpt-3-know-about-me/" target="_blank">What does GPT-3 know about you?</a> Possibly quite a lot; much of it may be incorrect; and some of it could be damaging (for example, being linked to “terror”).</li><li>A teenager has built a tool that uses machine learning to <a href="https://www.smithsonianmag.com/innovation/this-teenager-invented-a-low-cost-tool-to-spot-elephant-poachers-in-real-time-180980522/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">detect elephants and humans in real time</a> from infrared images taken by drones. This could be invaluable in preventing poaching.</li></ul>



<h2>Programming</h2>



<ul><li>Stephen O’Grady’s article on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://redmonk.com/sogrady/2022/09/23/dead-end/" target="_blank">bait-and-switch open source licenses</a> is a must-read.</li><li>Is <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://platformengineering.org/blog/what-is-platform-engineering" target="_blank">platform engineering</a> an <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/how-is-platform-engineering-different-from-devops-and-sre/" target="_blank">alternative to both DevOps and SRE</a>? Platform engineering is the discipline of “building toolchains and workflows that enable self-service capabilities for software engineering organizations in the cloud-native era.”</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://nbdev.fast.ai/" target="_blank">Nbdev2</a> lets <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.fast.ai/posts/2022-08-25-jupyter-git.html" target="_blank">git and Jupyter notebooks</a> play well together, solving a major problem for collaboration with notebooks. Collaboration and version control no longer work at cross-purposes.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://tauri.app/" target="_blank">Tauri</a> is a Rust-based framework for building desktop apps. It is conceptually <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://betterprogramming.pub/adi%C3%B3s-electron-a-rust-powered-alternative-has-arrived-and-its-lovely-bd26262dcf1a" target="_blank">similar to Electron</a>, but uses Rust for the backend, and generates much smaller executable files.</li><li>For those who don’t get along with IDEs, here’s a quick HowTo about running Github <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/maxwell-bland/copilot-in-the-terminal" target="_blank">Copilot in the terminal</a> with Vim. Has anyone done this with Emacs?</li><li>Bryan Cantrill on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/bryan-cantrill-on-rust-and-the-future-of-low-latency-systems/" target="_blank">Rust and the future of low latency embedded systems</a>: Rust is the first language since C to live at the border between hardware and software.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://explainshell.com/" target="_blank">Explainshell</a> looks up the documentation for every command and its arguments on a bash shell command line. Clever. </li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://horovits.medium.com/http-s-new-method-for-data-apis-http-query-1ff71e6f73f3" target="_blank">HTTP QUERY</a> is a new method that has been added to HTTP to support building APIs. QUERY requests are safe; they never alter the resource being queried. The query is placed in the payload of the request, rather than the URI. And responses from a QUERY are cacheable.</li><li>Fuzzing is a powerful testing technique; it means watching how the software under test handles random data. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/status-im/nim-drchaos" target="_blank">Dr. Chaos</a> is a new fuzzing framework for C, C++, and Objective-C.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/trace-based-testing-the-next-step-in-observability/" target="_blank">Trace-based testing</a> is the next step forward in observability. It means using data from tests run during software development in operations, to determine exactly what kinds of events can occur and how.</li></ul>



<h2>Security</h2>



<ul><li>Software supply chain security is more important than ever; Microsoft <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/microsoft-lazarus-hackers-are-weaponizing-open-source-software/" target="_blank">claims</a> that the Lazurus cybercrime group, which is sponsored by North Korea, is adding backdoors to many widely used Open Source programs and libraries.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/09/never-before-seen-malware-has-infected-hundreds-of-linux-and-windows-devices/" target="_blank">Chaos</a> is new malware that can infect both Windows and Linux devices, including routers, firewalls, and other networking hardware. It is spreading in the wild; it propagates by taking advantage of known vulnerabilities.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://simonwillison.net/2022/Sep/12/prompt-injection/" target="_blank">Prompt injection attacks against GPT-3</a>: Simon Willison demonstrates a new security threat that is similar to SQL injection. This will be an issue for GPT-3 applications that combine prompts from untrusted users with prompts that are generated by the application.</li><li>The Atlantic Council has published a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.atlanticcouncil.org/in-depth-research-reports/report/security-in-the-billions/" target="_blank">report</a> describing an international strategy for securing the Internet of Things. The report is based on case studies in the US, UK, and APAC, and focuses on smart homes, networking, and telecommunications.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/domain-shadowing-becoming-more-popular-among-cybercriminals/" target="_blank">Domain shadowing</a>, in which a criminal group hijacks a DNS server to insert its own domains under the legitimate domains, without modifying the legitimate domains, is becoming an increasingly important threat.</li><li>An experiment demonstrating the danger of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenextweb.com/news/ai-stalks-instagram-influencers-to-expose-high-tech-surveillance" target="_blank">automated surveillance</a> showed that it was possible to find individuals and locations in Instagram photos using data feeds from cameras (both open and private) installed in public places.</li><li>The popularity of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/hackers-steal-steam-accounts-in-new-browser-in-the-browser-attacks/" target="_blank">browser-in-browser attacks</a>, in which a compromised site steals information by creating a fake browser within the active browser window, is rising.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-09-google-immersive-street-view-glimpse.html" target="_blank">Street View</a> gives Google a head start on building immersive experiences of different places. Is this a down payment on the Metaverse?</li><li>The LockBit ransomware group may be preparing to use <a href="https://www.bleepingcomputer.com/news/security/lockbit-ransomware-gang-gets-aggressive-with-triple-extortion-tactic/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">distributed denial of service (DDOS)</a> attacks as another form of extortion. They are also learning to defend themselves against ransomware victims who attack them with DDOS rather than paying.</li></ul>



<h2>Web3</h2>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://stories.starbucks.com/press/2022/starbucks-brewing-revolutionary-web3-experience-for-its-starbucks-rewards-members/" target="_blank">Starbucks</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nrn.com/fast-casual/chipotle-mexican-grill-debuts-menu-item-metaverse-first-time" target="_blank">Chipotle</a>, and even <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.theblock.co/post/171491/moonpay-universal-create-an-in-person-nft-based-scavenger-hunt-with-more-than-6-million-tokens" target="_blank">Universal Studios</a> have developed NFT-based <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://newsletter.blockandmortar.xyz/archive/of-loyalty-and-leadership-titles-4119/" target="_blank">loyalty programs</a>. Chipotle even has a simulated grilling experience, conducted in their Metaverse property.</li><li>Cryptocurrency can be used to pay taxes in <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-09-colorado-cryptocurrency-taxes-state-tech.html" target="_blank">Colorado</a>. Utah is set to follow.</li><li>Can Web3 be used as a tool to combat climate change? <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://avc.com/2022/09/regenerative-finance-refi/" target="_blank">Fred Wilson</a> points to efforts like <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blog.refidao.com/introducing-new-atlantis-on-gr15/" target="_blank">New Atlantis</a>, for marine biodiversity, and the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://toucan.earth/" target="_blank">Toucan Protocol</a>, a voluntary carbon market. Wilson’s thesis is that work against climate change will be crowd-funded.</li><li>Andreessen Horowitz has introduced a <a href="https://a16zcrypto.com/introducing-nft-licenses/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">“Don’t Be Evil” license for NFTs</a>, similar (in concept) to the Creative Commons licenses. There are six distinct kinds of license, including an “exclusive commercial rights” license and a “universal license”; some licenses provide automatic revocation for hate speech.</li></ul>



<h2>Metaverse</h2>



<ul><li>Some studies show that surgery patients who are given a virtual reality program to view during a procedure <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/09/21/1059869/patients-virtual-reality-surgery-anesthetic/" target="_blank">require less anaesthetic</a>. VR may also help in post-operative recovery.</li><li>A modeling agency is using <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.voguebusiness.com/technology/fashions-next-metaverse-opportunity-turning-real-models-into-digital-avatars" target="_blank">real models to create Metaverse avatars</a> for use in advertising. Faces are based on 3D photos; bodies are synthesized. The models are given unique voices and personalities. The avatars are sold as NFTs that expire after a given time.</li><li>Ethereum has made the transition to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/VitalikButerin/status/1570306185391378434" target="_blank">Proof of Stake</a>. PoS provides its own set of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/09/15/1059520/the-merge-is-here-ethereum-has-switched-to-proof-of-stake/" target="_blank">challenges</a>, but requires much less energy and should support significantly higher transaction rates. Nothing broke, the price of the major cryptocurrencies remained stable, and the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.tomshardware.com/news/gpu-mining-is-now-unprofitable" target="_blank">used equipment market is now flooded with GPUs</a>.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://medium.com/@unclefibonacci/the-father-of-the-metaverse-neal-stephenson-launches-the-metaverse-blockchain-3f4dbf1c0604" target="_blank">Neal Stephenson says that the Metaverse</a> will “start on the wrong foot” if it leaves behind people using 2D screens. In the 1990s, he didn’t forsee the sophistication of modern gaming, specifically the ability to navigate 3D spaces with 2D hardware. Stephenson is co-founding <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.lamina1.com/" target="_blank">Lamina1</a>, a company building a “base layer” for an Open Metaverse.</li><li>Roblox is developing avatars that can <a href="https://www.technologyreview.com/2022/09/09/1059135/robloxs-avatars-are-about-to-get-more-expressive/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">reflect their owners’ facial expressions</a> during game play in real time.</li></ul>



<h2>Quantum Computing</h2>



<ul><li>A new quantum algorithm computes the <a href="https://phys.org/news/2022-09-quantum-algorithm-critical-chemistry-problem.html" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">lowest energy states</a> for molecules during chemical reactions.</li></ul>



<h2>Biology</h2>



<ul><li>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/09/06/1059032/memory-prosthesis-damaged-brains/" target="_blank">memory prosthesis</a> might be able to restore memory to people with diseases like Alzheimer’s. The prosthesis generates signals that are similar to the signals that neurons create when creating or activating memories.</li><li>Manufacturers of high performance biomaterials, such as spider silk protein and mycelium, are <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.tsungxu.com/performance-biomaterials/" target="_blank">starting to scale up production</a>. Synthetic biology is becoming real.</li><li>A new genetic therapy attempts to <a href="https://www.technologyreview.com/2022/09/01/1058830/next-act-antibody-cells-new-form-of-gene-therapy/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">design human B cells</a>, the cells that make antibodies, to target rare diseases by manufacturing missing enzymes.</li></ul>



<h2>Hardware</h2>



<ul><li>The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.maximintegrated.com/en/products/microcontrollers/MAX78002.html" target="_blank">MAX78002</a> is a low power microcontroller designed for running neural networks in edge computing applications. There are claims that it can <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://towardsdatascience.com/how-to-run-a-deep-neural-network-on-a-aa-battery-for-a-week-75ac6247198e" target="_blank">run for a week on a single AA battery</a>.&nbsp;It has 64 parallel processors and can run a network with up to 3.5 million parameters.</li><li>The Chinese are planning to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/science/2022/08/chinese-propose-to-build-a-dam-with-a-distributed-3d-printer/" target="_blank">build a dam with a distributed 3D printer</a>, using no direct human labor. There’s arguably no printer at all; the work is done by AI-controlled robots that pour the concrete and roll it out in layers.</li><li>NVidia has a new GPU chip with specialized hardware for <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/09/nvidias-flagship-ai-chip-reportedly-4-5x-faster-than-the-previous-champ/" target="_blank">training transformer models</a>. It is 4.5x faster than their previous high-performance data center GPU.</li><li>China has developed its own GPUs, the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nextplatform.com/2022/08/25/china-launches-the-inevitable-indigenous-gpu/" target="_blank">Biren 100 and Biren 104</a>. This will greatly reduce its dependence on NVidia for high performance computing hardware.</li><li><a href="https://www.latimes.com/opinion/story/2022-09-13/california-electric-grid-batteries-heat-wave-september-2022" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Battery power</a> played an important role in helping California’s electrical grid survive September’s heat wave without outages.</li></ul>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/radar-trends-to-watch-october-2022/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>The Problem with Intelligence</title>
		<link>https://www.oreilly.com/radar/the-problem-with-intelligence/</link>
				<comments>https://www.oreilly.com/radar/the-problem-with-intelligence/#respond</comments>
				<pubDate>Tue, 13 Sep 2022 11:21:40 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Commentary]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14718</guid>
				<description><![CDATA[Projects like OpenAI’s DALL-E and DeepMind’s Gato and LaMDA have stirred up many discussions of artificial general intelligence (AGI). These discussions tend not to go anywhere, largely because we don’t really know what intelligence is. We have some ideas–I’ve suggested that intelligence and consciousness are deeply connected to the ability to disobey, and others have [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>Projects like OpenAI’s DALL-E and DeepMind’s Gato and LaMDA have stirred up many discussions of artificial general intelligence (AGI). These discussions tend not to go anywhere, largely because we don’t really know what intelligence is. We have some ideas–I’ve suggested that intelligence and consciousness are deeply connected to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oreilly.com/radar/intelligence-and-comprehension/" target="_blank">the ability to disobey</a>, and others have suggested that intelligence can’t exist outside of embodiment (some sort of connection between the intelligence and the physical world). But we really don’t have a definition. We have a lot of partial definitions, all of which are bound to specific contexts.</p>



<p>For example, we often say that dogs are intelligent. But what do we mean by that? Some dogs, like sheep dogs, are very good at performing certain tasks. Most dogs can be trained to sit, fetch, and do other things. And they can disobey. The same is true of children, though we’d never compare a child’s intelligence to a dog’s. And cats won’t do any of those things, though we never refer to cats as unintelligent.</p>



<p>I’m very impressed with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://alexfoundation.org/about/dr-irene-pepperberg/" target="_blank">Irene Pepperberg’s work on parrot intelligence</a>. She’s shown that her parrots can have an understanding of numbers, can use language intelligently, and can even invent new vocabulary. (“Banerry” for apple, probably because birds don’t have lips and can’t say Ps very well. And apples look like giant cherries and taste like bananas, at least to parrots.) But I wonder if even this is getting the question wrong. (I think Dr. Pepperberg would agree.) We ask birds to be intelligent about things humans are intelligent about. We never ask humans to be intelligent about things birds are intelligent about: navigating in three-dimensional space, storing food for use during winter (a boreal chickadee will <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://knowablemagazine.org/article/mind/2019/chickadee-memory-food" target="_blank">store as many as 80,000 seeds</a> in different places, and remember where they’re all located), making use of the many colors birds see that we can’t (<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://academic.oup.com/bioscience/article/50/10/854/233996" target="_blank">their vision extends well into the ultraviolet</a>). It’s easy to imagine a bird thinking, “Those poor humans. They can’t find their home without taking out that strange little black box (which is actually colored octarine).”</p>



<p>In a similar vein, we often say that dolphins and elephants are intelligent, but it’s never clear what exactly we mean by that. We’ve demonstrated that dolphins can recognize patterns and that they recognize themselves in mirrors, and they’ve demonstrated a (limited) ability to communicate with humans, but their intelligence certainly goes much further. I wouldn’t be the least bit surprised if animals like dolphins had an oral literature. We penalize them on the intelligence scale because they don’t have hands and can’t pick up a pen. Likewise, some research shows that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.sciencedaily.com/releases/2012/08/120803103421.htm" target="_blank">elephants communicate</a> with each other using low frequency rumbles that can be heard for miles (if you’re an elephant). Information theory suggests that this communication can’t be fast, but that doesn’t mean that it can’t be rich.</p>



<p>Humans are intelligent. After all, we get to define what “intelligence” means. Controlling the definition of intelligence has always been a source of cultural and political power; just read anything written in America in the 19th century about the intelligence of women, Asians, Africans, or even the Irish and Italians. We have “intelligence tests” to measure intelligence–or do they just measure test-taking ability? We also talk about “emotional” and other kinds of intelligence. And we recognize that mathematical, linguistic, and artistic ability rarely go hand-in-hand. Our own view of our own intelligence is highly fractured, and often has more to do with pseudo-science than anything we could use as a metric in machine learning experiments. (Though GPT-3 and LaMDA are no doubt very good at taking tests.) </p>



<p>Finally, there’s also been a lot of talk recently about the possibility of discovering life on other planets. Life is one thing, and my decidedly amateur opinion is that we will find life fairly common. However, to discover intelligent life, we would need a working definition of intelligence. The only useful definition I can imagine is “able to generate signals that can be received off planet and that are indisputably non-natural.” But by that definition, humans have only been intelligent for roughly 100 years, since the early days of radio. (I’m not convinced that the early electrical experiments from the 19th century and spark-based radio from the first two decades of the 20th century could be detected off planet.) There may be fantastically <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Life_on_Titan" target="_blank">intelligent creatures living under the ice covering Saturn’s moon Titan</a>, but we’ll never be able to detect them without going there. For Titan, a visit may be possible. For planets elsewhere in our galaxy, probably not.</p>



<p>Even more important: these definitions aren’t just different. They’re different in kind. We’re not saying that a parrot or a crow is intelligent if it scores 0.3 (on a scale of 0 to 1) on some test, but an autonomous vehicle has to score .99. The definitions aren’t remotely comparable. I don’t know what it would mean to ask GPT-3 about soaring on air currents. If we asked, we would get an answer, and quite likely a good one with a lot of information about aerodynamics, but would that have anything to do with an eagle’s understanding of flight? I could tell Gato to “sit,” but how would I know if it complied?</p>



<p>So what does this tell us about intelligence that’s artificial? Context is important; an appropriate definition of “intelligence” has to start with what we want the system to do. In some cases, that’s generating publishable papers and good PR. With natural language systems like GPT-3, we tend to ignore the fact that you often have to try several prompts to produce reasonable output. (Would we consider a human intelligent if they had to try 5 times to answer a question?) As has often been noted, systems like GPT-3 often get basic facts wrong. But humans often respond to prompts incoherently, and we frequently get our facts wrong.&nbsp; We get things wrong in different ways, and for different reasons; investigating those differences might reveal something about how our intelligence works, and might lead us to a better understanding of what an “artificial intelligence” might mean.</p>



<p>But without that investigation, our standard for intelligence is fairly loose. An AI system for making product recommendations can be successful even if most of the recommendations are wrong–just look at Amazon. (I’m not being ironic. If there are 10 recommendations and you’re interested in one of them, Amazon has won.) An AI system for an autonomous vehicle has to work to a much higher standard. So do many systems where safety isn’t an issue. We could happily talk about the “intelligence” of an AI chess engine that can beat the average human player, but a chess playing product that can only beat the average human and couldn’t play on a world championship level would be an embarrassment.</p>



<p>Which is just to say that intelligence, especially of the artificial sort, is many things. If you read <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.csee.umbc.edu/courses/471/papers/turing.pdf" target="_blank">Turing’s paper on the Imitation Game</a>, you’ll see quickly that Turing is more interested in the quality of the interaction than the correctness of the result. In his examples, the machine says that it’s not good at writing poetry; hesitates before giving answers; and even gets some results wrong. Turing’s thought experiment is more about whether a machine can behave like a human than about whether it can master many different disciplines. The word “intelligence” only appears once in the body of the paper, and then it refers to a human experimenter.</p>



<p>That leads me to a conclusion: Intelligence doesn’t have any single definition, and shouldn’t. Intelligence is always specific to the application.&nbsp; Intelligence for a search engine isn’t the same as intelligence for an autonomous vehicle, isn’t the same as intelligence for a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.youtube.com/watch?v=7Vsbb9JW05w" target="_blank">robotic bird</a>, isn’t the same as intelligence for a language model. And it certainly isn’t the same as the intelligence for humans or for our unknown colleagues on other planets.</p>



<p>If that’s true, then why are we talking about “general intelligence” at all?&nbsp; General intelligence assumes a single definition. Discarding the idea of a single unifying definition of “intelligence” doesn’t cost us much, and gains a lot: we are free to create definitions of “intelligence” that are appropriate to specific projects. When embarking on a new project, it’s always helpful to know exactly what you’re trying to achieve. This is great for practical, real-world engineering. And even big, expensive research projects like DALL-E, Gato, LaMDA, and GPT-3 are ultimately engineering projects. If you look beyond the link-bait claims about general intelligence, sentience, and the like, the computer scientists working on these projects are working against well-defined benchmarks. Whether these benchmarks have anything to do with “intelligence” isn’t relevant. They aren’t trying to create an artificial human, or even an artificial dog. (We’ll leave artificial dogs to <a href="https://en.wikipedia.org/wiki/Boston_Dynamics" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Boston Dynamics</a>.) They are trying–with considerable success–to extend the range of what computers can do. A model that can work successfully in over 600 different contexts is an important achievement. Whether or not that’s “general intelligence” (or intelligence at all) is a side show we don’t need.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/the-problem-with-intelligence/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>Radar Trends to Watch: September 2022</title>
		<link>https://www.oreilly.com/radar/radar-trends-to-watch-september-2022/</link>
				<comments>https://www.oreilly.com/radar/radar-trends-to-watch-september-2022/#respond</comments>
				<pubDate>Tue, 06 Sep 2022 11:21:09 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[Radar Trends]]></category>
		<category><![CDATA[Signals]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14700</guid>
				<description><![CDATA[It’s hardly news to talk about the AI developments of the last month. DALL-E is increasingly popular, and being used in production. Google has built a robot that incorporates a large language model so that it can respond to verbal requests. And we’ve seen a plausible argument that natural language models can be made to [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>It’s hardly news to talk about the AI developments of the last month. DALL-E is increasingly popular, and being used in production. Google has built a robot that incorporates a large language model so that it can respond to verbal requests. And we’ve seen a plausible argument that natural language models can be made to reflect human values, without raising the question of consciousness or sentience.</p>



<p>For the first time in a long time we’re talking about the Internet of Things. We’ve got a lot of robots, and Chicago is attempting to make a “smart city” that doesn’t facilitate surveillance. We’re also seeing a lot in biology. Can we make a real neural network from cultured neurons? The big question for biologists is how long it will take for any of their research to make it out of the lab.</p>



<h3>Artificial Intelligence</h3>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://stability.ai/blog/stable-diffusion-public-release" target="_blank">Stable Diffusion</a> is a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.artificialintelligence-news.com/2022/08/24/stable-diffusion-text-to-image-generator-now-publicly-available/" target="_blank">new text-to-image model</a> that has been designed to run on consumer GPUs. It has been released under a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://huggingface.co/spaces/CompVis/stable-diffusion-license" target="_blank">license</a> that is similar to permissive open source licenses, but has restrictions requiring the model to be used ethically.</li><li>Researches <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://petapixel.com/2022/08/23/mind-reading-technology-translate-brainwaves-into-photos/" target="_blank">claim</a> that they can use a neural network to <a href="https://www.nature.com/articles/s41598-021-03938-w">reconstruct images (specifically, faces) that humans are seeing</a>. They use fMRI to collect brain activity, and a neural decoding algorithm to turn that activity into images that are scarily similar to the photos the subjects were shown.</li><li><a href="https://arxiv.org/abs/2206.07682">Research</a> from Google and other institutions investigates the <a href="https://bdtechtalks.com/2022/08/22/llm-emergent-abilities/">emergent properties of large language models</a>: their ability to do things that can’t be predicted by scale alone.</li><li>DALL-E’s popularity is soaring and, like Copilot, it’s being adopted as a tool. It’s fun to play with, <a href="https://openai.com/blog/dall-e-now-available-in-beta">relatively inexpensive</a>, and it’s increasingly being used for projects like <a href="https://jacobmartins.com/posts/how-i-used-dalle2-to-generate-the-logo-for-octosql/">designing logos</a> and generating <a rel="noreferrer noopener" aria-label="thumbnail images (opens in a new tab)" href="https://deephaven.io/blog/2022/08/08/AI-generated-blog-thumbnails/" target="_blank">thumbnail images</a> for a blog.</li><li>Elon Musk has announced that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nzherald.co.nz/technology/elon-musk-says-his-tesla-bot-designed-to-eliminate-boring-household-chores-will-be-ready-in-2022/W2EYE3OSSVUVX45O4HTHKK5ETA/" target="_blank">Tesla will have a robot</a> capable of performing household chores by the end of 2022. That is almost certainly overly ambitious (and we hope it works better than his self-driving vehicles), but it’s no doubt coming.</li><li>Google has demonstrated a robot that can <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.wired.com/story/google-robot-learned-to-take-orders-by-scraping-the-web/" target="_blank">respond to verbal statements</a> (for example, bringing food when you say “I’m hungry”) without being trained on those specific statements; it uses a large language model to interpret the statement and determine a response.</li><li>Molecular modeling with deep learning has been used to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/08/11/1057623/deep-learning-predicts-ice-formation/" target="_blank">predict the way ice forms</a>. This can be very important for understanding weather patterns; the technique may be applicable to developing new kinds of materials.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/brain-js-brings-deep-learning-to-the-browser-and-node-js/" target="_blank">Brain.js is a deep learning library for JavaScript</a>, designed to run in the browser and using the computer’s GPU (if available).</li><li>Graph neural networks may be able to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-ai-future-firefighters.html" target="_blank">predict sudden flareups</a> in burning homes, the largest cause of death among firefighters.</li><li>While avoiding the question of whether language models are “intelligent,” Blaise Aguera y Arcas <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://medium.com/@blaisea/can-machines-learn-how-to-behave-42a02a57fadb" target="_blank">argues</a> that language models can be trained to reflect particular moral values and standards of behavior.</li><li>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/gadgets/2022/08/4k-webcam-uses-a-built-in-gimbal-to-follow-you-around-enable-gesture-controls/" target="_blank">webcam mounted on a 3-D gimbal</a> uses AI to automatically track moving objects. This could be a step towards making virtual reality less virtual.</li><li>A new political party in Denmark has policies determined entirely by AI. The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-danish-ai-driven-political-party-eyes.html" target="_blank">Synthetic Party</a> plans to run candidates for parliament in 2023.</li><li>One irony of AI work is that neural networks are designed by human intuition. Researchers are working on new <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/08/05/1056814/automation-ai-machine-learning-automl/" target="_blank">AutoML</a> systems that can quickly and efficiently design neural networks for specific tasks.</li><li>To succeed at deploying AI, AI developers need to understand and use <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/for-ai-to-succeed-mlops-needs-a-bridge-to-devops/" target="_blank">DevOps methods and tools</a>. </li><li>Cerebras, the company that released a gigantic (850,000 core) processor, claims their chip will <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://bdtechtalks.com/2022/08/01/cerebras-large-language-models/" target="_blank">democratize the hardware</a> needed to train and run very large language models by eliminating the need to distribute computation across thousands of smaller GPUs.</li><li>Large language models are <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://bdtechtalks.com/2022/06/27/large-language-models-logical-reasoning/" target="_blank">poor at planning and reasoning</a>. Although they have done well on “common sense” benchmarks, they fail at planning tasks requiring more than one or two steps and that can’t be solved by doing simple statistics on their training data. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://bdtechtalks.com/2022/07/25/large-language-models-cant-plan/" target="_blank">Better benchmarks</a> for planning and reasoning are needed to make progress.</li><li>A GPT-3 based application can <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.vice.com/en/article/epzx3m/in-experiment-ai-successfully-impersonates-famous-philosopher" target="_blank">answer philosophical questions</a> well enough to fool philosophers. The authors make it clear that the machine is not “thinking”; it was intended as an experiment to demonstrate the danger of automated plagiarism.</li><li>DoNotPay has built a tool that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.vice.com/en/article/y3ppgw/californians-can-now-auto-detect-racist-language-in-housing-deeds-hoa-rules-and-have-it-removed" target="_blank">finds racist language</a> in real estate documents, and automates the process of having it removed. Not very surprisingly, it quickly discovered that clauses preventing the sale of property to non-Whites are extremely common.</li><li>Researchers have developed <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-07-hardware-faster-artificial-intelligence-energy.html" target="_blank">analog “neurons”</a> that can build analog neural networks programmed similarly to digital neural networks. They are potentially much faster and require much less power.</li><li>A startup called Language I/O does <a href="https://thenewstack.io/language-i-o-runs-react-based-javascript-with-java-backend/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">machine translation by leveraging translations</a> from Google, Facebook, and Amazon, then uses AI to choose the best and fine-tune the result, using customer-supplied vocabularies with minimal training.</li></ul>



<h3>Programming</h3>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-automatic-device-driver-isolation-bugs.html" target="_blank">KSplit</a> is an automated framework for isolating operating system device drivers from each other and the OS kernel. Isolating device drivers is very difficult for human programmers, but greatly reduces vulnerabilities and bugs.</li><li>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.postman.com/state-of-api/" target="_blank">report on the API economy</a> says that one of the biggest obstacles is the lack of API design skills.</li><li>A bit of history comes back to life: An archive of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://whytheluckystiff.net/" target="_blank">everything written by why the lucky stiff</a> (aka _why) is now online. _why was a mainstay of the Ruby community in the early 2000s; he disappeared from the community and took all of his content offline when a reporter revealed his name. Well worth reading; maybe even well worth re-acquainting yourself with Ruby.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://semaphoreci.com/blog/javascript-bun" target="_blank">Bun</a> is a new JavaScript framework that aims to replace Node.js. It’s still early, and doesn’t yet support some important NPM packages. But it’s very fast, and (like Deno) implements Typescript.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/observability-is-shifting-left-following-security-and-ops/" target="_blank">Observability needs to “shift left”</a>: that is, become a primary concern of developers, in addition to operations. Most observability tools are oriented towards operations, rather than software development.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/mCaptcha/mCaptcha" target="_blank">mCaptcha</a> is a proof-of-work-based Captcha system that avoids any human interaction like identifying images. It imposes a small penalty on genuine users that actors who want to pound web sites at scale won’t be willing to pay.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.rstudio.com/blog/rstudio-is-becoming-posit/" target="_blank">RStudio is renaming itself Posit</a>. We don’t normally deal in corporate names, but this change is significant. Although R will remain a focus, RStudio has been looking beyond R; specifically, they’re interested in Python and their Jupyter-based <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://quarto.org/" target="_blank">Quarto</a> publishing system.</li><li>Google is releasing <a href="https://thenewstack.io/google-puts-open-source-in-chip-design-and-manufacturing/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">open source tools for designing chips</a>, and funding a program that allows developers to <a href="https://developers.google.com/silicon" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">have their custom designs built</a> at a fabrication facility. The goal is to jump-start an open source ecosystem for silicon.</li></ul>



<h3>Security</h3>



<ul><li>Zero trust adoption has soared in the past year. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.okta.com/blog/2022/08/state-of-zero-trust-report-2022-takeaways/" target="_blank">According to Okta</a>, 97% of the respondents to their recent “state of zero trust” survey say they have zero trust initiatives in place, or will have them within the next year.</li><li>An online tool named <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://krausefx.com/blog/announcing-inappbrowsercom-see-what-javascript-commands-get-executed-in-an-in-app-browser/" target="_blank">InAppBrowser</a> can <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/new-tool-checks-if-a-mobile-apps-browser-is-a-privacy-risk/" target="_blank">detect</a> whether the browsers that are built in to mobile apps can be used to inject JavaScript into sites you visit. This kind of JavaScript injection isn’t always dangerous, but is often used to inject tracking code.</li><li>Google blocked a distributed denial of service attack (DDOS) against one of its cloud customers that peaked at <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/google-blocks-largest-https-ddos-attack-reported-to-date/" target="_blank">26 million requests per second</a>, a record. The customer was using Google’s Cloud Armor service.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/theyre-among-us-malicious-bots-hide-using-nlp-and-ai/" target="_blank">Chatbots backed by AI and NLP</a> are becoming a significant problem for security. Well-designed chatbots can perform social engineering, execute denial of service attacks on customer service by generating complaints, and generate fake account credentials in bulk.</li><li>A security researcher has created a $25 tool that allows users to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://gizmodo.com/hacker-starlink-spacex-black-hat-security-conference-1849396899" target="_blank">run custom code on terminals for the Starlink network</a>. It requires attaching a board to your dish, but we suspect that enough Starlink users would be interested in “exploring” the satellite network to become a serious problem.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-whatsapp-messages-encryptedbut-traceable.html" target="_blank">Message Franking</a> is a cryptographic technology that includes end-to-end encryption, but also allows abusers to be held to account for misinformation–without revealing the content of the message.</li><li>One trick for <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://metaphysic.ai/to-uncover-a-deepfake-video-call-ask-the-caller-to-turn-sideways/" target="_blank">detecting live deepfakes</a> in video calls: ask the caller to turn sideways. Deepfake software is good at generating head-on views, but tends to fail badly at profiles.</li><li>Bruce Schneier on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.schneier.com/blog/archives/2022/08/nists-post-quantum-cryptography-standards.html" target="_blank">cryptographic agility</a>: We need the ability to swap in cryptographic algorithms quickly, in light of the possibility that quantum computers will soon be able to break current codes. Industry adoption of new algorithms takes a long time, and we may not have time.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/08/north-korea-backed-hackers-have-a-clever-way-to-read-your-gmail/#p3" target="_blank">SHARPEXT</a> is malware that installs a browser extension on Chrome or Edge that allows an attacker to read gmail. It can’t be detected by email services. Users are tricked into installing it through a phishing attack.</li><li><a href="https://thenewstack.io/passage-a-passwordless-service-with-biometrics/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Passage offers biometric authentication</a> services that work across devices using WebAuthn. Biometric data is encrypted, of course, and never leaves the user’s device.</li></ul>



<h3>Privacy</h3>



<ul><li>Watch the progress of the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://theconversation.com/a-new-us-data-privacy-bill-aims-to-give-you-more-control-over-information-collected-about-you-and-make-businesses-change-how-they-handle-data-188279" target="_blank">American Data Privacy Protection Act</a>, which has bipartisan support in Congress. This is the first serious attempt to provide nationwide digital privacy standards in the US.</li><li>A lawsuit filed in California claims that Oracle is selling a detailed social graph that incorporates information about <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.mi-3.com.au/22-08-2022/oracles-5bn-consumer-identity-graph-violates-privacy-billions-dr-johnny-ryan-privacy" target="_blank">5 billion distinct users</a>, roughly ⅔ the population of the planet. This information was gathered almost entirely without consent.</li><li>Finland is planning to test <a href="https://www.schengenvisainfo.com/news/finland-to-become-the-first-eu-country-to-test-digital-passports/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">digital passports</a> later this year. Volunteers with digital passports will be issued a smartphone app, rather than papers. Digital passports will require travelers to send plans to border control agencies, and a photo of them will be taken at the border.</li></ul>



<h3>Biology</h3>



<ul><li>A startup is attempting to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/08/25/1058652/grow-new-organs/" target="_blank">grow a new liver inside a human body</a>, as an alternative to a transplant. They will inject the patient’s lymph nodes with cells that will hopefully be able to reproduce and function as an alternate liver.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/08/17/1058090/mini-caps-measure-activity-lab-grown-minibrains/" target="_blank">Tiny caps for tiny brains</a>: Researchers have developed “caps” that can measure activity in brain organoids (cultured clusters of human neurons). It’s possible that groups of organoids can then be connected and networked. Is this the next neural network?</li><li>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/08/11/1057576/bioengineered-cornea-restored-sight/" target="_blank">bioengineered cornea</a> made from collagen collected from pig skin, could be an important step in treating keratoconus and other causes of blindness. Artificial corneas would eliminate the problem of donor shortage, and can be stored for much longer than donated corneas.</li><li>A startup in Israel is creating <a href="https://www.technologyreview.com/2022/08/04/1056633/startup-wants-copy-you-embryo-organ-harvesting/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">artificial human embryos</a> from human cells. These embryos, which survive for several days but are not viable, could be used to harvest very early-stage organs for transplants.</li></ul>



<h3>Things</h3>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-material-capable.html" target="_blank">Materials that can think</a>: Researchers have developed a mechanical integrated circuit that can respond to physical stresses, like touch, and perform computation on those stresses, and generate digital output.</li><li>Eutelsat, a European satellite operator, has launched a commercial “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-software-defined-satellite-commercial.html" target="_blank">software defined satellite</a>”: a satellite that can be reconfigured for different missions once it’s in space.</li><li>Developing robots just got easier. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/robomechanics/quad-sdk" target="_blank">Quad-SDK</a> is an <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-open-source-software-leg-robot.html" target="_blank">open source stack for four-legged locomotion</a> that’s compatible with ROS, the Robot Operating System.</li><li>Artificial intelligence isn’t just about humans. A startup is <a href="https://www.eetimes.com/reverse-engineering-insect-brains-to-make-robots/">reverse-engineering insect brains</a> to develop efficient vision and motion systems for robots.</li><li>A Japanese firm has developed robots that are being used to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-robot-arms-shelf-stockers-japan.html" target="_blank">stock shelves</a> in a convenience store chain.</li><li>Chicago’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/08/19/1057848/array-of-things-goes-global/" target="_blank">Array of Things</a> is an edge network for a smart city: an array of inexpensive temporary sensors to report on issues like traffic, safety, and air quality. Although the sensors include cameras, they only send processed data (not video) and can’t be used for surveillance.</li><li>The US Department of Energy is funding research on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-08-sensor-wildfires.html" target="_blank">using sensors, drones, and machine learning to predict and detect wildfires</a>. This includes identifying power line infrastructure that’s showing signs of arcing and in need of maintenance.</li><li>The UK is developing “flyways” for drones: <a href="https://info.deeplearning.ai/uks-drone-superhighway-largest-open-source-language-model-ai-protects-bees-countering-biased-labels" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Project Skyway</a> will reserve flight paths for drone aircraft between six major cities.</li></ul>



<h3>Work</h3>



<ul><li>It’s often thought that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenextweb.com/news/hybrid-workplace-tech-companies-less-inclusive" target="_blank">hybrid home/office work policies</a> help diversity and inclusion, but it’s more complex: people who choose to work from home often lose out in performance reviews, salary increases, and promotions.</li><li>A survey by the DevOps institute claims that 62% of companies have <a href="https://thenewstack.io/devops-institute-checks-the-pulse-of-sre/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">adopted some form of Site Reliability Engineering (SRE</a>); the biggest challenge is hiring staff with the right skills.</li></ul>



<h3>Web3</h3>



<ul><li>Ethereum will be moving to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/" target="_blank">proof-of-stake</a> in <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.theverge.com/2022/8/11/23301638/ethereum-crypto-blockchain-proof-of-stake-environment" target="_blank">September</a>. Fred Wilson has an analysis of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://avc.com/2022/08/the-merge/" target="_blank">what this will mean for the network</a>. The current proof-of-work blockchain will continue to exist.</li><li>Beginning in November, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://medium.datadriveninvestor.com/the-biggest-change-to-our-financial-system-in-50-years-is-happening-in-november-e976918c6118" target="_blank">international payments will begin moving to blockchains</a>, based on the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://altcoininvestor.com/what-is-iso-20022/" target="_blank">ISO 20022</a> standard. A small number of cryptocurrencies comply with this standard. (Bitcoin and Ethereum are not on the list.)</li><li>Application-specific blockchains, or <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/are-application-specific-chains-the-future-of-blockchain/" target="_blank">appchains</a>, may be the way to go, rather than using a Layer 1 blockchain like Ethereum. Appchains can be built to know about each other, making it easier to develop sophisticated applications; and why let fees go to the root blockchain’s miners?</li><li>Cryptocurrency scans and thefts are old news these days, but now we’ve seen the first <a href="https://www.bestbrokers.com/2022/08/03/altcoins-affected-by-nomad-hack-collapsed-as-much-as-94/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">decentralized robbery</a>. The attackers posted a “how to” on public servers, allowing others to join in the theft, and giving the original thieves cover. </li></ul>



<h3>Quantum Computing</h3>



<ul><li>Practical quantum computers may still be years away, but <a href="https://thenewstack.io/early-days-for-quantum-developers-but-serverless-coming/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Quantum Serverless</a> is coming. For almost all users, quantum computers will be in some provider’s cloud, and they’ll be programmed using APIs that have been designed for serverless access.</li></ul>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/radar-trends-to-watch-september-2022/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>Ad Networks and Content Marketing</title>
		<link>https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/</link>
				<comments>https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/#respond</comments>
				<pubDate>Tue, 16 Aug 2022 11:21:21 +0000</pubDate>
		<dc:creator><![CDATA[Q McCallum]]></dc:creator>
				<category><![CDATA[Operations]]></category>
		<category><![CDATA[Deep Dive]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14688</guid>
				<description><![CDATA[In a recent Radar piece, I explored N-sided marketplaces and the middlemen who bring disparate parties together. One such marketplace is the world of advertising, in which middlemen pair hopeful advertisers with consumer eyeballs. And this market for attention is absolutely huge, with global ad spend weighing in at $763 billion in 2021 revenues. Most [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>In a recent Radar piece, I explored <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oreilly.com/radar/building-a-better-middleman/" target="_blank">N-sided marketplaces and the middlemen</a> who bring disparate parties together. One such marketplace is the world of advertising, in which middlemen pair hopeful advertisers with consumer eyeballs. And this market for attention is absolutely huge, with global ad spend <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.statista.com/topics/990/global-advertising-market/#dossierKeyfigures" target="_blank">weighing in at $763 <em>billion</em> in 2021 revenues</a>.</p>



<p>Most of that money is <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.emarketer.com/content/worldwide-digital-ad-spending-2021" target="_blank">spent on digital ads</a>, like the ones that follow you across websites to offer you deals on items you&#8217;ve just bought. Those are typically based on your online activity. Ad networks trail behind you as you browse the web, trying to get an idea of who you are and what you&#8217;re likely to buy, so they can pair you with hopeful merchants.</p>



<p>While merchants are clearly happy with targeted ads—at least, I&#8217;d hope so, given how much they&#8217;re spending—consumers have, understandably, expressed concerns over personal privacy. Apple took note, and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.cnbc.com/2022/02/02/facebook-says-apple-ios-privacy-change-will-cost-10-billion-this-year.html" target="_blank">limited iOS apps&#8217; ability to track users</a> across sites. Google has announced <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.cnet.com/tech/computing/google-chromes-privacy-changes-will-hit-the-web-later-this-year/" target="_blank">changes that would further limit advertisers&#8217; reach</a>. Who knows? Maybe the next step will be that the ad industry gets stronger regulations.</p>



<p>There&#8217;s also the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thecorrespondent.com/100/the-new-dot-com-bubble-is-here-its-called-online-advertising" target="_blank">question of whether targeted advertising even works</a>.&nbsp; While the ad networks aren&#8217;t required to disclose their stats, there are even people inside those companies who think that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://theintercept.com/2020/12/24/facebook-ad-targeting-small-business/" target="_blank">their product is &#8220;almost all crap.&#8221;</a></p>



<p>Maybe it&#8217;s time for a different approach? Recently, Disney&#8217;s video streaming service, Disney+, threw its hat into the advertising ring by announcing a new ad-supported plan. (Credit where it&#8217;s due: I originally <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.lesechos.fr/tech-medias/medias/disney-va-lancer-une-offre-avec-de-la-publicite-1391472" target="_blank">found this in <em>Les Echos</em></a>, which may be paywalled. Here&#8217;s the official, English-language <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thewaltdisneycompany.com/disney-to-introduce-an-ad-supported-subscription-offering-in-late-2022/" target="_blank">press release from Disney</a>.)</p>



<p>It may be easy to disregard this Disney+ move, since so much of the online world is ad-supported these days. But I think this merits more attention than it may seem on the surface.</p>



<p>To be clear: I have no inside information here. But it at least <em>looks like</em> Disney+ can run its ad platform in a fairly low-tech fashion while also preserving privacy. That&#8217;s a pretty big deal for Disney, for consumers, and for the wider space of online advertising.</p>



<h3>Everything old is new again</h3>



<p>To understand why, let&#8217;s first consider the idea of <em>&#8220;content marketing.&#8221;</em> This is a new term for the age-old practice of selling ad space next to curated content that aligns with a particular theme. For example, let&#8217;s say you&#8217;ve created a magazine about cars. Motoring enthusiasts will read your magazine, which means advertisers (merchants) who want to reach them will place ads in your pages. The content is what draws readers and advertisers to the same spot.</p>



<p>What&#8217;s nice about content marketing is that the ad&#8217;s placement is based on the <em>content,</em> not the <em>specific person reading it.</em></p>



<p>This addresses the privacy concern at the core of targeted advertising, because content marketing doesn&#8217;t require that you build a detailed profile of a person based on their every browsing habit. You&#8217;re not pairing an ad to a person; you&#8217;re pairing an ad to a piece of content. So you shift your analytical focus from the reader to what they&#8217;re reading.</p>



<h3>The mouse has a large library</h3>



<p>Now, consider Disney: its catalog spans decades&#8217; worth of cartoons, tween sitcoms, and movies. Its recent acquisition of the Star Wars franchise gives it access to an even wider fanbase. And don&#8217;t forget that Disney owns ESPN, which adds sports content to the portfolio. It now makes that content available through its video-on-demand (VOD) platform of Disney+.</p>



<p>Disney already has to keep track of that catalog of content as part of its day-to-day business, which means we can reasonably assume that every show, movie, and sporting event on Disney+ has been assigned some number of descriptive tags or labels.</p>



<p>From the perspective of content marketing, all of this adds up to Disney+ being able to place ads on that content without having to do much extra work. The parent company, Disney, already owns the content and it&#8217;s already been tagged. The depth and breadth of the video catalog will certainly attract a large number and wide variety of viewers. That shifts the heavy lifting to the ad-matching system, which connects advertisers with the content.</p>



<h3>Tracking your ad budget</h3>



<p>You&#8217;ve likely heard the John Wanamaker adage: &#8220;Half the money I spend on advertising is wasted; the trouble is, I don&#8217;t know which half.&#8221; It&#8217;s a well-founded complaint about billboard or magazine advertising, since an advertiser can&#8217;t really tell how many people saw a given ad.</p>



<p>(Some early advertising pioneers, David Ogilvy among them, learned to supply coupons with print ads so stores could track which one had resonated the most. While this added a new level of analytical rigor to the field, it still wasn&#8217;t a perfect solution to Wanamaker&#8217;s plight.)</p>



<p>Delivering content-based ads through a well-curated streaming platform addresses that somewhat. Disney+ can provide an advertiser a detailed analysis of their ad spend without revealing any individual&#8217;s identity: <em>&#8220;N number of people watched Variant V, your ad for Product P, during Show S, with the following breakdowns for time of day&#8230;&#8221;</em></p>



<p>And that leads me to my next point:</p>



<h3>Minimal ML/AI</h3>



<p>When you review the setup—a curated and labeled catalog, with broad-brush marketing characteristics—Disney+ has the ability to run this ad service using minimal ML/AI.</p>



<p>(Once again: I&#8217;m speculating from the outside here. I don&#8217;t know for sure how much ML/AI Disney+ is using or plans to use. I&#8217;m working through one hypothetical-yet-seemingly-plausible scenario.)</p>



<p>Disney+ can use those content labels—&#8221;pro football,&#8221; &#8220;tween comedy,&#8221; &#8220;gen-X cartoon&#8221;—to pair a piece of content with an advertisement. They may not get a <em>perfect</em> hit rate on these ads; but given that they&#8217;re building on top of work they&#8217;ve already done (the catalog and the streaming platform) then the ad system can run at a relatively low cost. And providing stats to advertisers is a matter of counting. Since those calculations are so trivial, I expect the toughest part of that BI will be scaling it to Disney&#8217;s audience size.</p>



<p>Can Disney+ still use ML/AI in places? They most certainly <em>can,</em> but they don&#8217;t <em>have to.</em> Disney+ has the option to run this using a smaller team of data scientists and a far smaller data analysis infrastructure. Whether you call this &#8220;smaller budget&#8221; or &#8220;higher margins,&#8221; the net effect is the same: the company ends the day with money in its pocket.</p>



<p>Disney+ can task that ML team with building models that better tag content, or that improve matches between content and advertisers. They don&#8217;t have to spend money analyzing the specific actions of a specific individual in the hopes of placing ads.</p>



<h3>Future-proofing the ad system</h3>



<p>Assuming that the Disney+ ad system will indeed run on a content marketing concept, that means the company has one more card to play: They have just sidestepped potential future privacy laws that limit the use of personal information.</p>



<p>Yes, Disney+ can get a person&#8217;s contact information when they subscribe to the service. Yes, the company can track customer behavior on- and off-platform, through a mix of first- and third-party data. But, contrary to targeted advertising, they don&#8217;t <em>need</em> all of that to run ads. All the company needs is to pair content with an advertisement. Given that this is the modern-day equivalent of a billboard or newspaper article, I imagine it would be difficult for Disney+ to run afoul of any present-day or upcoming privacy regulation with such an ad setup.</p>



<h3>There&#8217;s still some room for trouble&#8230;</h3>



<p>Going back to our car magazine example, Disney&#8217;s library is the equivalent of hundreds or even thousands of magazines. And if a single magazine is a hint as to a single interest, what can a larger number of magazines tell us?</p>



<p>By tracking what content a person watches, how they watch it (phone, tablet, TV), and what time of day, Disney+ could infer quite a bit about that person and household: the number and age of adults; marital or relationship status; age and number of children; whether this is a multi-generational household; and even some clues as to viewers&#8217; gender. (I emphasize the term &#8220;infer&#8221; here, since it would hardly be perfect.)</p>



<p>In turn, Disney <em>could</em> use this for ad targeting, or to provide even more-detailed breakdowns to advertisers, or even find ways to share the data with other companies. This could get creepy quickly, so let&#8217;s hope they don&#8217;t take this route. And based on what we&#8217;ve covered thus far, Disney+ has every opportunity to run an ad network that preserves a reasonable amount of privacy.</p>



<h3>Could the tail someday wag the dog?</h3>



<p>Another possible wrinkle would be in how advertising weighs on future content.</p>



<p>Disney already has a good eye for what people will want to watch. And right now, those viewers are Disney&#8217;s customers. But when Disney+ becomes an ad marketplace, they&#8217;ll officially be a middleman, which means they&#8217;ll have to keep both sides of the ad equation happy. At what point does Disney use the Disney+ advertising as a compass, feeding back into decisions around what content to create?</p>



<p>And would Disney ever stretch beyond its own character lines, to build TV and movies around someone <em>else&#8217;s</em> toys?&nbsp; It&#8217;s not too far-fetched of an idea. In <em>The Great Beanie Baby Bubble,</em> author Zac Bisonette points out that:</p>



<blockquote class="wp-block-quote"><p>[A TV show deal] was the kind of product-based programming that was responsible for billions per year in sales and could turn toys that no one wanted into hits through sheer exposure. Lines such as He-Man, My Little Pony, and the ThunderCats had all become hundred-million-dollar brands with the help of the product-based TV shows that accompanied their launches.</p></blockquote>



<p>Creating content in one side of the businesses while running ads in the other, it&#8217;s not unlike running an investment bank and retail bank under one roof: sure, it can lead to all kinds of interesting business opportunities.&nbsp; It can also lead to trouble.</p>



<p>When it comes to content marketing, you need to strike a balance: you want to create evergreen content, so you can continue to run ads. And when that content is going into the Disney catalog—some of which currently spans multiple generations—it has to be absolutely timeless. Giving in to the whims of a single advertiser, or a single fad, can lead to short-term gains but also short-lived content.</p>



<h3>Beyond the Magic Kingdom</h3>



<p>Despite those challenges, content marketing has huge potential for generating revenue, preserving privacy, and avoiding future regulation that could hinder targeted advertising. By building this system on BI and content tagging, Disney could do so at a smaller price tag than an AI-based, targeted-ad marketplace.</p>



<p>And this isn&#8217;t just a Disney opportunity. I&#8217;ve focused on them in this piece but other VOD providers have already seen the benefit in monetizing their catalog. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bloomberg.com/news/newsletters/2022-04-10/the-phone-company-didn-t-destroy-hbo-will-the-cable-guy" target="_blank">According to Jason Kilar</a>, former CEO of WarnerMedia, &#8220;Close to 50% of every new [HBO Max] subscriber is choosing the ad tier. Hulu, the last stat they shared publicly, is they are north of 60%.&#8221; Amazon will rename its ad-supported IMDb TV service to Freevee. (I first saw this in <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.spiegel.de/netzwelt/freevee-amazon-kuendigt-deutschland-start-von-kostenlosem-streamingdienst-an-a-4bfbd854-34ca-476b-95b7-3ff5763d3966" target="_blank">Der Spiegel</a>; I&#8217;ve since found a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://apnews.com/article/technology-business-amazoncom-inc-netflix-jennifer-salke-84b0978c4880366ea6bd8dfff7e77af0" target="_blank">US&nbsp; press release</a>.)&nbsp; And Netflix, long a holdout in the ad-supported space, hinted at <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bloomberg.com/news/articles/2022-04-19/netflix-plans-lower-priced-service-with-ads-marking-big-shift" target="_blank">plans for a similar offering</a>.</p>



<p>To be clear, content marketing at this scale is not exactly a get-rich-quick scheme. It works best for groups that already have a large amount of content—video, image, text, audio—that they can monetize. This certainly holds true for the platforms I&#8217;ve just mentioned. Maybe it&#8217;s also true for your company?</p>



<p>It may require getting creative as you comb through your attic. And maybe there&#8217;s an option for a new kind of ad marketplace, one that groups people with a small amount of content into a larger content ecosystem.&nbsp;Sort of like what <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.ethicalads.io/" target="_blank">EthicalAds</a> does for developer documentation. If low-cost, non-invasive content marketing is an option, it can&#8217;t hurt to try.</p>



<hr class="wp-block-separator" />



<p>Many thanks to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oreilly.com/people/chris-butler/" target="_blank">Chris Butler</a> for reviewing an early draft of this article. I always appreciate his insights. The section on the tail wagging the dog was based on his idea and I give him full credit for pointing this out to me.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/ad-networks-and-content-marketing-the-potential-to-do-more-with-less/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>On Technique</title>
		<link>https://www.oreilly.com/radar/on-technique/</link>
				<comments>https://www.oreilly.com/radar/on-technique/#respond</comments>
				<pubDate>Tue, 09 Aug 2022 11:12:22 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[AI & ML]]></category>
		<category><![CDATA[Commentary]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14669</guid>
				<description><![CDATA[In a previous article, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>In a <a href="https://www.oreilly.com/radar/artificial-creativity-2/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">previous article</a>, I wrote about how models like DALL-E and Imagen disassociate ideas from technique. In the past, if you had a good idea in any field, you could only realize that idea if you had the craftsmanship and technique to back it up. With DALL-E, that’s no longer true. You can say, “Make me a picture of a lion attacking a horse,” and it will happily generate one. Maybe not as good as the one that <a href="https://collections.britishart.yale.edu/catalog/tms:32" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">hangs in an art museum</a>, but you don’t need to know anything about canvas, paints, and brushes, nor do you need to get your clothes covered with paint. </p>



<p>This raises some important questions, though. What is the connection between expertise and ideation? Does technique help you form ideas? (The Victorian artist William Morris is often <a href="https://books.google.com/books?id=Til0DwAAQBAJ&amp;pg=PT292&amp;lpg=PT292&amp;dq=%E2%80%9CYou+can%E2%80%99t+have+art,%E2%80%9D+said+William+Morris,+the+designer,+poet,+and+master+craftsman+of+the+Victorians,+%E2%80%9Cwithout+resistance+in+the+material.%E2%80%9D&amp;source=bl&amp;ots=WYX6uA9wTq&amp;sig=ACfU3U3M2qyEIEsf1rrjKJ3poWb8CWIj9g&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj0-JHhlo35AhUVjIkEHYP-AT0Q6AF6BAgCEAM#v=onepage&amp;q=%E2%80%9CYou%20can%E2%80%99t%20have%20art%2C%E2%80%9D%20said%20William%20Morris%2C%20the%20designer%2C%20poet%2C%20and%20master%20craftsman%20of%20the%20Victorians%2C%20%E2%80%9Cwithout%20resistance%20in%20the%20material.%E2%80%9D&amp;f=false" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">quoted</a> as saying “You can’t have art without resistance in the materials,” though he may only have been talking about his hatred of typewriters.) And what kinds of user interfaces will be effective for collaborations between humans and computers, where the computers supply the technique and we supply the ideas? Designing the prompts to get DALL-E to do something extraordinary requires a new kind of technique that’s very different from understanding pigments and brushes. What kinds of creativity does that new technique enable? How are these works different from what came before?</p>



<p>As interesting as it is to talk about art, there’s an area where these questions are more immediate. GitHub Copilot (based on a model named <a href="https://openai.com/blog/openai-codex/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Codex</a>, which is derived from GPT-3) generates code in a number of programming languages, based on comments that the user writes. Going in the other direction, GPT-3 has proven to be surprisingly good at <a href="https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">explaining code</a>. Copilot users still need to be programmers; they need to know whether the code that Copilot supplies is correct, and they need to know how to test it. The prompts themselves are really a sort of pseudo-code; even if the programmers don’t need to remember details of the language’s syntax or the names of library functions, they still need to think like programmers. But it’s obvious where this is trending. We need to ask ourselves how much “technique” we will ask of future programmers: in the 2030s or 2040s, will people just be able to tell some future Copilot what they want a program to be? More to the point, what sort of higher-order knowledge will future programmers need? Will they be able to focus more on the nature of what they want to accomplish, and less on the syntactic details of writing code?</p>



<p>It’s easy to imagine a lot of software professionals saying, “Of course you’ll have to know C. Or Java. Or Python. Or Scala.” But I don’t know if that’s true. We’ve been here before. In the 1950s, computers were programmed in machine language. (And before that, with cables and plugs.) It’s hard to imagine now, but the introduction of the first programming languages–Fortran, COBOL, and the like–was met with resistance from programmers who thought you needed to understand the machine. Now almost no one works in machine language or assembler. Machine language is reserved for a few people who need to work on some specialized areas of operating system internals, or who need to write some kinds of embedded systems code.</p>



<p>What would be necessary for another transformation? Tools like Copilot, useful as they may be, are nowhere near ready to take over. What capabilities will they need? At this point, programmers still have to decide whether or not code generated by Copilot is correct.&nbsp;We don’t (generally) have to decide whether the output of a C or Java compiler is correct, nor do we have to worry about whether, given the same source code, the compiler will generate identical output. Copilot doesn’t make that guarantee–and, even if it did, any change to the model (for example, to incorporate new StackOverflow questions or GitHub repositories) would be very likely to change its output.&nbsp;While we can certainly imagine compiling a program from a series of Copilot prompts, I can’t imagine a program that would be likely to stop working if it was recompiled without changes to the source code. Perhaps the only exception would be a library that could be developed once, then tested, verified, and used without modification–but the development process would have to re-start from ground zero whenever a bug or a security vulnerability was found. That wouldn’t be acceptable; we’ve never written programs that don’t have bugs, or that never need new features. A key principle behind much modern software development is minimizing the amount of code that has to change to fix bugs or add features.</p>



<p>It’s easy to think that programming is all about creating new code. It isn’t; one thing that every professional learns quickly is that most of the work goes into maintaining old code. A new generation of programming tools must take that into account, or we’ll be left in a weird situation where a tool like Copilot can be used to write new code, but programmers will still have to understand that code in detail because it can only be maintained by hand. (It is possible–even likely–that we will have AI-based tools that help programmers research software supply chains, discover vulnerabilities, and possibly even suggest fixes.) Writing about AI-generated art, Raphaël Millière <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.wired.com/story/dalle-art-curation-artificial-intelligence/" target="_blank">says</a>, “No prompt will produce the exact same result twice”; that may be desirable for artwork, but is destructive for programming. Stability and consistency is a requirement for next-generation programming tools; we can’t take a step backwards.</p>



<p>The need for greater stability might drive tools like Copilot from free-form English language prompts to some kind of more formal language. A book about <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://dallery.gallery/the-dalle-2-prompt-book/" target="_blank">prompt engineering for DALL-E</a> already exists; in a way, that’s trying to reverse-engineer a formal language for generating images. A formal language for prompts is a move back in the direction of traditional programming, though possibly with a difference. Current programming languages are all about describing, step by step, what you want the computer to do in great detail. Over the years, we’ve gradually progressed to higher levels of abstraction. Could building a language model into a compiler facilitate the creation of a simpler language, one in which programmers just described what they wanted to do, and let the machine worry about the implementation, while providing guarantees of stability? Remember that it was possible to build applications with graphical interfaces, and for those applications to communicate about the Internet, before the Web. The Web (and, specifically, HTML) added a new formal language that encapsulated tasks that used to require programming.</p>



<p>Now let’s move up a level or two: from lines of code to functions, modules, libraries, and systems. Everyone I know who has worked with Copilot has said that, while you don’t need to remember the details of the programming libraries you’re using, you have to be even more aware of what you’re trying to accomplish. You have to know what you want to do; you have to have a design in mind. Copilot is good at low-level coding; does a programmer need to be in touch with the craft of low-level coding to think about the high-level design? Up until now that’s certainly been true, but largely out of necessity: you wouldn’t let someone design a large system who hasn’t built smaller systems. It is true (as Dave Thomas and Andy Hunt argued in <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://learning.oreilly.com/library/view/the-pragmatic-programmer/9780135956977/" target="_blank">The Pragmatic Programmer</a>) that knowing different programming languages gives you different tools and approaches for solving problems.&nbsp; Is the craft of software architecture different from the craft of programming?</p>



<p>We don’t really have a good language for describing software design. Attempts like UML have been partially successful at best. UML was both over- and under-specified, too precise and not precise enough; tools that generated source code scaffolding from UML diagrams exist, but aren’t commonly used these days. The scaffolding defined interfaces, classes, and methods that could then be implemented by programmers. While automatically generating the structure of a system sounds like a good idea, in practice it may have made things more difficult: if the high-level specification changed, so did the scaffolding, obsoleting any work that had been put into implementing with the scaffold. This is similar to the compiler’s stability problem, modulated into a different key. Is this an area where AI could help?</p>



<p>I suspect we still don’t want source code scaffolding, at least as UML envisioned it; that’s bound to change with any significant change in the system’s description. Stability will continue to be a problem. But it might be valuable to have a AI-based design tool that can take a verbal description of a system’s requirements, then generate some kind of design based on a large library of software systems–like Copilot, but at a higher level. Then the problem would be integrating that design with implementations of the design, some of which could be created (or at least suggested) by a system like Copilot. The problem we’re facing is that software development takes place on two levels: high level design and mid-level programming. Integrating the two is a hard problem that hasn’t been solved convincingly.&nbsp; Can we imagine taking a high-level design, adding our descriptions to it, and going directly from the high-level design with mid-level details to an executable program? That programming environment would need the ability to partition a large project into smaller pieces, so teams of programmers could collaborate. It would need to allow changes to the high-level descriptions, without disrupting work on the objects and methods that implement those descriptions. It would need to be integrated with a version control system that is effective for the English-language descriptions as it is for lines of code. This wouldn’t be thinkable without guarantees of stability.</p>



<p>It was fashionable for a while to talk about programming as “craft.”&nbsp; I think that fashion has waned, probably for the better; “code as craft” has always seemed a bit precious to me. But the idea of “craft” is still useful: it is important for us to think about how the craft may change, and how fundamental those changes can’t be.&nbsp;It’s clear that we are a long way from a world where only a few specialists need to know languages like C or Java or Python. But it’s also possible that developments like Copilot give us a glimpse of what the next step might be. Lamenting the state of programing tools, which haven’t changed much since the 1960s, Alan Kay <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.quora.com/What-was-the-last-breakthrough-in-computer-programming" target="_blank">wrote on Quora</a> that “the next significant threshold that programming must achieve is for programs and programming systems to have a much deeper understanding of both what they are trying to do, and what they are actually doing.” A new craft of programming that is focused less on syntactic details, and more on understanding what the systems we are building are trying to accomplish, is the goal we should be aiming for.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/on-technique/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>Scaling False Peaks</title>
		<link>https://www.oreilly.com/radar/scaling-false-peaks/</link>
				<comments>https://www.oreilly.com/radar/scaling-false-peaks/#respond</comments>
				<pubDate>Thu, 04 Aug 2022 11:12:44 +0000</pubDate>
		<dc:creator><![CDATA[Kevlin Henney]]></dc:creator>
				<category><![CDATA[AI & ML]]></category>
		<category><![CDATA[Commentary]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14661</guid>
				<description><![CDATA[Humans are notoriously poor at judging distances. There&#8217;s a tendency to underestimate, whether it&#8217;s the distance along a straight road with a clear run to the horizon or the distance across a valley. When ascending toward a summit, estimation is further confounded by false summits. What you thought was your goal and end point turns [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>Humans are notoriously poor at judging distances. There&#8217;s a tendency to underestimate, whether it&#8217;s the distance along a straight road with a clear run to the horizon or the distance across a valley. When ascending toward a summit, estimation is further confounded by false summits. What you thought was your goal and end point turns out to be a lower peak or simply a contour that, from lower down, looked like a peak. You thought you made it–or were at least close–but there&#8217;s still a long way to go.</p>



<p>The story of AI is a story of punctuated progress, but it is also the story of (many) false summits.</p>



<p>In the 1950s, machine translation of Russian into English was considered to be no more complex than dictionary lookups and templated phrases. Natural language processing has come a very long way since then, having burnt through a good few paradigms to get to something we can use on a daily basis. In the 1960s, Marvin Minsky and Seymour Papert proposed the Summer Vision Project for undergraduates: connect a TV camera to a computer and identify objects in the field of view. Computer vision is now something that is commodified for specific tasks, but it continues to be a work in progress and, worldwide, has taken more than a few summers (and AI winters) and many more than a few undergrads.</p>



<p>We can find many more examples across many more decades that reflect naiveté and optimism and–if we are honest–no small amount of ignorance and hubris. The two general lessons to be learned here are not that machine translation involves more than lookups and that computer vision involves more than edge detection, but that when we are confronted by complex problems in unfamiliar domains, we should be cautious of anything that looks simple at first sight, and that when we have successful solutions to a specific sliver of a complex domain, we should not assume those solutions are generalizable. This kind of humility is likely to deliver more meaningful progress and a more measured understanding of such progress. It is also likely to reduce the number of pundits in the future who mock past predictions and ambitions, along with the recurring irony of machine-learning experts who seem unable to learn from the past trends in their own field.</p>



<p>All of which brings us to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.deepmind.com/publications/a-generalist-agent" target="_blank">DeepMind&#8217;s Gato</a> and the claim that the summit of artificial general intelligence (AGI) is within reach. The hard work has been done and reaching AGI is now a simple matter of scaling. At best, this is a false summit on the right path; at worst, it&#8217;s a local maximum far from AGI, which lies along a very different route in a different range of architectures and thinking.</p>



<p>DeepMind&#8217;s Gato is an AI model that can be taught to carry out many different kinds of tasks based on a single transformer neural network. The 604 tasks Gato was trained on vary from playing Atari video games to chat, from navigating simulated 3D environments to following instructions, from captioning images to real-time, real-world robotics. The achievement of note is that it’s underpinned by a single model trained across all tasks rather than different models for different tasks and modalities. Learning how to ace Space Invaders does not interfere with or displace the ability to carry out a chat conversation.</p>



<p><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arxiv.org/pdf/2205.06175.pdf" target="_blank">Gato was intended to</a> &#8220;test the hypothesis that training an agent which is generally capable on a large number of tasks is possible; and that this general agent can be adapted with little extra data to succeed at an even larger number of tasks.&#8221; In this, it succeeded. But how far can this success be generalized in terms of loftier ambitions? The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/NandoDF/status/1525397036325019649" target="_blank">tweet</a> that provoked a wave of responses (this one included) came from DeepMind&#8217;s research director, Nando de Freitas: &#8220;It&#8217;s all about scale now! The game is over!&#8221;</p>



<p>The game in question is the quest for AGI, which is closer to what science fiction and the general public think of as AI than the narrower but applied, task-oriented, statistical approaches that constitute commercial machine learning (ML) in practice.</p>



<p>The claim is that AGI is now simply a matter of improving performance, both in hardware and software, and making models bigger, using more data and more kinds of data across more modes. Sure, there&#8217;s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/NandoDF/status/1525398087203983360" target="_blank">research work</a> to be done, but now it&#8217;s all about turning the dials up to 11 and beyond and, voilà, we&#8217;ll have scaled the north face of the AGI to plant a flag on the summit.</p>



<p>It&#8217;s easy to get breathless at altitude.</p>



<p>When we look at other systems and scales, it&#8217;s easy to be drawn to superficial similarities in the small and project them into the large. For example, if we look at water swirling down a plughole and then out into the cosmos at spiral galaxies, we see a similar structure. But these spirals are more closely bound in our desire to see connection than they are in physics. In looking at scaling specific AI to AGI, it&#8217;s easy to focus on tasks as the basic unit of intelligence and ability. What we know of intelligence and learning systems in nature, however, suggests the relationships between tasks, intelligence, systems, and adaptation is more complex and more subtle. Simply scaling up one dimension of ability may simply scale up one dimension of ability without triggering emergent generalization.</p>



<p>If we look closely at software, society, physics or life, we see that scaling is usually accompanied by fundamental shifts in organizing principle and process. Each scaling of an existing approach is successful up to a point, beyond which a different approach is needed. You can run a small business using office tools, such as spreadsheets, and a social media page. Reaching Amazon-scale is not a matter of bigger spreadsheets and more pages. Large systems have radically different architectures and properties to either the smaller systems they are built from or the simpler systems that came before them.</p>



<p>It may be that artificial general intelligence is a far more significant challenge than taking task-based models and increasing data, speed, and number of tasks. We typically underappreciate how complex such systems are. We divide and simplify, make progress as a result, only to discover, as we push on, that the simplification was just that; a new model, paradigm, architecture, or schedule is needed to make further progress. Rinse and repeat. Put another way, just because you got to basecamp, what makes you think you can make the summit using the same approach? And what if you can&#8217;t see the summit? If you don&#8217;t know what you&#8217;re aiming for, it&#8217;s difficult to plot a course to it.</p>



<p>Instead of assuming the answer, we need to ask: <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oreilly.com/radar/closer-to-agi/" target="_blank">How do we define AGI</a>? Is AGI simply task-based AI for N tasks and a sufficiently large value of N? And, even if the answer to that question is <em>yes</em>, is the path to AGI necessarily task-centric? How much of AGI is performance? How much of AGI is big/bigger/biggest data?</p>



<p>When we look at life and existing learning systems, we learn that scale matters, but not in the sense suggested by a simple multiplier. It may well be that the trick to cracking AGI is to be found in scaling–but down rather than up.</p>



<p>Doing more with less looks to be more important than doing more with more. For example, the GPT-3 language model is based on a network of 175 billion parameters. The first version of DALL-E, the prompt-based image generator, used a 12-billion parameter version of GPT-3; the second, improved version used only 3.5 billion parameters. And then there&#8217;s Gato, which achieves its multitask, multimodal abilities with only 1.2 billion.</p>



<p>These reductions hint at the direction, but it&#8217;s not clear that Gato&#8217;s, GPT-3&#8217;s or any other contemporary architecture is necessarily the right vehicle to reach the destination. For example, how many training examples does it take to learn something? For biological systems, the answer is, in general, not many; for machine learning, the answer is, in general, very many. GPT-3, for example, developed its language model based on 45TB of text. Over a lifetime, a human reads and hears of the order of a billion words; a child is exposed to ten million or so before starting to talk. Mosquitoes can learn to avoid a particular pesticide after a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nature.com/articles/s41598-022-05754-2" target="_blank">single non-lethal exposure</a>. When you learn a new game–whether video, sport, board or card–you generally only need to be told the rules and then play, perhaps with a game or two for practice and rule clarification, to make a reasonable go of it. Mastery, of course, takes far more practice and dedication, but general intelligence is not about mastery.</p>



<p>And when we look at the hardware and its needs, consider that while the brain is one of the most power-hungry organs of the human body, it still has a modest power consumption of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.scientificamerican.com/article/thinking-hard-calories/" target="_blank">around 12 watts</a>. Over a life the brain will consume up to 10 MWh; training the GPT-3 language model took an estimated 1 GWh.</p>



<p>When we talk about scaling, the game is only just beginning.</p>



<p>While hardware and data matter, the architectures and processes that support general intelligence may be necessarily quite different to the architectures and processes that underpin current ML systems. Throwing faster hardware and all the world&#8217;s data at the problem is likely to see diminishing returns, although that may well let us scale a false summit from which we can see the real one.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/scaling-false-peaks/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>The Metaverse Is Not a Place</title>
		<link>https://www.oreilly.com/radar/the-metaverse-is-not-a-place/</link>
				<comments>https://www.oreilly.com/radar/the-metaverse-is-not-a-place/#respond</comments>
				<pubDate>Tue, 02 Aug 2022 18:38:46 +0000</pubDate>
		<dc:creator><![CDATA[Tim O’Reilly]]></dc:creator>
				<category><![CDATA[Metaverse]]></category>
		<category><![CDATA[Research]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14641</guid>
				<description><![CDATA[The metaphors we use to describe new technology constrain how we think about it, and, like an out-of-date map, often lead us astray. So it is with the metaverse. Some people seem to think of it as a kind of real estate, complete with land grabs and the attempt to bring traffic to whatever bit [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>The metaphors we use to describe new technology constrain how we think about it, and, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.linkedin.com/pulse/20121029141916-16553-language-is-a-map" target="_blank">like an out-of-date map</a>, often lead us astray. So it is with the metaverse. Some people seem to think of it as <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://news.bitcoin.com/metaverse-real-estate-sales-to-grow-by-5-billion-by-2026/" target="_blank">a kind of real estate</a>, complete with land grabs and the attempt to bring traffic to whatever bit of virtual property they’ve created.</p>



<figure class="wp-block-image size-large"><img src="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_01.png" alt="" class="wp-image-14642" srcset="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_01.png 977w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_01-300x186.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_01-768x476.png 768w" sizes="(max-width: 977px) 100vw, 977px" /></figure>



<p>Seen through the lens of the real estate metaphor, the metaverse becomes a natural successor not just to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Second_Life" target="_blank">Second Life</a> but to the World Wide Web and to social media feeds, which can be thought of as a set of places (sites) to visit. Virtual Reality headsets will make these places more immersive, we imagine.</p>



<p>But what if, instead of thinking of the metaverse as a set of interconnected virtual places, we think of it as a communications medium? Using this metaphor, we see the metaverse as a continuation of a line that passes through messaging and email to “rendezvous”-type social apps like Zoom, Google Meet, Microsoft Teams, and, for wide broadcast, Twitch + Discord. This is a progression from text to images to video, and from store-and-forward networks to real time (and, for broadcast, “stored time,” which is a useful way of thinking about recorded video), but in each case, the interactions are not place based but happening in the ether between two or more connected people. The occasion is more the point than the place.</p>



<p>In an interview with Lex Fridman, Mark Zuckerberg disclaimed the notion of the metaverse as a place, but in the same sentence <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://youtu.be/5zOHSysMmH0?t=1019" target="_blank">described its future in a very place-based way</a>:</p>



<blockquote class="wp-block-quote"><p><em>A lot of people think that the Metaverse is about a place, but one definition of this is it&#8217;s about a time when basically immersive digital worlds become the primary way that we live our lives and spend our time.</em></p></blockquote>



<p>Think how much more plausible this statement might be if it read:</p>



<blockquote class="wp-block-quote"><p><em>A lot of people think that the Metaverse is about a place, but one definition of this is it&#8217;s about a time when immersive digital worlds become the primary way that we communicate and share digital experiences.</em></p></blockquote>



<p>My personal metaverse prototype moment does not involve VR at all, but Zoom. My wife Jen and I join our friend Sabrina over Zoom each weekday morning to exercise together. Sabrina leads the sessions by sharing her Peloton app, which includes live and recorded exercise videos. Our favorites are the strength training videos with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.onepeloton.com/instructors/peloton_r" target="_blank">Rad Lopez</a> and the 15-minute abs videos with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.onepeloton.com/instructors/bike/robin" target="_blank">Robin Arzón</a>. We usually start with Rad and end with Robin, for a vigorous 45-minute workout.</p>



<p>Think about this for a moment: Jen and I are in our home. Sabrina is in hers. Rad and Robin recorded their video tracks from their studios on the other side of the county. Jen and Sabrina and I are there in real time. Rad and Robin are there in stored time. We have joined five people in four different places and three different times into one connected moment and one connected place, “the place between” the participants.</p>



<p>Sabrina also works out on her own on her Peloton bike, and that too has this shared quality, with multiple participants at various “thicknesses” of connection. While Jen and Sabrina and I are “enhancing” the sharing using real-time Zoom video, Sabrina’s “solo” bike workouts use the intrinsic sharing in the Peloton app, which lets participants see real-time stats from others doing the same ride.</p>



<p>This is the true internet—the network of networks, with dynamic interconnections. If the metaverse is to inherit that mantle, it has to have that same quality. <em>Connection</em>.</p>



<p>Hacker News user <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://news.ycombinator.com/item?id=29083271" target="_blank">kibwen put it beautifully</a> when they wrote:</p>



<blockquote class="wp-block-quote"><p><em>A metaverse involves some kind of shared space and shared experience across a networked medium. Not only is it more than just doing things in VR, a metaverse doesn&#8217;t even require VR.</em></p></blockquote>



<h3>The metaverse as a vector</h3>



<p>It’s useful to look at technology trends (lines of technology progression toward the future, and inheritance from the past) as vectors—quantities that can only be fully described by both a magnitude and a direction and that can be summed or multiplied to get a sense of how they might cancel, amplify, or redirect possible pathways to the future.</p>



<p>I wrote about this idea back in 2020, in a piece called “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oreilly.com/tim/21stcentury/" target="_blank">Welcome to the 21st Century</a>,” in the context of using <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.wired.com/1995/11/how-to-build-scenarios/" target="_blank">scenario planning</a> to imagine the post-COVID future. It’s worth recapping here:</p>



<blockquote class="wp-block-quote"><p><em>Once you’ve let loose your imagination, observe the world around you and watch for what scenario planners sometimes call “news from the future”—data points that tell you that the world is trending in the direction of one or another of your imagined scenarios. As with any scatter plot, data points are all over the map, but when you gather enough of them, you can start to see the trend line emerge.…</em><br><br><em>If you think of trends as vectors, new data points can be seen as extending and thickening the trend lines and showing whether they are accelerating or decelerating. And as you see how trend lines affect each other, or that new ones need to be added, you can continually update your scenarios (or as those familiar with Bayesian statistics might put it, you can </em><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Prior_probability" target="_blank"><em>revise your priors</em></a><em>). This can be a relatively unconscious process. Once you’ve built mental models of the world as it might be, the news that you read will slot into place and either reinforce or dismantle your imagined future.</em></p></blockquote>



<p>Here’s how my thinking about the metaverse was formed by “news from the future” accreting around a technology-development vector:</p>



<ol><li>I had a prior belief, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://web.archive.org/web/20000711041545/http://www.oreillynet.com/pub/a/network/2000/06/09/java_keynote.html" target="_blank">going back decades</a>, that the internet is a tool for connection and communication, and that advances along that vector will be important. I’m always looking with soft focus for evidence that the tools for connection and communication are getting richer, trying to understand <em>how</em> they are getting richer and how they are changing society.&nbsp;</li><li>I’ve been looking at VR for years, trying various headsets and experiences, but they are mostly solo and feel more like stand-alone games or if shared, awkward and cartoonish. Then I read a thoughtful piece by my friend Craig Mod in which he noted that while he lives his physical life in a small town in Japan or <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://craigmod.com/essays/walk_japan/" target="_blank">walking its ancient footpaths</a>, he also has a work life in which he spends time daily with people all over the world. I believe he made the explicit connection to the metaverse, but neither he nor I can find the piece that planted this thought to confirm that. In any case, I think of Craig’s newsletter as where the notion that the metaverse is a continuation of the communications technologies of the internet took hold for me.</li><li>I began to see the connection to Zoom when friends started using interesting backgrounds, some of which make them appear other than where they are and others that make clear just where they are. (For example, my friend Hermann uses as a background the beach behind his home in New Zealand, which is more vividly place based than his home office, which could be anywhere.) That then brought my exercise sessions with Sabrina and Jen into focus as part of this evolving story.</li><li>I talked to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.sequoiacap.com/article/phil-libin-mmhmm-spotlight/" target="_blank">Phil Libin</a> about his brilliant service <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.mmhmm.app/" target="_blank">mmhmm</a>, which makes it easy to create and deliver richer, more interactive presentations over Zoom and similar apps. The speaker literally gets to occupy the space of the presentation. Phil’s presentation on “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.youtube.com/watch?v=mBKIMhGO8WA" target="_blank">The Out of Office World</a>” was where it all clicked. He talks about the hierarchy of communication and the tools for modulating it. (IMO this is a must-watch piece for anyone thinking about the future of internet apps. I’m surprised how few people seem to have watched it.)<br></li></ol>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe title="The Out-of-office World" width="500" height="281" src="https://www.youtube.com/embed/mBKIMhGO8WA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<ol start="5"><li>Trying <a href="https://www.getsupernatural.com/">Supernatural</a> using the Meta Quest 2 headset completed the connection between my experience using Zoom and Peloton for fitness with friends and the VR-dominant framing of the metaverse. Here I was, standing on the edge of one of the lava lakes at <a href="https://www.atlasobscura.com/places/erta-ale">Erta Ale</a> in Ethiopia, an astonishing volcano right out of central casting for Mount Doom in <em>The Lord of the Rings</em>, working through warm-up exercises with a video of a fitness instructor green-screened into the scene, before launching into a boxing training game. Coach Susie was present in stored time, just like Robin and Rad. All that was missing was Jen and Sabrina. I’m sure that such shared experiences in remarkable places are very much part of the VR future.</li></ol>



<p></p>



<figure class="wp-block-image size-large"><a href="https://www.youtube.com/watch?v=jufCUdibP4c" target="_blank" rel="noreferrer noopener"><img src="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_02.png" alt="" class="wp-image-14643" srcset="https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_02.png 977w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_02-300x169.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2022/08/the_metaverse_is_not_a_place_02-768x432.png 768w" sizes="(max-width: 977px) 100vw, 977px" /></a></figure>



<p>That kind of shared experience is central to Mark Zuckerberg’s vision of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.youtube.com/watch?v=b9vWShsmE20" target="_blank">socializing in the metaverse</a>.</p>



<figure class="wp-block-embed-youtube wp-block-embed is-type-video is-provider-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe title="Watch Mark Zuckerberg&#039;s vision for socializing in the Metaverse" width="500" height="281" src="https://www.youtube.com/embed/b9vWShsmE20?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>In that video, Zuck shows off lavishly decorated personal spaces, photorealistic and cartoon avatars, and an online meeting interrupted by a live video call. He says:</p>



<blockquote class="wp-block-quote"><p><em>It&#8217;s a ways off but you can start to see some of the fundamental building blocks take shape. First the feeling of presence. This is the defining quality of the metaverse. You&#8217;re going to really feel like you&#8217;re there with other people. You&#8217;ll see their facial expressions, you&#8217;ll see their body language, maybe figure out if they&#8217;re actually holding a winning hand—all the subtle ways that we communicate that today&#8217;s technology can&#8217;t quite deliver.</em></p></blockquote>



<p>I totally buy the idea that presence is central. But Meta’s vision seems to miss the mark in its focus on avatars. Embedded video delivers more of that feeling of presence with far less effort on the part of the user than learning to create avatars that mimic our gestures and expressions.</p>



<p>Chris Milk, the CEO of Within, the company that created Supernatural, both agreed and disagreed about avatars when explaining the company’s origin story to me in a phone conversation a few months ago:</p>



<blockquote class="wp-block-quote"><p><em>What we learned early on was that photorealism matters a lot in terms of establishing presence and human connection. Humans, captured using photorealistic methods like immersive video, allow for a deeper connection between the audience and the people recorded in the immersive VR experience. The audience feels present in the story with them. But it&#8217;s super hard to do from a technical standpoint and you give up a bunch of other things. The trade-off is that you can have photorealism but sacrifice interactivity, as the photorealistic humans need to be prerecorded. Alternatively, you can have lots of interactivity and human-to-human communication, but you give up on anyone looking real. In the latter, the humans need to be real-time-rendered avatars, and those, for the moment, don’t look remotely like real humans.</em></p></blockquote>



<p>At the same time, Milk pointed out that humans are able to read a lot into even crude avatars, especially when they’re accompanied by real-time communication using voice.</p>



<blockquote class="wp-block-quote"><p><em>Especially if it’s someone you already know, then the human connection can overcome a lot of missing visual realism. We did an experiment back in 2014 or 2015, probably. Aaron [Koblin, the cofounder of Within] was living in San Francisco, and I was in Los Angeles. We had built a VR prototype where we each had a block for the head and two blocks for our hands. I got into my headset in LA, and Aaron&#8217;s blocks were sitting over on the floor across from me as his headset and hand controllers were sitting on his floor in San Francisco. All of a sudden the three blocks jumped up off the ground into the air as he picked up his headset and put it on. The levitating cubes “walked” up to me, waved, and said, “Hey.” Immediately, before I even heard the voice, I recognized the person in those blocks as Aaron. I recognized through the posture and gait the spirit of Aaron in these three cubes moving through space. The resolution, or any shred of photorealism, was completely absent, but the humanity still showed through. And when his voice came out of them, my brain just totally accepted that the soul of Aaron now resides in these three floating cubes. Nothing was awkward about communicating back and forth. My brain just accepted it instantly. </em></p></blockquote>



<p>And that’s where we get back to vectors. Understanding the future of photorealism in the metaverse depends on the speed and direction of progress in AI. In many ways, a photorealistic avatar is a kind of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Deepfake" target="_blank">deepfake</a>, and we know how computationally expensive their creation is today. How long will it be before the creation of deepfakes is cheap enough and fast enough that hundreds of millions of people can be creating and using them in real time? I suspect it will be a while.</p>



<p>Mmhmm’s blending of video and virtual works really well, using today’s technology. It’s ironic that in Meta’s video about the future, video is only shown on a screen in the virtual space rather than as an integral part of it. Meta could learn a lot from mmhmm.</p>



<p>On the other hand, creating a vast library of immersive 3D still images of amazing places into which either avatars or green-screened video images can be inserted seems much closer to realization. It’s still hard, but the problem is orders of magnitude smaller. The virtual spaces offered by Supernatural and other VR developers give an amazing taste of what’s possible here.</p>



<p>In this regard, an interesting sidenote came from a virtual session that we held earlier this year at the Social Science Foo Camp (an event put together annually by O’Reilly, Meta, and Sage) using the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://engagevr.io/" target="_blank">ENGAGE</a> virtual media conferencing app. The group began their discussion in one of the default meeting spaces, but one of the attendees, Adam Flaherty, proposed that they have it in a more appropriate place. They moved to a beautifully rendered version of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Bodleian_Library" target="_blank">Oxford’s Bodleian Library</a>, and attendees reported that the entire tenor of the conversation changed.</p>



<p>Two other areas worth thinking about:</p>



<ol><li>Social media evolved from a platform for real-time interaction (real-time status updates, forums, conversations, and groups) to one that’s often dominated by stored-time interaction (posts, stories, reels, et al). Innovation in formats for stored-time communications is at the heart of future social media competition, as TikTok has so forcefully reminded Facebook. There’s a real opportunity for developers and influencers to pioneer new formats as the metaverse unfolds.</li><li>Bots are likely to play a big role in the metaverse, just as they do in today’s gaming environments. Will we be able to distinguish bots from humans? Chris Hecker’s indie game <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.spyparty.com/" target="_blank"><em>SpyParty</em></a>, prototyped in 2009, made this a central feature of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/SpyParty" target="_blank">its game play</a>, requiring two human players (one spy and one sniper) to find or evade each other among a party crowded with bots (what game developers call non-player characters or NPCs). Bots and deepfakes are already transforming our social experiences on the internet; expect this to happen on steroids in the metaverse. Some bots will be helpful, but others will be malevolent and disruptive. We will need to tell the difference.</li></ol>



<h3>The need for interoperability</h3>



<p>There’s one thing that a focus on communications as the heart of the metaverse story reminds us: communication, above all, depends on interoperability. A balkanized metaverse in which a few big providers engage in a winner-takes-all competition to create the Meta- or Apple- or whatever-owned metaverse will take far longer to develop than one that allows developers to create great environments and experiences and connect them bit by bit with the innovations of others. It would be far better if the metaverse were an extension of the internet (“the network of networks”) rather than an attempt to replace it with a walled garden.</p>



<p>Some things that it would be great to have be interoperable:</p>



<ul><li><strong>Identity.</strong> We should be able to use the digital assets that represent who we are across platforms, apps, and places offered by different companies.</li><li><strong>Sensors.</strong> Smartwatches, rings, and so forth are increasingly being used to collect physiological signals. This technology can be built into VR-specific headsets, but we would do better if it were easily shared between devices from different providers.</li><li><strong>Places.</strong> (Yes, places are part of this after all.) Rather than having a single provider (say Meta) become the ur-repository of photorealistic 360-degree immersive spaces, it would be great to have an interoperability layer that allows their reuse.</li><li><strong>Bot identification.</strong> Might NFTs end up becoming the basis for a nonrepudiable form of identity that must be produced by both humans and bots? (I suspect we can only force bots to identify themselves as such if we also require humans to do so.)</li></ul>



<h3>Foundations of the metaverse</h3>



<p>You can continue this exercise by thinking about the metaverse as the combination of multiple technology trend vectors progressing at different speeds and coming from different directions, and pushing the overall vector forward (or backward) accordingly. No new technology is the product of a single vector.</p>



<p>So rather than settling on just “the metaverse is a communications medium,” think about the various technology vectors besides real-time communications that are coming together in the current moment. What news from the future might we be looking for?</p>



<ul><li><strong>Virtual Reality/Augmented Reality. </strong>Lighter and less obtrusive headsets. Advances in 3D video recording. Advances in sensors, including eye-tracking, expression recognition, physiological monitoring, even <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.cnbc.com/2019/09/23/facebook-announces-acquisition-of-brain-computing-start-up-ctrl-labs.html" target="_blank">brain-control interfaces</a>. Entrepreneurial innovations in the balance between AR and VR. (Why do we think of them as mutually exclusive rather than on a continuum?)</li><li><strong>Social media. </strong>Innovations in connections between influencers and fans. How does stored time become more real time?</li><li><strong>Gaming. </strong>Richer integration between games and communications. What’s the next Twitch + Discord?</li><li><strong>AI. </strong>Not just deepfakes but the proliferation of AIs and bots as participants in social media and other communications. NPCs becoming a routine part of our online experience outside of gaming. Standards for identification of bots versus humans in online communities.</li><li><strong>Cryptocurrencies and “Web3.”</strong>&nbsp;Does crypto/Web3 provide new business models for the metaverse? (BTW, I enjoyed the way that Neal Stephenson, in <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Reamde" target="_blank"><em>Reamde</em></a>, had his character design the business model and money flows for his online game before he designed anything else. Many startups just try to get users and assume the business model will follow, but that has led us down the dead end of advertising and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Surveillance_capitalism" target="_blank">surveillance capitalism</a>.) </li><li><strong>Identity. </strong>Most of today’s identity systems are centralized in one way or another, with identity supplied by a trusted provider or verifier. Web3 proponents, however, are exploring a variety of systems for decentralized “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Self-sovereign_identity" target="_blank">self-sovereign identity</a>,” including Vitalik Buterin’s “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://vitalik.eth.limo/general/2022/01/26/soulbound.html" target="_blank">soulbound tokens</a>.” The vulnerability of crypto systems to <a href="https://en.wikipedia.org/wiki/Sybil_attack">Sybil attacks</a> in the absence of verifiable identity is driving a lot of innovation in the identity space. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/" target="_blank">Molly White’s skeptical survey of these various initiatives</a> is a great overview of the problem and the difficulties in overcoming it. Gordon Brander’s “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://subconscious.substack.com/p/soulbinding-like-a-state" target="_blank">Soulbinding Like A State</a>,” a riff on Molly White’s post and James C. Scott’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Seeing_Like_a_State" target="_blank"><em>Seeing Like A State</em></a>, provides a further warning: “Scott’s framework reveals…that the dangers of legibility are not related to the sovereignty of an ID. There are many reasons self-sovereignty is valuable, but the function of a self-sovereign identity is still to make the bearer legible. What’s measured gets managed. What’s legible gets controlled.” As is often the case, no perfect solution will be found, but society will adopt an imperfect solution by making trade-offs that are odious to some, very profitable to others, and that the great mass of users will passively accept.</li></ul>



<p>There’s a lot more we ought to be watching. I’d love your thoughts in the comments.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/the-metaverse-is-not-a-place/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>Radar Trends to Watch: August 2022</title>
		<link>https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/</link>
				<comments>https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/#respond</comments>
				<pubDate>Tue, 02 Aug 2022 11:18:24 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[Radar Trends]]></category>
		<category><![CDATA[Signals]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14631</guid>
				<description><![CDATA[The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>The large model train keeps rolling on. This month, we’ve seen the release of Bloom, an open, large language model developed by the BigScience collaboration, the first public access to DALL-E (along with a guide to prompt engineering), a Copilot-like model for generating regular expressions from English-language prompts, and Simon Willison’s experiments using GPT-3 to explain JavaScript code.</p>



<p>On other fronts, NIST has released the first proposed standard for post-quantum cryptography (i.e., cryptography that can’t be broken by quantum computers). CRISPR has been used in human trials to re-engineer a patient’s DNA to reduce cholesterol. And a surprising number of cities are paying high tech remote workers to move there.</p>



<h2>Artificial Intelligence</h2>



<ul><li>Regardless of where a company is based, to avoid legal problems later, it’s a good idea to build AI and other data-based systems that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenextweb.com/news/european-or-not-make-sure-your-ai-business-sticks-to-eu-data-laws" target="_blank">observe the EU’s data laws</a>.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://openai.com/blog/dall-e-now-available-in-beta/" target="_blank">Public (beta) access to DALL-E is beginning</a>! It might take a while to get in because there are over a million on the waitlist. Accepted users get 50 free credits the first month, 15/month thereafter; a credit allows you to give one prompt, which returns 4 images. Users can buy additional credits.</li><li>Researchers have used reinforcement learning to build a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/07/18/1056059/robot-dog-ai-reinforcement/" target="_blank">robotic dog that learns to walk on its own</a> in the real world (i.e., without prior training and use of a simulator).</li><li>Princeton held a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://sites.google.com/princeton.edu/rep-workshop/" target="_blank">workshop</a> on the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/random_walker/status/1542879397245423616" target="_blank">reproducibility crisis</a> that the use of machine learning is causing in science. Evaluating the accuracy of results from machine learning is a problem that most scientific disciplines aren’t yet equipped to deal with.</li><li>Microsoft has revised its <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf" target="_blank">Responsible AI standard</a>, making recommendations more concrete, particularly in the areas of accountability, transparency, fairness, safety, privacy, and inclusiveness. Microsoft also provides <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.microsoft.com/en-us/ai/responsible-ai-resources" target="_blank">tools and resources</a> to help developers build responsible AI systems.</li><li>The Dallery Gallery has published a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://dallery.gallery/the-dalle-2-prompt-book/" target="_blank">Prompt Engineering Guide to DALL-E</a>. (DALL-E is maintaining a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://help.openai.com/en/articles/4936794-is-dall-e-available-yet" target="_blank">waitlist</a> for free trial accounts.)</li><li>Simon Willison has successfully used GPT-3 to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/" target="_blank">explain how code works</a>. It is amazingly good and, as Simon pointed out, works both on code that he understands, and code that he doesn’t.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://huggingface.co/bigscience/bloom" target="_blank">Bloom</a>, the open and transparent large language model developed by the BigScience group, is <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://bigscience.huggingface.co/blog/bloom" target="_blank">finished</a>!&nbsp; You can try it out, download it, and read its specifications. Unlike all other large language models, Bloom was developed in public, and is open to the public.</li><li>Radiologists outperform AI systems operating by themselves at detecting breast cancer from mammograms. However, a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/07/11/1055677/ai-diagnose-breast-cancer-mammograms/" target="_blank">system designed to collaborate</a> with radiologists in making decisions is better than either radiologists or AI alone. (The big question is whether these results hold up when taken to other hospitals.)</li><li>You liked Copilot? Try <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.autoregex.xyz/" target="_blank">Autoregex</a>: GPT-3 to generate regular expressions from natural language descriptions.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/facebookresearch/fairseq/tree/nllb" target="_blank">No Language Left Behind</a> (NLLB) is a Meta AI project that translates text directly between any pair of over 200 languages. Benchmarks, training code, and models are all open source.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nature.com/articles/s41562-022-01383-x" target="_blank">Democratic AI</a> is an experiment in human-in-the-loop design that enables an AI system to design a social mechanism with human collaboration. </li><li>The Allen Institute, Microsoft, and others have developed a tool to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/07/06/1055458/ai-research-emissions-energy-efficient/" target="_blank">measure the energy use and emissions generated by training AI models</a> on Azure. They have found that emissions can be reduced substantially by training during periods when renewable power is at its peak.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html" target="_blank">Minerva</a> is a large language model that Google has trained to solve quantitative reasoning (i.e., mathematics) problems, generating simple proofs in addition to answers. The problem domain extends through pre-calculus, including algebra and geometry, roughly at a high school level. Minerva has also been trained and tested in chemistry and physics.  </li></ul>



<h2>Security</h2>



<ul><li>Perhaps the scariest exploit in security would be a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/07/researchers-unpack-unkillable-uefi-rootkit-that-survives-os-reinstalls/" target="_blank">rootkit that cannot be detected or removed</a>, even by wiping the disk and reinstalling the operating system.&nbsp;Such rootkits were recently discovered (one is named CosmicStrand); they have apparently been in the wild since 2016.</li><li>AWS is offering some customers a free <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/aws-customers-can-now-order-a-free-mfa-security-key/" target="_blank">multi factor authentication</a> (MFA) security key.</li><li>Lost passwords are an important <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/07/malware-circulating-online-wrangles-industrial-systems-into-a-botnet/#p3" target="_blank">attack vector for industrial systems</a>. A system is installed; the default password is changed; the person who changed the password leaves; the password is lost; the company installs password recovery software, which is often malware-infested, to recover the password.</li><li>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.wired.com/story/web-deanonymization-side-channel-attack-njit/" target="_blank">new technique for browser de-anonymization</a> is based on correlating users’ activities on different websites.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/ransomware-gang-now-lets-you-search-their-stolen-data/" target="_blank">Ransomware companies are now using search engines</a> to allow their users to search the data they have stolen.</li><li>Ransomware doesn’t get as much attention in the news as it did last year, but in the past week one ransomware operation has shut down and released its decryptors, and two new ones (RedAlert and omega) <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/the-week-in-ransomware-july-8th-2022-one-down-many-to-go/" target="_blank">have started</a>.</li><li>Apple has added “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.apple.com/newsroom/2022/07/apple-expands-commitment-to-protect-users-from-mercenary-spyware/" target="_blank">lockdown mode</a>” to iOS.&nbsp; Lockdown mode provides an extreme degree of privacy; it is intended for people who believe they are being targeted by state-sponsored mercenary spyware.</li><li>The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://openssf.org/oss-security-mobilization-plan/" target="_blank">Open Source Security Mobilization Plan</a> is an initiative that aims to address major areas of open source security, including education, risk assessment, digital signatures, memory safety, incident response, and software supply chain management.</li><li>Mitre has released their annual list of the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html" target="_blank">25 most dangerous software weaknesses</a> (bugs, flaws, vulnerabilities).</li><li>Patches for the Log4J vulnerability were released back in February, 2022, but <a href="https://thenewstack.io/log4shell-hacks-on-and-on/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">many organizations have not applied them</a>, and remain vulnerable to attack.</li></ul>



<h2>Programming</h2>



<ul><li>Microsoft and Oracle have announced <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oracle.com/news/announcement/oracle-database-service-for-microsoft-azure-2022-07-20/" target="_blank">Oracle Data Service</a>, which allows applications running on Azure to manage and use data in Oracle’s cloud. It’s a multicloud strategy that’s enabled by the cloud providers.</li><li>Google has announced a new programming language, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://9to5google.com/2022/07/19/carbon-programming-language-google-cpp/" target="_blank">Carbon</a>, that is intended to be the successor to C++. One goal is complete interoperability between Carbon and existing C++ code and libraries.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://theburningmonk.com/2022/07/the-best-ways-to-save-money-on-lambda/" target="_blank">How to save money on AWS Lambda</a>: watch your memory!&nbsp; Don’t over-allocate memory. This probably only applies to a few of your functions, but those functions are what drive the cost up.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/07/14/1055894/us-military-sofware-linux-kernel-open-source/" target="_blank">SocialCyber</a> is a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.darpa.mil/program/hybrid-ai-to-protect-integrity-of-open-source-code" target="_blank">DARPA program</a> to understand the internals of open source software, along with the communities that create the software. They plan to use machine learning heavily, both to understand the code and to map and analyze communications within the communities. They are concerned about potential vulnerabilities in the software that the US military depends on.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/whats-next-in-webassembly/" target="_blank">WebAssembly in the cloud</a>? Maybe it isn’t just a client-side technology. As language support grows, so do the kinds of applications Wasm can support.</li><li>A <a rel="noreferrer noopener" aria-label="surveyreports (opens in a new tab)" href="https://tidelift.com/2022-open-source-software-supply-chain-survey" target="_blank">surveyreports</a> that 62% of its respondents were only “somewhat confident” that open source software was “secure, up-to-date, and well-maintained.”&nbsp; Disappointing as this may be, it’s actually an improvement over prior results.</li><li>Is <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/infrastructure-as-code-goes-low-code-no-code/" target="_blank">low-code infrastructure as code</a> the future of cloud operations?</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://lunduke.substack.com/p/tiny-core-linux-130-full-linux-desktop" target="_blank">Tiny Core Linux</a> is amazingly small: a 22MB download, and runs in 48MB of RAM. As a consequence, it’s also amazingly fast. With a few exceptions, making things small has not been a trend over the past few years.&nbsp;We hope to see more of this.</li><li>Yet another JavaScript web framework? <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/denos-fresh-uses-server-side-rendering-for-faster-apps/" target="_blank">Fresh</a> does server-side rendering, and is based on Deno rather than NodeJS.</li></ul>



<h2>Web</h2>



<ul><li>Facebook is considering whether to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/tech-policy/2022/07/meta-thinks-facebook-may-need-more-harmful-health-misinformation/#p3" target="_blank">rescind its bans on health misinformation</a>. The pandemic is over, after all. Except that it isn’t. However, being a conduit for health misinformation is clearly profitable.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.etsy.com/codeascraft/priority-hints-what-your-browser-doesnt-know-yet" target="_blank">Priority Hints</a> are a way for web developers to tell the browser <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://web.dev/priority-hints/" target="_blank">which parts of the page are most important</a>, so that they can be rendered quickly. They are currently supported by the Chrome and Edge browsers.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://hotwired.dev/" target="_blank">Hotwire</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://htmx.org/" target="_blank">HTMX</a>, and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://unpoly.com/" target="_blank">Unpoly</a> are frameworks for building complex web applications while minimizing the need for complex Javascript. Are they an alternative to heavyweight JavaScript frameworks like React? Could a return to server-side web applications lead to a resurgence of platforms like <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/turbocharging-ruby-on-rails-with-html-over-the-wire/" target="_blank">Ruby on Rails</a>?</li><li>Facebook has started <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.ghacks.net/2022/07/17/facebook-has-started-to-encrypt-links-to-counter-privacy-improving-url-stripping/" target="_blank">encrypting the portions of URLs that are used to track users</a>, preventing the Firefox and Brave browsers from stripping the tracking portion of the URL.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/07/15/1056042/chinese-novel-censored-before-shared/" target="_blank">A priori censorship?</a>&nbsp; A popular cloud-based word processor in China has been observed censoring content upon the creation of a link for sharing the content. The document is locked; it cannot be edited or even opened by the author.</li><li>The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://pilimi.org/" target="_blank">Pirate Library Mirror</a> is exactly what it says: a mirror of libraries of pirated books. It is focused on the preservation of human knowledge. There is no search engine, and it is only accessible by using BitTorrent over TOR.</li></ul>



<h2>Web3</h2>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/gaming/2022/07/minecraft-blocks-the-blockchain-from-its-block-game/" target="_blank">Minecraft has decided that they will not “support or allow” the integration of NFTs</a> into their virtual worlds. They object to “digital ownership based on scarcity and exclusion.”</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/07/usage-of-crypto-mixers-for-stymying-blockchain-investigations-hits-all-time-high/#p3" target="_blank">Mixers</a> are cryptocurrency services that randomize the currency you use; rather than pay with your own coin, you deposit money in a mixer and pay with randomly selected coins from other users. It’s similar to a traditional bank in that you never withdraw the same money you deposited.</li><li>So much for privacy. Coinbase, one of the largest cryptocurrency exchanges, <a href="https://theintercept.com/2022/06/29/crypto-coinbase-tracer-ice/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">sells geolocation data to ICE</a> (the US Immigration and Customs Enforcement agency).</li></ul>



<h2>Quantum Computing</h2>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://phys.org/news/2022-07-quantum.html" target="_blank">Quantum computers aren’t limited to binary</a>: That limit is imposed by analogy to traditional computers, but some quantum computers have access to more state, and taking advantage of those states may make applications like simulating physical or biological systems easier.</li><li>Is quantum-aided computing for some industrial applications just around the corner? <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/quantum-computing-use-cases-how-viable-is-it-really/" target="_blank">IonQ and GE have announced a results from a hybrid system</a> for risk management. The quantum computer does random sampling from probability distributions, which are computationally expensive for classical computers; the rest of the computation is classical.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://phys.org/news/2022-07-entanglement-quantum-memories.html" target="_blank">Quantum networking</a> is becoming real: researchers have created entangled qubits via a 33-mile fiber optic connection. In addition to their importance for secure communications, quantum networks may be a crucial step in building quantum computers at scale. </li><li>NIST has announced <a href="https://arstechnica.com/information-technology/2022/07/nist-selects-quantum-proof-algorithms-to-head-off-the-coming-cryptopocalypse/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">four candidate algorithms for post-quantum cryptography</a>. While it may be years before quantum computing can break current algorithms, many organizations are anxious to start the transition from current algorithms. </li></ul>



<h2>Biology</h2>



<ul><li>Not long ago (2020), DeepMind released AlphaFold, which used AI to solve protein folding problems. In 2021, they announced a public database containing the structure of a million proteins. With their latest additions, that database now contains the structure of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe" target="_blank">over 200 million</a> proteins, almost every protein known to science.</li><li>A <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nature.com/articles/s41586-022-04910-y" target="_blank">motor made of DNA</a>!&nbsp; This nanoscale motor uses ideas from origami to fold DNA in a way that causes it to rotate when an electrical field is applied. </li><li>An <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bloomberg.com/news/articles/2022-07-18/brain-computer-interface-company-implants-new-type-of-device?sref=htOHjx5Y" target="_blank">electrode has been implanted into the brain of an ALS patient</a> that will allow them to communicate thoughts via computer. The patient has otherwise lost the ability to move or speak.</li><li>Genetic editing with <a href="https://www.technologyreview.com/2022/07/12/1055773/crispr-gene-editing-cholesterol/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">CRISPR was tested in a human</a> to permanently lower LDL (“bad cholesterol”) levels. If this works, it could make heart attacks much rarer, and could be the first widespread use of CRISPR in humans.</li></ul>



<h2>Energy</h2>



<ul><li>Researchers in India have developed a carbon-negative process for <a href="https://techxplore.com/news/2022-07-green-hydrogen-biomass-abundant-renewable.html" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">generating Hydrogen from biomass</a>. </li></ul>



<h2>Work</h2>



<ul><li>Some cities (largely in the US South and Midwest) are giving <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/us-cities-try-luring-remote-tech-workers-with-cash/" target="_blank">cash bonuses to tech worker</a>s who are willing to move there and work remotely.</li><li>The <a href="https://www.zdnet.com/article/fbi-warning-crooks-are-are-using-deepfakes-to-apply-for-remote-tech-jobs/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">FBI is warning employers</a> that they are seeing an increasing number of fraudulent applications for remote work in which the application uses stolen personal information and deepfake imagery.</li></ul>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/radar-trends-to-watch-august-2022/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>SQL: The Universal Solvent for REST APIs</title>
		<link>https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/</link>
				<comments>https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/#respond</comments>
				<pubDate>Tue, 19 Jul 2022 11:16:39 +0000</pubDate>
		<dc:creator><![CDATA[Jon Udell]]></dc:creator>
				<category><![CDATA[Data]]></category>
		<category><![CDATA[Deep Dive]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14612</guid>
				<description><![CDATA[Data scientists working in Python or R typically acquire data by way of REST APIs. Both environments provide libraries that help you make HTTP calls to REST endpoints, then transform JSON responses into dataframes. But that&#8217;s never as simple as we&#8217;d like. When you&#8217;re reading a lot of data from a REST API, you need [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>Data scientists working in Python or R typically acquire data by way of REST APIs. Both environments provide libraries that help you make HTTP calls to REST endpoints, then transform JSON responses into dataframes. But that&#8217;s never as simple as we&#8217;d like. When you&#8217;re reading a lot of data from a REST API, you need to do it a page at a time, but pagination works differently from one API to the next. So does unpacking the resulting JSON structures. HTTP and JSON are low-level standards, and REST is a loosely-defined framework, but nothing guarantees absolute simplicity, never mind consistency across APIs.</p>



<p>What if there were a way of reading from APIs that abstracted all the low-level grunt work and worked the same way everywhere? Good news! That is exactly what <a href="https://steampipe.io/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Steampipe</a> does. It&#8217;s a tool that translates REST API calls directly into SQL tables. Here are three examples of questions that you can ask and answer using Steampipe.</p>



<h3>1. Twitter: What are recent tweets that mention PySpark?</h3>



<p>Here&#8217;s a SQL query to ask that question:</p>



<pre class="wp-block-code"><code>select
  id,
  text
from
  twitter_search_recent
where
  query = 'pyspark'
order by
  created_at desc
limit 5;</code></pre>



<p>Here&#8217;s the answer:</p>



<pre class="wp-block-code"><code>+---------------------+------------------------------------------------------------------------------------------------&gt;
| id                  | text                                                                                           &gt;
+---------------------+------------------------------------------------------------------------------------------------&gt;
| 1526351943249154050 | @dump Tenho trabalhando bastante com Spark, mas especificamente o PySpark. Vale a pena usar um &gt;
| 1526336147856687105 | RT @MitchellvRijkom: PySpark Tip &#x26a1;                                                            &gt;
|                     |                                                                                                &gt;
|                     | When to use what StorageLevel for Cache / Persist?                                             &gt;
|                     |                                                                                                &gt;
|                     | StorageLevel decides how and where data should be s…                                           &gt;
| 1526322757880848385 | Solve challenges and exceed expectations with a career as a AWS Pyspark Engineer. https://t.co/&gt;
| 1526318637485010944 | RT @JosMiguelMoya1: #pyspark #spark #BigData curso completo de Python y Spark con PySpark      &gt;
|                     |                                                                                                &gt;
|                     | https://t.co/qf0gIvNmyx                                                                        &gt;
| 1526318107228524545 | RT @money_personal: PySpark &amp;amp; AWS: Master Big Data With PySpark and AWS                    &gt;
|                     | #ApacheSpark #AWSDatabases #BigData #PySpark #100DaysofCode                                    &gt;
|                     | -&amp;gt; http…                                                                                    &gt;
+---------------------+------------------------------------------------------------------------------------------------&gt;</code></pre>



<p>The table that&#8217;s being queried here,&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent" target="_blank">twitter_search_recent</a>, receives the output from Twitter&#8217;s&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent" target="_blank">/2/tweets/search/recent</a>&nbsp;endpoint and formulates it as a table with&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent#inspect" target="_blank">these columns</a>. You don&#8217;t have to make an HTTP call to that API endpoint or unpack the results, you just write a SQL query that refers to the documented columns. One of those columns,&nbsp;<code>query</code>, is special: it encapsulates Twitter&#8217;s&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query" target="_blank">query syntax</a>. Here, we are just looking for tweets that match&nbsp;<em>PySpark</em>&nbsp;but we could as easily refine the query by pinning it to specific users, URLs, types (<code>is:retweet</code>,&nbsp;<code>is:reply</code>), properties (<code>has:mentions</code>,&nbsp;<code>has_media</code>), etc. That query syntax is the same no matter how you&#8217;re accessing the API: from Python, from R, or from Steampipe. It&#8217;s plenty to think about, and all you should really need to know when crafting queries to mine Twitter data.</p>



<h3>2. GitHub: What are repositories that mention PySpark?</h3>



<p>Here&#8217;s a SQL query to ask that question:</p>



<pre class="wp-block-code"><code>select 
  name, 
  owner_login, 
  stargazers_count 
from 
  github_search_repository 
where 
  query = 'pyspark' 
order by stargazers_count desc 
limit 10;</code></pre>



<p>Here&#8217;s the answer:</p>



<pre class="wp-block-code"><code>+----------------------+-------------------+------------------+
| name                 | owner_login       | stargazers_count |
+----------------------+-------------------+------------------+
| SynapseML            | microsoft         | 3297             |
| spark-nlp            | JohnSnowLabs      | 2725             |
| incubator-linkis     | apache            | 2524             |
| ibis                 | ibis-project      | 1805             |
| spark-py-notebooks   | jadianes          | 1455             |
| petastorm            | uber              | 1423             |
| awesome-spark        | awesome-spark     | 1314             |
| sparkit-learn        | lensacom          | 1124             |
| sparkmagic           | jupyter-incubator | 1121             |
| data-algorithms-book | mahmoudparsian    | 1001             |
+----------------------+-------------------+------------------+</code></pre>



<p>This looks very similar to the first example! In this case, the table that&#8217;s being queried,&nbsp;<a href="https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository">github_search_repository</a>, receives the output from GitHub&#8217;s&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://docs.github.com/en/rest/search#search-repositories" target="_blank">/search/repositories</a>&nbsp;endpoint and formulates it as a table with&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository#inspect" target="_blank">these columns</a>.</p>



<p>In both cases the Steampipe documentation not only shows you the schemas that govern the mapped tables, it also gives examples (<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://hub.steampipe.io/plugins/turbot/twitter/tables/twitter_search_recent#examples" target="_blank">Twitter</a>,&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://hub.steampipe.io/plugins/turbot/github/tables/github_search_repository#examples" target="_blank">GitHub</a>) of SQL queries that use the tables in various ways.</p>



<p>Note that these are just two of many available tables. The Twitter API is mapped to&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://hub.steampipe.io/plugins/turbot/twitter/tables" target="_blank">7 tables</a>, and the GitHub API is mapped to&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://hub.steampipe.io/plugins/turbot/github/tables" target="_blank">41 tables</a>.</p>



<h3>3. Twitter + GitHub: What have owners of PySpark-related repositories tweeted lately?</h3>



<p>To answer this question we need to consult two different APIs, then join their results. That&#8217;s even harder to do, in a consistent way, when you&#8217;re reasoning over REST payloads in Python or R. But this is the kind of thing SQL was born to do. Here&#8217;s one way to ask the question in SQL.</p>



<pre class="wp-block-code"><code>-- find pyspark repos
with github_repos as (
  select 
    name, 
    owner_login, 
    stargazers_count 
  from 
    github_search_repository 
  where 
    query = 'pyspark' and name ~ 'pyspark'
  order by stargazers_count desc 
  limit 50
),

-- find twitter handles of repo owners
github_users as (
  select
    u.login,
    u.twitter_username
  from
    github_user u
  join
    github_repos r
  on
    r.owner_login = u.login
  where
    u.twitter_username is not null
),

-- find corresponding twitter users
  select
    id
  from
    twitter_user t
  join
    github_users g
  on
    t.username = g.twitter_username
)

-- find tweets from those users
select
  t.author-&gt;&gt;'username' as twitter_user,
  'https://twitter.com/' || (t.author-&gt;&gt;'username') || '/status/' || t.id as url,
  t.text
from
  twitter_user_tweet t
join
  twitter_userids u
on
  t.user_id = u.id
where
  t.created_at &gt; now()::date - interval '1 week'
order by
  t.author
limit 5</code></pre>



<p>Here is the answer:</p>



<pre class="wp-block-code"><code>+----------------+---------------------------------------------------------------+-------------------------------------&gt;
| twitter_user   | url                                                           | text                                &gt;
+----------------+---------------------------------------------------------------+-------------------------------------&gt;
| idealoTech     | https://twitter.com/idealoTech/status/1524688985649516544     | Are you able to find creative soluti&gt;
|                |                                                               |                                     &gt;
|                |                                                               | Join our @codility Order #API Challe&gt;
|                |                                                               |                                     &gt;
|                |                                                               | #idealolife #codility #php          &gt;
| idealoTech     | https://twitter.com/idealoTech/status/1526127469706854403     | Our #ProductDiscovery team at idealo&gt;
|                |                                                               |                                     &gt;
|                |                                                               | Think you can solve it? &#x1f60e;          &gt;
|                |                                                               | &#x27a1;  https://t.co/ELfUfp94vB https://t&gt;/
| ioannides_alex | https://twitter.com/ioannides_alex/status/1525049398811574272 | RT @scikit_learn: scikit-learn 1.1 i&gt;
|                |                                                               | What's new? You can check the releas&gt;
|                |                                                               |                                     &gt;
|                |                                                               | pip install -U…                     &gt;
| andfanilo      | https://twitter.com/andfanilo/status/1524999923665711104      | @edelynn_belle Thanks! Sometimes it &gt;
| andfanilo      | https://twitter.com/andfanilo/status/1523676489081712640      | @juliafmorgado Good luck on the reco&gt;
|                |                                                               |                                     &gt;
|                |                                                               | My advice: power through it + a dead&gt;
|                |                                                               |                                     &gt;
|                |                                                               | I hated my first few short videos bu&gt;
|                |                                                               |                                     &gt;
|                |                                                               | Looking forward to the video &#x1f642;</code></pre>



<p>When APIs frictionlessly become tables, you can devote your full attention to reasoning over the abstractions represented by those APIs. Larry Wall, the creator of Perl, famously said: &#8220;Easy things should be easy, hard things should be possible.&#8221; The first two examples are things that should be, and are, easy: each is just 10 lines of simple, straight-ahead SQL that requires no wizardry at all.</p>



<p>The third example is a harder thing. It would be hard in any programming language. But SQL makes it possible in several nice ways. The solution is made of concise stanzas (CTEs, Common Table Expressions) that form a pipeline. Each phase of the pipeline handles one clearly-defined piece of the problem. You can validate the output of each phase before proceeding to the next. And you can do all this with the most mature and widely-used grammar for selection, filtering, and recombination of data.</p>



<h4>Do I have to use SQL?</h4>



<p>No! If you like the idea of mapping APIs to tables, but you would rather reason over those tables in Python or R dataframes, then Steampipe can oblige. Under the covers it&#8217;s Postgres, enhanced with&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers" target="_blank">foreign data wrappers</a>&nbsp;that handle the API-to-table transformation. Anything that can connect to Postgres can connect to Steampipe, including SQL drivers like Python&#8217;s&nbsp;<code>psycopg2</code>&nbsp;and R&#8217;s&nbsp;<code>RPostgres</code>&nbsp;as well as business-intelligence tools like Metabase, Tableau, and PowerBI. So you can use Steampipe to frictionlessly consume APIs into dataframes, then reason over the data in Python or R.</p>



<p>But if you haven&#8217;t used SQL in this way before, it&#8217;s worth a look. Consider this comparison of SQL to Pandas from&nbsp;<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://medium.com/jbennetcodes/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e" target="_blank">How to rewrite your SQL queries in Pandas</a>.</p>



<figure class="wp-block-table"><table class=""><thead><tr><th class="has-text-align-center" data-align="center">SQL</th><th class="has-text-align-center" data-align="center">Pandas</th></tr></thead><tbody><tr><td class="has-text-align-center" data-align="center">select * from airports</td><td class="has-text-align-center" data-align="center">airports</td></tr><tr><td class="has-text-align-center" data-align="center">select * from airports limit 3</td><td class="has-text-align-center" data-align="center">airports.head(3)</td></tr><tr><td class="has-text-align-center" data-align="center">select id from airports where ident = &#8216;KLAX&#8217;</td><td class="has-text-align-center" data-align="center">airports[airports.ident == &#8216;KLAX&#8217;].id</td></tr><tr><td class="has-text-align-center" data-align="center">select distinct type from airport</td><td class="has-text-align-center" data-align="center">airports.type.unique()</td></tr><tr><td class="has-text-align-center" data-align="center">select * from airports where iso_region = &#8216;US-CA&#8217; and type = &#8216;seaplane_base&#8217;</td><td class="has-text-align-center" data-align="center">airports[(airports.iso_region == &#8216;US-CA&#8217;) &amp; (airports.type == &#8216;seaplane_base&#8217;)]</td></tr><tr><td class="has-text-align-center" data-align="center">select ident, name, municipality from airports where iso_region = &#8216;US-CA&#8217; and type = &#8216;large_airport&#8217;</td><td class="has-text-align-center" data-align="center">airports[(airports.iso_region == &#8216;US-CA&#8217;) &amp; (airports.type == &#8216;large_airport&#8217;)][[&#8216;ident&#8217;, &#8216;name&#8217;, &#8216;municipality&#8217;]]</td></tr></tbody></table></figure>



<p>We can argue the merits of one style versus the other, but there&#8217;s no question that SQL is the most universal and widely-implemented way to express these operations on data. So no, you don&#8217;t have to use SQL to its fullest potential in order to benefit from Steampipe. But you might find that you want to.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/sql-the-universal-solvent-for-rest-apis/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>Artificial Creativity?</title>
		<link>https://www.oreilly.com/radar/artificial-creativity-2/</link>
				<comments>https://www.oreilly.com/radar/artificial-creativity-2/#respond</comments>
				<pubDate>Tue, 12 Jul 2022 13:24:16 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Commentary]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14604</guid>
				<description><![CDATA[There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&#160; As with the discussion of sentience, authors are [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>There’s a puzzling disconnect in the many articles I read about DALL-E 2, Imagen, and the other increasingly powerful tools I see for generating images from textual descriptions. It’s common to read articles that talk about AI having creativity–but I don’t think that’s the case at all.&nbsp; As with the discussion of sentience, authors are being misled by a very human will to believe. And in being misled, they’re missing out on what’s important.</p>



<p>It’s impressive to see AI-generated pictures of an <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/OpenAI/status/1511714545529614338?ref_src=twsrc%5Etfw" target="_blank">astronaut riding a horse</a>, or a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.thedailybeast.com/googles-new-text-to-image-generator-imagen-is-scary-accurate" target="_blank">dog riding a bike in Times Square</a>. But where’s the creativity?&nbsp; Is it in the prompt or in the product?&nbsp; I couldn’t draw a picture of a dog riding a bike; I’m not that good an artist. Given a few pictures of dogs, Times Square, and whatnot, I could probably photoshop my way into something passable, but not very good. &nbsp;(To be clear: these AI systems are not automating photoshop.) So the AI is doing something that many, perhaps most humans, wouldn’t be able to do. That’s important. Very few humans (if any) can play Go at the level of AlphaGo. We’re getting used to being second-best.</p>



<p>However, a computer replacing a human’s limited photoshop skills isn’t creativity. It took a human to say “create a picture of a dog riding a bike.” An AI couldn’t do that of its own volition. That’s creativity.&nbsp;But before writing off the creation of the picture, let’s think more about what that really means. Works of art really have two sources: the idea itself and the technique required to instantiate that idea. You can have all the ideas you want, but if you can’t paint like Rembrandt, you’ll never generate a Dutch master. Throughout history, painters have learned technique by copying the works of masters. What’s interesting about DALL-E, Imagen, and their relatives is that they supply the technique. Using DALL-E or Imagen, I could create a painting of a tarsier eating an anaconda without knowing how to paint.</p>



<p>That distinction strikes me as very important. In the 20th and 21st centuries we’ve become very impatient with technique. We haven’t become impatient with creating good ideas. (Or at least strange ideas.) The “age of mechanical reproduction” seems to have made technique less relevant; after all, we’re heirs of the poet Ezra Pound, who famously said, “Make it new.”</p>



<p>But does that quote mean what we think? Pound’s “Make it new” has been <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.guernicamag.com/the-making-of-making-it-new/" target="_blank">traced back</a> to 18th century China, and from there to the 12th century, something that’s not at all surprising if you’re familiar with Pound’s fascination with Chinese literature. What’s interesting, though, is that Chinese art has always focused on technique to a level that’s almost inconceivable to the European tradition. And “Make it new” has, within it, the acknowledgment that what’s new first has to be made. Creativity and technique don’t come apart that easily.</p>



<p>We can see that in other art forms. Beethoven broke Classical music and put it back together again, but different-–he’s the most radical composer in the Western tradition (except for, perhaps, Thelonious Monk). And it’s worth asking how we get from what’s old to what’s new.&nbsp; AI has been used to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.classicfm.com/composers/beethoven/unfinished-tenth-symphony-completed-by-artificial-intelligence/" target="_blank">complete Beethoven’s 10th symphony</a>, for which Beethoven left a number of sketches and notes at the time of his death. The result is pretty good, better than the human attempts I’ve heard at completing the 10th.&nbsp;It sounds Beethoven-like; its flaw is that it goes on and on, repeating Beethoven-like riffs but without the tremendous forward-moving force that you get in Beethoven’s compositions. But completing the 10th isn’t the problem we should be looking at. How did we get Beethoven in the first place?&nbsp; If you trained an AI on the music Beethoven was trained on, would you eventually get the 9th symphony?&nbsp;Or would you get something that sounds a lot like Mozart and Haydn?</p>



<p>I’m betting the latter. The progress of art isn’t unlike the structure of scientific revolutions, and Beethoven indeed took everything that was known, broke it apart, and put it back together differently. Listen to the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.youtube.com/watch?v=HljSXSm6v9M" target="_blank">opening of Beethoven’s 9th symphony</a>: what is happening? Where’s the theme? It sounds like the orchestra is tuning up. When the first theme finally arrives, it’s not the traditional “melody” that pre-Beethoven listeners would have expected, but something that dissolves back into the sound of instruments tuning, then gets reformed and reshaped. Mozart would never do this. Or listen again to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.youtube.com/watch?v=a9UApyClFKA" target="_blank">Beethoven’s 5th symphony</a>, probably the most familiar piece of orchestral music in the world. That opening duh-duh-duh-DAH–what kind of theme is that? Beethoven builds this movement by taking that four note fragment, moving it around, changing it, breaking it into even smaller bits and reassembling them. You can’t imagine a witty, urbane, polite composer like Haydn writing music like this. But I don’t want to worship some notion of Beethoven’s “genius” that privileges creativity over technique. Beethoven could never have gotten beyond Mozart and Haydn (with whom Beethoven studied) without extensive knowledge of the technique of composing; he would have had some good ideas, but he would never have known how to realize them. Conversely, the realization of radical ideas as actual works of art inevitably changes the technique. Beethoven did things that weren’t conceivable to Mozart or Haydn, and they changed the way music was written: those changes made the music of Schubert, Schumann, and Brahms possible, along with the rest of the 19th century. </p>



<p>That brings us back to the question of computers, creativity, and craft. Systems like DALL-E and Imagen break apart the idea and the technique, or the execution of the idea. Does that help us be more creative, or less? I could tell Imagen to “paint a picture of a 15th century woman with an enigmatic smile,” and after a few thousand tries I might get something like the Mona Lisa. I don’t think that anyone would care, really.&nbsp; But this isn’t creating something new; it’s reproducing something old. If I magically appeared early in the 20th century, along with a computer capable of running Imagen (though only trained on art through 1900), would I be able to tell it to create a Picasso or a Dali? I have no idea how to do that. Nor do I have any idea what the next step for art is now, in the 21st century, or how I’d ask Imagen to create it. It sure isn’t Bored Apes. And if I could ask Imagen or DALL-E to create a painting from the 22nd century, how would that change the AI’s conception of technique?</p>



<p>At least part of what I lack is the technique, for technique isn’t just mechanical ability; it’s also the ability to think the way great artists do. And that gets us to the big question:</p>



<p>Now that we have abstracted technique away from the artistic process, can we build interfaces between the creators of ideas and the machines of technique in a way that allows the creators to “make it new”?&nbsp; That’s what we really want from creativity: something that didn’t exist, and couldn’t have existed, before.</p>



<p>Can artificial intelligence help us to be creative? That’s the important question, and it’s a question about user interfaces, not about who has the biggest model.</p>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/artificial-creativity-2/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>Radar Trends to Watch: July 2022</title>
		<link>https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/</link>
				<comments>https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/#respond</comments>
				<pubDate>Tue, 05 Jul 2022 11:09:04 +0000</pubDate>
		<dc:creator><![CDATA[Mike Loukides]]></dc:creator>
				<category><![CDATA[Radar Trends]]></category>
		<category><![CDATA[Signals]]></category>

		<guid isPermaLink="false">https://www.oreilly.com/radar/?p=14591</guid>
				<description><![CDATA[This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask. The most important issue facing technology might now be [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>This month, large models are even more in the news than last month: the open source Bloom model is almost finished, Google’s LaMDA is good enough that it can trick people into thinking it’s sentient, and DALL-E has gotten even better at drawing what you ask.</p>



<p>The most important issue facing technology might now be the protection of privacy. While that’s not a new concern, it’s a concern that most computer users have been willing to ignore, and that most technology companies have been willing to let them ignore. New state laws that criminalize having abortions out of state and the stockpiling of location information by antiabortion groups have made privacy an issue that can’t be ignored.</p>



<h2>Artificial Intelligence</h2>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nature.com/articles/d41586-022-01705-z" target="_blank">Big Science has almost finished training</a> its open source <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://bigscience.huggingface.co/blog/model-training-launched" target="_blank">BLOOM language model</a>, which was developed by volunteer researchers and trained using public funds. Bloom will provide an open, public platform for research into the capabilities of large language models and, specifically,&nbsp; issues like avoiding bias and toxic language. </li><li>AI tools like AlphaFold2 can <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://colbyford.medium.com/am-i-hallucinating-or-can-ai-now-design-cancer-curing-antibodies-3ef1bef92106" target="_blank">create new proteins</a>, not just analyze existing ones; the unexpected creation of new artifacts by an AI system is playfully called “hallucination.” The proteins designed so far probably aren’t useful; still, this is a major step forward in drug design.</li><li>Microsoft is <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.theverge.com/2022/6/21/23177016/microsoft-retires-emotion-recognition-azure-ai-tool-api" target="_blank">limiting or removing access</a> to some features in its face recognition service, Azure Face. Organizations will have to tell Microsoft how and why facial recognition will be used in their systems; and services like emotion recognition will be removed completely.</li><li>Amazon plans to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.reuters.com/technology/amazon-has-plan-make-alexa-mimic-anyones-voice-2022-06-22/" target="_blank">give Alexa the ability to imitate anyone’s voice</a>, using under a minute of audio. They give the example of a (possibly dead) grandmother “reading” a book to a child. Other AI vendors (most notably <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenextweb.com/news/openai-punished-dev-used-gpt-3-to-resurrect-dead-ethics" target="_blank">OpenAI/Microsoft</a>) have considered such mimicry unethical.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/dolthub/dolt" target="_blank">Dolt</a> is a SQL database that lets you version data using git commands, You can clone, push, pull, fork, branch, and merge just as with git; you access data using standard SQL.</li><li>It’s sadly unsurprising that a robot incorporating a widely-used neural network (OpenAI CLIP) learns <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-06-robots-racist-sexist-flawed-ai.html" target="_blank">racist and sexist biases</a>, and that these biases affect its performance on tasks.</li><li>Building <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-06-technology-self-driving-cars-memories.html" target="_blank">autonomous vehicles with memory</a>, so that they can learn about objects on the routes they drive, may be an important step in making AV practical. In real life, most people drive over routes they are already familiar with. Autonomous vehicles should have the same advantage.</li><li>The argument about whether Google’s LaMDA is “sentient” continues, with a Google engineer placed on administrative leave for <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.theguardian.com/technology/2022/jun/12/google-engineer-ai-bot-sentient-blake-lemoine" target="_blank">publishing transcripts of conversations</a> that he claimed demonstrate sentience. Or are large language models just <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/janellecshane/status/1535835610396692480" target="_blank">squirrels</a>?</li><li>For <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-06-ai-future-art.html" target="_blank">artists working in collaboration with AI</a>, the possibilities and imperfections of AI are a means of extending their creativity.</li><li>Pete Warden’s proposal for <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://petewarden.com/2022/06/09/what-are-ml-sensors/" target="_blank">ML Sensors</a> could make developing embedded ML systems much simpler: push the machine learning into the sensors themselves.</li><li>Researchers using DALL-E 2 discovered that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://theconversation.com/do-ai-systems-really-have-their-own-secret-language-184335" target="_blank">the model has a “secret vocabulary”</a> that’s not human language, but that can be used somewhat reliably to create consistent pictures. It may be an artifact of the model’s inability to say “I didn’t understand that”; given nonsense input, it is pulled towards similar words in the training corpus.</li><li>HuggingFace has made an <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://huggingface.co/blog/hugging-face-endpoints-on-azure" target="_blank">agreement</a> with Microsoft that will allow Azure customers to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenextweb.com/news/what-hugging-face-and-microsofts-collaboration-means-for-applied-ai" target="_blank">run HuggingFace language models on the Azure platform</a>.</li><li>The startup <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://predibase.com/" target="_blank">Predibase</a> has built a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/predibase-takes-declarative-approach-to-automl/" target="_blank">declarative low-code platform</a> for building AI systems. In a declarative system, you describe the outcome you want, rather than the process for creating the outcome. The system figures out the process.</li><li>Researchers are developing AI models that implement <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-06-artificial-intelligence-human.html" target="_blank">metamemory</a>: the ability to remember whether or not you know something.</li><li>As the population ages, it will be more important to diagnose diseases like Alzheimer’s early, when treatment is still meaningful. AI is <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/06/02/1052942/evaluating-brain-mri-scans-with-the-help-of-artificial-intelligence/" target="_blank">providing tools</a> to help doctors analyze MRI images more accurately than humans. These tools don’t attempt diagnosis; they provide data about brain features.</li><li>Google has <a href="https://www.bleepingcomputer.com/news/technology/google-quietly-bans-deepfake-training-projects-on-colab/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">banned the training of Deepfakes</a> on Colab, its free Jupyter-based cloud programming platform.</li></ul>



<h2>Metaverse</h2>



<ul><li>Samsung and RedHat are working on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/samsung-red-hat-to-work-on-linux-drivers-for-future-tech/" target="_blank">new memory architectures and device drivers</a> that will be adequate to the demands of a 3D-enabled, cloud-based metaverse.</li><li>The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://metaverse-standards.org/" target="_blank">Metaverse Standards Forum</a> is a new industry group with the goal of solving interoperability problems for the Metaverse. It views the Metaverse as the outgrowth of the Web, and plans to coordinate work between existing standards groups (like the W3C) relevant to the Metaverse.</li><li>Can the “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/how-the-open-metaverse-will-transform-our-online-identities/" target="_blank">Open Metaverse</a>” be the future of the Internet?&nbsp; The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/omigroup/omigroup/" target="_blank">Open Metaverse Interoperability Group</a> is building vendor-independent standards for social graphs, identities, and other elements of a Metaverse.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-06-augmented-reality-head-up-next-gen.html" target="_blank">Holographic heads-up displays</a> allow for 3D augmented reality: the ability to project 3D images onto the real world (for example, onto a car’s windshield).</li><li>Google’s <a href="https://medium.com/@bilawal/new-google-api-turns-the-world-into-a-3d-canvas-for-augmented-reality-developers-on-ios-android-5c541a705800" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Visual Position Service</a> uses the data they’ve collected through Street View to provide high-accuracy positioning data for augmented reality applications. (This may be related to Niantic’s VPS, or they may just be using the same acronym.)</li></ul>



<h2>Security</h2>



<ul><li>With the end of Roe v. Wade, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.siliconvalley.com/2022/06/27/search-histories-location-data-text-messages-how-personal-data-could-be-used-to-enforce-anti-abortion-laws/" target="_blank">personal data, including search histories and location data, could be used to prosecute women who have abortions</a>. Data brokers already collect and sell this data. It is unclear how large Internet companies that also collect this data will respond. (Google has announced that they will <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blog.google/technology/safety-security/protecting-peoples-privacy-on-health-topics/" target="_blank">delete location histories</a> that include visits to sensitive locations.)</li><li>Security researchers have identified over <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/over-900-000-kubernetes-instances-found-exposed-online/" target="_blank">900,000 Kubernetes clusters that are exposed (and possibly vulnerable) to malicious scans</a>. 65% of them are in the US.</li><li>Sonatype has discovered a number of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blog.sonatype.com/python-packages-upload-your-aws-keys-env-vars-secrets-to-web" target="_blank">modules in the Python’s PyPI repository that steal AWS credentials</a> and other important data. Supply chain security will continue to be a problem for developers, regardless of the programming language or problem domain.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blogs.microsoft.com/on-the-issues/2022/06/22/defending-ukraine-early-lessons-from-the-cyber-war/" target="_blank">Microsoft’s analysis of Russia’s cyberwar efforts</a> show that they have increasingly attacked resources in countries allied with Ukraine (most notably the US), and that government computers that are on-premises are especially vulnerable.</li><li>Working with Fastly and Cloudflare, Apple has developed a service called <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenextweb.com/news/apple-ios-16-banish-captchas" target="_blank">Automatic Verification</a> that eliminates the need for Captchas. According to rumors, it will be enabled by default in the beta of iOS16.</li><li>A surprisingly small botnet (only 5,000 hosts) generated a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/information-technology/2022/06/tsunami-of-junk-traffic-that-broke-ddos-records-delivered-by-tiniest-of-botnets/" target="_blank">record-setting DDOS attack</a> that peaked at 26M HTTPS requests per second. The botnet was so powerful because most of its devices belonged to cloud providers. Cloudflare’s free service was able to mitigate the attack.</li><li>A different kind of attack against neural networks: present them with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://ieeexplore.ieee.org/document/9581273" target="_blank">inputs that drive worst-case energy consumption</a>, forcing processors to reduce their clock speed or even overheat. </li><li>A new attack called Hertzbleed uses <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://arstechnica.com/tech-policy/2022/06/cryptocurrency-plunges-as-crypto-bank-celsius-suspends-withdrawals/" target="_blank">small variations in a processor’s clock speed</a> while it is processing encryption keys to guess those keys. Intel and AMD CPUs are vulnerable. While this attack may never be seen in the wild, it shows how the complexity of modern processors creates vulnerabilities.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.bleepingcomputer.com/news/security/new-symbiote-malware-infects-all-running-processes-on-linux-systems/" target="_blank">Symbiote is a new kind of malware that attacks Linux</a>, injects software into all running processes, and uses Berkeley packet filters (eBPF) to steal data and create covert communications channels. Symbiote uses <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/the-symbiote-malware-what-we-know-so-far/" target="_blank">dynamic linker hijacking</a> to link executables to modified system libraries at run time.</li><li>In the first quarter of 2022, the <a href="https://www.bleepingcomputer.com/news/security/ransomware-gangs-now-give-victims-time-to-save-their-reputation/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">number of known ransomware attacks was down 40%</a>, largely due to the disappearance of the Conti ransomware group. This drop is probably only temporary. Tactics also changed; attackers aren’t announcing the names of their victims publicly, preferring to negotiate a ransom privately. </li></ul>



<h2>Programming</h2>



<ul><li>Amazon has launched <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/" target="_blank">CodeWhisperer</a>, a direct competitor to GitHub Copilot.</li><li>Linus Torvalds predicts that <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/rust-in-the-linux-kernel-by-2023-linus-torvalds-predicts/" target="_blank">Rust will be used in the Linux kernel by 2023</a>.</li><li>GitHub Copilot is now <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/" target="_blank">generally available</a> (for a price); it’s free to students and open source maintainers. Corporate licenses will be available later this year.</li><li>WebAssembly is making inroads. The universal WebAssembly runtime, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://wasmer.io/" target="_blank">Wasmer</a>, runs any code, on any platform. Impressive, if it delivers.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/when-webassembly-replaces-docker/" target="_blank">Can WebAssembly replace Docker?</a> Maybe, in some applications. WASM provides portability and eliminates some security issues (possibly introducing its own); Docker sets up environments.</li><li>Mozilla’s <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blog.mozilla.org/en/mozilla/local-translation-add-on-project-bergamot/" target="_blank">Project Bergamot</a> is an automated translation tool designed for use on the Web. It can be used to build multilingual forms and other web pages. Unlike most other AI technologies, Bergamot runs in the browser using WASM. No data is sent to the cloud.</li><li>Microsoft has <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://thenewstack.io/microsoft-talks-collaborative-apps-at-build-conference/" target="_blank">released</a> a framework called <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://fluidframework.com/" target="_blank">Fluid</a> for building collaborative apps, such as Slack, Discord, and Teams. Microsoft will also be releasing <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://docs.microsoft.com/en-us/azure/azure-fluid-relay/" target="_blank">Azure Fluid Relay</a> to support Fluid-based applications.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://github.com/dragonflydb/dragonfly" target="_blank">Dragonfly</a> is a new in-memory database that claims significantly faster performance than memcached and Redis.</li><li>The Chinese government has <a href="https://www.technologyreview.com/2022/05/30/1052879/censoring-china-open-source-backfire/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">blocked access to open source code</a> on Gitee, the Chinese equivalent to GitHub, saying that all code must be reviewed by the government before it can be released to the public.</li></ul>



<h2>Web3</h2>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blog.trailofbits.com/2022/06/21/are-blockchains-decentralized/" target="_blank">Is Blockchain Decentralized?</a> <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://assets-global.website-files.com/5fd11235b3950c2c1a3b6df4/62af6c641a672b3329b9a480_Unintended_Centralities_in_Distributed_Ledgers.pdf" target="_blank">A study commissioned by DARPA</a> investigates whether a blockchain is truly immutable, or whether it can be modified without exploiting cryptographic vulnerabilities, but by attacking the blockchain’s implementation, networking, and consensus protocols. This is the most comprehensive examination of blockchain security that we’ve seen. </li><li>Jack Dorsey has announced that he’s working on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://cryptobriefing.com/jack-dorsey-tbd-build-web5-on-bitcoin/" target="_blank">Web5</a>, which will be focused on identity management and be based on Bitcoin.</li><li>Molly White’s post questioning the possibility of <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/" target="_blank">acceptably non-dystopian self-sovereign identity</a> is a must-read; she has an excellent summary and critique of just about all the work going on in the field.</li><li>Cryptographer Matthew Green makes an important <a href="https://blog.cryptographyengineering.com/2022/06/09/in-defense-of-cryptocurrency/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">argument for the technologies behind cryptocurrency</a> (though not for the current implementations).</li></ul>



<h2>Biology</h2>



<ul><li>The Innovative Genomics Institute is trying to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2022/06/14/1053843/carbon-capture-crispr-crops/" target="_blank">use CRISPR gene editing to optimize plants for carbon storage</a>.</li><li>A printed artificial skin with embedded transistors may <a href="https://techxplore.com/news/2022-06-artificial-skin-capable-pain-touch-sensitive.html" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">allow robots to feel pain</a>. That’s one step closer to dreaming of electric sheep.</li></ul>



<h2>Quantum Computing</h2>



<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://techxplore.com/news/2022-06-potential-p-computers.html" target="_blank">Probabilistic computers</a>, built from probabilistic bits (p-bits), may provide a significant step forward for probabilistic decision making. This sounds esoteric, but it’s essentially what we’re asking AI systems to do. P-bits may also be able to simulate q-bits and quantum computing.</li><li>A system that <a href="https://thenextweb.com/news/eureka-scientists-just-linked-two-time-crystals-together-first-time" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">links two time crystals</a> could be the basis for a new form of quantum computing. Time crystals can exist at room temperature, and remain coherent for much longer than existing qubit technologies.</li></ul>
]]></content:encoded>
							<wfw:commentRss>https://www.oreilly.com/radar/radar-trends-to-watch-july-2022/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
	</channel>
</rss>
